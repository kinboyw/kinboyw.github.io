<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Git 压缩多个commit为单个commit]]></title>
    <url>%2F2019%2F04%2F09%2FGit-%E5%8E%8B%E7%BC%A9%E5%A4%9A%E4%B8%AAcommit%E4%B8%BA%E5%8D%95%E4%B8%AAcommit%2F</url>
    <content type="text"><![CDATA[原文——Squash commits into one with Git 本篇介绍一个很棒的能将多次修改合并起来的方法，尤其是在将他们共享出去之前 在 Git 中，你可以使用强大的 interactive rebase（交互式 rebase）将多次提交合并成一次。这是我常用的一个很方便的工具；我经常通过将多个临时的小的提交合并成一次提交，然后将整理好的代码 push 给远端。 步骤 1: 选择你的起始提交第一步就是让 git 开始一次交互式 rebase 会话： 1git rebase --interactive HEAD~[N] 或者简写的方式: 1git rebase -i HEAD~[N] 这里的 N 就是你想要合并的提交的数量，从最近的一次提交往前数。例如，这是一个假象的从 git log 中拉取的提交列表，我当前正在修改 feature Z： 12345678871adf OK, feature Z is fully implemented --- newer commit0c3317 Whoops, not yet...87871a I'm ready!643d0e Code cleanupafb581 Fix this and that4e9baa Cool implementationd94e78 Prepare the workbench for feature Z6394dc Feature Y --- older commit 然后这是我要做的事情： 12345678871adf OK, feature Z is fully implemented --- newer commit --┐0c3317 Whoops, not yet... |87871a I'm ready! |643d0e Code cleanup |-- Join these into oneafb581 Fix this and that |4e9baa Cool implementation |d94e78 Prepare the workbench for feature Z -------------------┘6394dc Feature Y --- older commit 要达到的效果： 1284d1f8 Feature Z --- newer commit (result of rebase)6394dc Feature Y --- older commit 所以在这个案例中，要执行的命令就是： 1git rebase --interactive HEAD~[7] 因为我想将最后的 7 次提交合并为一次，所以 d94e78 Prepare the workbench for feature X 就是第 7 次提交。 我有数不清的提交要压缩，必须一个一个的数吗？git rebase --interactive HEAD~[N] 命令的缺点就是你必须一个一个的数出准确的提交次数。幸运的是这里还有另一种方式： 1git rebase --interactive [commit-hash] [commit-hash] 就是你要压缩的提交范围的起始提交之前的一次提交的 hash。所以在我的示例中的命令就是： 1git rebase --interactive 6394dc 6394dc 是 Feature Y。你可以将这个命令理解为： 对 [commit-hash] 之上的所有提交进行合并。 这样更简单不是吗？ 步骤 2: 选择与压缩这时你的编辑器会有弹窗，显示出你想要合并的提交列表。注意，一开始可能会感觉有点看不明白，因为是按反序排列的，旧的提交显示在顶部。我通过 --- older commit 和 --- newer commit 进行了说明，在编辑器的窗口中不会显示说明。 123456789pick d94e78 Prepare the workbench for feature Z --- older commitpick 4e9baa Cool implementation pick afb581 Fix this and that pick 643d0e Code cleanuppick 87871a I'm ready! pick 0c3317 Whoops, not yet... pick 871adf OK, feature Z is fully implemented --- newer commit[...] 在提交列表的底部有一个简短的注释（示例中忽略了），提示了所有的操作选项。你可以在交互式 rebase 中进行各种操作，我们现在只进行一些基本的操作。我们的任务是将所有的提交注释为 squashable，除了第一个（最早的）提交：它将被用作起始点。 你可以通过将任务 pick 修改为 squash （或者简写为 s ，评论中有提示）来将提交标记为 squashable 。最后的结果就是： 123456789pick d94e78 Prepare the workbench for feature Z --- older commits 4e9baa Cool implementation s afb581 Fix this and that s 643d0e Code cleanups 87871a I'm ready! s 0c3317 Whoops, not yet... s 871adf OK, feature Z is fully implemented --- newer commit[...] 保存文件，关闭编辑器。 步骤 3: 创建新的提交你刚刚告诉了 Git 将全部的 7 次提交合并到列表的第一个提交中。现在要给它添加注释：你的编辑器会再次弹出一个带有默认消息的窗口，内容是压缩的所有提交的注释。 你可以保留默认的提交注释，这样最终的提交信息将会是这些临时提交的注释列表，如下所示： 1234567Prepare the workbench for feature ZCool implementation Fix this and that Code cleanupI'm ready! Whoops, not yet... OK, feature Z is fully implemented 通常我不喜欢保留这些信息，所以我会清楚默认消息，使用一些自定义注释，例如 Implemented feature Z。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字体设计基础(1)视觉均衡]]></title>
    <url>%2F2019%2F04%2F03%2F%E5%AD%97%E4%BD%93%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80-1-%E8%A7%86%E8%A7%89%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[字体设计基础 【字体设计基础】系列翻译自 typeworkshop.com，每篇文章都配有精美的插图，用于解释设计字体时会遇到的一些基础的问题。这些内容只解释了一些基础概念，不会深入讨论复杂的内容。 Same size for all! To optically align all characters on a line, they cannot not have exactly the same mathematical height. For example the triangle on this drawing has to be higher than the rectangle. If this is not the case, the triangle will for sure look smaller than the rectangle. While creating a typeface, you want all the letters to have the same height. 一视同仁！！为了让所有字体在视觉上对齐，它们就不能采用恰恰相同的尺寸。比如说，上图中的三角形必须的高度必须大于矩形。否则，三角形就会看起来比矩形小。在设计字体的时候，我们往往想要所有的字母定义同样的高度。 Also round forms have to exceed the baseline to be optically the same. If the circle would have exactly the same mathematical height as the rectangle, it would look smaller than the square. This doesn’t only count for basic forms like triangles, circles and squares. It’s essential in type design, because they apply to every single character in a typeface. Then it even doesn’t matter if you’re designing a latin, cyrillic or greek font. It’s a basic principle for any kind of shape. 同样的，为了使圆形看起来和矩形相同大小，就必须得让圆形超出基线。如果圆形的高度和矩形完全相同，就会看起来比方形更小。这种情况不仅适用于像三角形，圆形和方块这样的基本形状。这是字体设计的基本原则，整个字体中的所有字符都适用这套原则。甚至不论你正在设计拉丁，斯拉夫还是希腊字体，这种效果都同样适用。这是所有形体都必须遵循的基本原则。]]></content>
      <categories>
        <category>翻译</category>
        <category>字体</category>
      </categories>
      <tags>
        <tag>字体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 VSCode 调试 React]]></title>
    <url>%2F2019%2F04%2F02%2F%E7%94%A8-VSCode-%E8%B0%83%E8%AF%95-React%2F</url>
    <content type="text"><![CDATA[我终于不用再花时间在终端，浏览器和编辑器之间往返来回了。难道不是所有人都在这么做吗？ 在这篇教程中我会教你用 Visual Studio Code 的 debug 功能为你的 React 工作流赋能。你会学到如何如何将 VSCode 和 Chrome 连接起来，这样你就可以做到直接从 VSCode 调试浏览器中的代码了😎 准备测试项目在开始教程之前我们需要创建一个测试应用，后面将会用到。我尝尝适用 create-react-app 因为我不喜欢写模板。如果你已经有一个应用程序了你也可以就用它。 首先创建测试应用： 执行 npm i -g create-react-app 命令，在全局安装 create-react-app 安装成功后，运行命令 create-react-app vscode-tutorial 创建一个新项目 完成后会创建一个包含新的 React 应用程序的目录。 设置 VSCodeNext up we need to install the VSCode extension so it knows how to talk to Chrome. VSCode connects to Chrome through Chrome’s debugger protocol. This is the same debugger protocol that Chrome’s developer tools use. Instead of using Chrome’s developer tools you can use VSCode to debug browser code. 接下来我们需要安装 VSCode 扩展，通过扩展来和 Chrome 通信。VSCode 通过 Chrome 的 debugger 协议 来连接到 Chrome。这个协议与 Chrome 开发者工具使用的协议相同。你可以用 VSCode 取代 Chrome 的开发者工具来调试浏览器代码。 安装 Chrome Debugger 扩展工具To get VSCode and Chrome communicating with each other we need to install an extension called Debugger for Chrome. Install it by navigating to the extensions pane and searching for: debugger for chrome. It should look similar to below: 为了让 VSCode 和 Chrome 之间相互通信，我们需要安装一个叫作 Debugger for Chrome 的扩展。通过导航到 VSCode 的扩展面板，搜索 Debugger for Chrome 。它应该看起来与下图相似。 设置 VSCode 连接到 Chrome接下来我们需要设置 VSCode 来让它连接到 Chrome。 点击 debugging 图标 点击下拉菜单（在运行按钮旁），然后点击“添加配置…” 从“选择环境”下拉菜单中选择“Chrome” 这一步完成后会自动在你的工程根目录下新建一个 .vscode 目录。目录将会包含一个 launch.json 文件，它将被用来配置你当前工程下的 VSCode 的 debugger 。每次创建一个新的项目时，你都必须按照相同步骤来设置远程 debug（或者拷贝之前项目的 .vscode 目录到新项目中） 修改 url 属性，将其只想开发服务器的 URL。对与 create-react-app 来说，这个 URL 是 http://localhost:3000 。 完整的配置选项列表可以 在这里找到。 运行调试器不要着急，我们快要完成了。接下来我们需要用到我们的测试项目来测试 debugger 是否正常工作。 打开调试器你可以通过下面的几种方式来打开调试器： 按 F5 在调试面板中按绿色的运行按钮 从菜单运行： Debug &gt; Start Debugger 设置一个断点断点是用来告诉调试器，当代码执行到指定的位置时暂停执行。这样你就可以查看变量，回调函数，甚至在应用程序运行的时候修改代码。 这一步，我们在代码 src/App.js 的第 11 行设置一个断点。 启动一个开发服务器最后要看是否能成功，通过在终端运行 npm start 来启动开发服务器。这会启动一个新的服务器，可以通过地址 http://localhost:3000/ 访问。 导航到 http://localhost:3000/，然后你应该能看到页面“冻结”了。这是因为应用程序命中了断点。如果你切换回 VSCode 中去看，你会注意第 11 行代码高亮了，并且调试面板也更新了能够反应出调用栈。 如果一切运行成功，那么恭喜你！你已经学会了如何设置 VSCode 远程调试。如果想要了解更多关于 VSCode 调试的知识，可以看看这里]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[撤销一个 git commit --amend]]></title>
    <url>%2F2019%2F03%2F29%2F%E6%92%A4%E9%94%80%E4%B8%80%E4%B8%AA-git-commit-amend%2F</url>
    <content type="text"><![CDATA[可能会碰到这样的情况，你想要将本该在 HEAD 之前提交的修改通过 git commit --amend 提交追加到 HEAD 上了。这样，就需要回滚你刚刚完成的操作，然后将它应用到正确的提交上。对于简单的修改，你可能会发现 git reset -p 很方便。很多情况下修改的内容太多，并且和前面的提交交织在一起，你可能会需要 git reflog 帮忙。 reflog 记录分支顶端的更新。顶端会在你每次创建新的提交，追加提交，重置提交，切换分支等等操作的时候被更新。基本上，一旦 HEAD 发生了变化，就会生成一次 reflog 记录。因此 reflog 是理解仓库如何进入特定状态的强大工具。 git reflog -2 会给你 Git 最近两次完成的操作。这种情况下，看起来就像下面： 128751261 HEAD@&#123;0&#125;: commit (amend): Something something something commit message9d3a192 HEAD@&#123;1&#125;: reset: moving to HEAD~1 git commit --amend 是一种简写（考虑修改已经产生，不在索引区就在工作目录中）： 12345git stashgit reset HEAD~1git stash popgit add .git commit 或者用文字描述： 将你想要应用到 HEAD 提交中的修改保存到 stash 中 移除 HEAD 提交，将内容放置到索引区 将暂存起来的修改释放到工作目录，添加到刚刚被重置的提交的修改中。 执行一个新的提交。 因此，reflog 中的最后两部操作是 reset 和 commit。 所以，我们能用它做什么？好吧，在 amend（尤其是在 reset 之前）发生之前，9d3a192 是 HEAD。8751261是在 amend 操作之后生成的提交。git diff 8751261..9d3a192 将会向你展示 amend 中应用了什么修改。 从这里开始，你可以用 git apply 来将 amend 之前到 amend 之后的差异应用到你的工作树，通过 git diff： 1git diff 8751261..9d3a192 | git apply - Note: The hyphen in git apply - causes git apply to take stdin as input. Extra Note: The arguments here are given in reverse order, with the later commit happening first to show the reverse of the amend. It’s the same as doing git diff 9d3a192..8751261 -R, which reverses the diff output. Additionally, the -R argument may be applied to git apply instead of git diff to achieve the same effect. Now we can do another amend to put the commit back to where it was before we did the previous amend: 1git commit -a --amend -CHEAD And then, by reversing the order of the SHAs to git diff, get the changes we want to apply to the correct commit back: 1git diff 9d3a192..8751261 | git apply - And commit as necessary, this time using –fixup to indicate the correct commit (in this example, 1234567): 1git commit -a --fixup 1234567 Then you can rebase at a later time (or now) to do the ‘amend’ you had originally intended: 1git rebase --i --autosquash 1234567~1 So don’t fret when you do an accidental amend. It’s just a couple commands away from being unwound and applied to the correct commit.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitFlow 工作流]]></title>
    <url>%2F2019%2F03%2F26%2FGitFlow-%E5%B7%A5%E4%BD%9C%E6%B5%81%2F</url>
    <content type="text"><![CDATA[原文– Gitflow Workflow Gitfow 工作流是一个 Git 工作流设计，第一次是被 Vincent Driessen at nvie 发布并收到欢迎。Gitflow 工作流 定义了一个严格围绕项目发布的分支模型。它提供了一个用于管理大型项目的稳定框架。 Gitflow 完美地适合于具有计划性发布周期的项目。这种工作流不会添加任何超出 特性分支工作流 所需范围之外的新概念或者命令。相反，它为不同分支分配了非常详细的角色，并且定义了如何以及合适他们应该交互。除了 feature 分支，它为准备阶段，维护阶段和记录版本阶段使用了独立的分支。当然，你也可以充分利用所有特性分支工作流的优势：拉取请求，独立实验，以及更多高效合作。 开始Gitflow 真的只是 Git 工作流的一个抽象理念。这意味着它指示了应该创建什么类型的分支以及如何合并他们。我们将会触及下面这些分支的墓地。git-flow 工具集是一个命令行工具，需要安装。git-flow 的安装过程很简单。各个操作系统平台都有对应的 git-flow 安装包。在 OSX 系统中，你可以执行 brew install git-flow 。在 Windows 上你需要下载并安装 git-flow 。安装完成后，你可以在你的项目中执行 git flow init 来使用它。Git-flow 内部封装了 Git 。git flow init 命令是对默认 git init 的扩展，除了为你创建分支外，不会对你的仓库作出任何修改。 它如何工作.svg) Develop 和 Master 分支这个工作流使用两个分支来记录项目历史，而不是用一个单独的 master 分支。master 分支保存了正式发布历史，develop 分支用于集成特性分支。可以很方便地为 master 分支上的所有提交打上一个数字的版本标记。 第一步就是从 master 分支上新建出 develop 分支。一个简单的方法就是在本地新建一个空的 develop 分支，然后将它同步到服务器： 12git branch developgit push -u origin develop 这个分支将会包含项目的完整历史，而 master 分支将会包含一个简略的版本历史。其他开发者现在应该 clone 中心仓库，然后创建一个 develop 的跟踪分支。 当使用 git-flow 扩展库时，对一个已存在的仓库执行 git flow init 将会创建 develop 分支： 12345678910111213141516$ git flow initInitialized empty Git repository in ~/project/.git/No branches exist yet. Base branches must be created now.Branch name for production releases: [master]Branch name for "next release" development: [develop]How to name your supporting branch prefixes?Feature branches? [feature/]Release branches? [release/]Hotfix branches? [hotfix/]Support branches? [support/]Version tag prefix? []$ git branch* develop master 特性分支每一个新的特性都应该有自己的分支，这样就可以被 push 到中心仓库达到备份/协作的目的。但是，feature 分支是将 develop 分支作为他们的父亲分支，而不是从 master 开辟分支。当一个特性开发完成后，它将会被 merge 回到develop分支中。特性分支应该永远不要和 master 分支交互。 .svg) 注意，无论出于什么目地，feature 分支与 develop 分支的结合就是特性分支工作流。但是 Gitflow 工作流还没有止步于此。 feature 分支通常从最新的 develop 分支创建。 创建一个特性分支没有 git-flow 扩展的情况下： 12git checkout developgit checkout -b feature_branch 使用 git-flow 扩展的情况： 1git flow feature start feature_branch 继续你的工作，并且像往常一样使用 Git。 结束一个特性分支当你完成了特性的开发工作，下一步就是将 feature_branch merge 到 develop 中。 不使用 git-flow 扩展： 12git checkout developgit merge feature_branch 使用 git-flow 扩展： 1git flow feature finish feature_branch 发布分支.svg) 一旦 develop 分支获取的特性足够发布一个版本了（或者快到了预定的发布日期），你就从 develop 分支开辟一个 release 分支。创建这个分支启动下一个发布周期，所有从这时开始不允许新特性加入进来——只允许 bug 修复，文档生成，以及其他面向发布的任务可以进入到这个分支中来。一旦准备好，release 分支就会被merge 到 master 分支中，并打上一个数字版本号。另外，它也应该被合并回 develop 中，在创建 release 分支以后，develop 分支可能会有推进。 使用一个专用的分支用于准备发布，这样就可以让一个团队来准备当前的发布，同时让另一个团队继续为下一个版本开发新特性。这也为开发创建了明确的阶段（例如，这样就很容易说 “这周我们准备 4.0 版本”，也很容易在仓库的结构中看到） 创建 release 分支是另一项直接的分支操作。就像 feature 分支，release 分支是基于 develop 分支的。一个新的 release 分支可以使用下面的方法创建。 不适用 git-flow 扩展： 12git checkout developgit checkout -b release/0.1.0 使用 git-flow 扩展： 12$ git flow release start 0.1.0Switched to a new branch 'release/0.1.0' 一旦新版本准备好了要发布，它将被合并到 master 和 develop 中，然后 release 分支将被删除。合并回 develop 分支是很重要的，因为可能有重要更新已经被添加到了 release 分支，他们也许要被新的特性使用到。如果你的团队重视代码重审，这是发起 pull request 理想时机。 结束一个 release 分支，要使用以下方法： 不使用 git-flow 扩展： 12git checkout mastergit merge release/0.1.0 使用 git-flow 扩展： 1git flow release finish '0.1.0' 修补分支.svg) 维护或者 hotfix 分支被用于快速修补生产版本。 hotfix 分支很像 release 分支与 feature 分支，除了他们是基于 master 分支 而不是 develop 分支。这是唯一一个应该直接从 master 分支开辟的分支。一旦 fix 完成了，它应该被 merge 回 master 和 develop （或者当前 release 分支），master 应该用一个更新的数字版本标记。 有一个专用的开发线用于 bug fix 可以让你的团队在不中断其余工作流程或等待下一个发布周期的情况下解决问题。你可以将维护分支视为直接与 master 分支协作的临时 release 分支。可以用下面的方法创建一个 hotfix 分支： 使用 git-flow 工作流： 12git checkout mastergit checkout -b hotfix_branch 不使用 git-flow 工作流： 1$ git flow hotfix start hotfix_branch 与结束 release 分支类似，hotfix 分支要被 merge 回到 master 和 develop 中。 123456git checkout mastergit merge hotfix_branchgit checkout developgit merge hotfix_branchgit branch -D hotfix_branch$ git flow hotfix finish hotfix_branch 示例下面是一个特性分支工作流的完整演示示例。假设我们已经有一个具备 master 分支的仓库。 123456789git checkout mastergit checkout -b developgit checkout -b feature_branch# work happens on feature branchgit checkout developgit merge feature_branchgit checkout mastergit merge developgit branch -d feature_branch 除了 feature 和 release 流程，下面还有一个 hotfix 的示例： 1234567git checkout mastergit checkout -b hotfix_branch# work is done commits are added to the hotfix_branchgit checkout developgit merge hotfix_branchgit checkout mastergit merge hotfix_branch 总结这里我们讨论了 Gitflow 工作流。Gitflow 是你和团队能够使用的众多 Git 工作流 之一。 关于 Gitflow 需要了解的关键点有这些： 这个工作流适合基于版本的软件开发工作流。 Gitflow 为生产环境提供了 hotfix 通道。 Gitflow 的完整流程如下： 从 master 创建一个 develop 分支 从 develop创建一个 release 分支 从 develop 创建 feature 分支 当一个 feature 开发结束，将被 merge 到 develop 分支 当 release 分支完成，将被 merge 到 develop 和 master 如果在 master 中发现问题，要从 master 创建一个 hotfix 分支 一旦 hotfix 完成，将被 merge 回 develop 和 master]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十分钟介绍 MobX 和 React]]></title>
    <url>%2F2019%2F03%2F24%2F%E5%8D%81%E5%88%86%E9%92%9F%E4%BB%8B%E7%BB%8D-MobX-%E5%92%8C-React%2F</url>
    <content type="text"><![CDATA[原文：Ten minute introduction to MobX and React MobX 是一个简单的，可扩展并且经过实战考研的状态管理解决方案。这篇教程将会花10分钟时间教会你关于 MobX 的全部重要概念。MobX 是一个独立的库，但是大多数人会将它和 React 组合使用，本篇教程也将关注这种组合的用法。 核心概念状态是每个应用程序的核心，没有比使用不一致的状态，或者四处分散且不能同步的本地变量组成的状态更容易创造出充满错误和不可管理的应用程序了。因此很多状态管理解决方案都会限制修改状态的方式，例如使用不可变状态。但是这样做会引入新的问题；数据需要规范化，参照完整性就不能得到保证，于是就不再可能使用像原型这样强大的概念。* MobX 通过解决了根本问题使得数据管理再次变得简单：它保证了不可能创造出不一致状态。实现的策略很简单：确定一切能够从应用程序的状态继承的，都将从应用程序的状态继承。并且自动完成继承。 概念上，MobX 对待你的应用程序与电子表格类似。 首先，应用程序中有 state（状态）。即构成应用程序的数据模型中的对象，数组，基础值，引用组成的图表。这些值是你应用程序的数据单元 然后有 derivations（求导）。基本上是指所有能够根据应用程序的 state 自动计算出的值。这些 derivation， 或者计算值的范围可以是从简单值类型，例如未完成的 todo 数量，到复杂类型例如 todo 的可视化 HTML 表示。电子表格中的等价物：那些公式和应用程序的图表。 Reaction（反应）和 derivation 十分相似。主要的差异在于 react 不会创造得出一个值，而是通过自动运行来执行一些任务。通常是 I/O 相关的。它们用来确定 DOM 被更新，或者网络请求会在正确的时间自动执行等。 最后是 action（动作）。action 是所有能够改变状态的东西。MobX 将会确保所有通过 ation 对状态所做的修改都能自动被所有的 derivation 和 reaction 处理。同步并且无干扰。 一个简单的 todo store原理说得够多了，实践操作一下可能会比认真阅读上面那些东西学到更多。为了从头开始，我们先创建一个非常简单的 ToDo store。注意下方的所有代码块都是可编辑的，点击 run code 按钮执行代码。下面是一个非常直接的 TodoStore ，用来管理一个 todo 集合。还没有引入 MobX。 1234567891011121314151617181920212223242526class TodoStore &#123; todos = []; get completedTodosCount() &#123; return this.todos.filter( todo =&gt; todo.completed === true ).length; &#125; report() &#123; if (this.todos.length === 0) return "&lt;none&gt;"; return `Next todo: "$&#123;this.todos[0].task&#125;". ` + `Progress: $&#123;this.completedTodosCount&#125;/$&#123;this.todos.length&#125;`; &#125; addTodo(task) &#123; this.todos.push(&#123; task: task, completed: false, assignee: null &#125;); &#125;&#125;const todoStore = new TodoStore(); 我们创建了一个 todoStore 的实例，实例中包含了 todo 的集合。给这个 todoStore 添加一些对象。为了确保看到修改的效果，我们在每次改变之后调用 todoStore.report 来输出日志。注意 report 故意始终只打印第一个任务。这使得这个例子非常人工，但是你将会在下面看到它能很好地证明 MobX 的依赖追踪是多么的动态。 1234567891011121314todoStore.addTodo("read MobX tutorial");console.log(todoStore.report());todoStore.addTodo("try MobX");console.log(todoStore.report());todoStore.todos[0].completed = true;console.log(todoStore.report());todoStore.todos[1].task = "try MobX in own project";console.log(todoStore.report());todoStore.todos[0].task = "grok MobX tutorial";console.log(todoStore.report()); 变得响应式目前，这部分代码还没有什么特别之处。但是如果我们不必显示执行 report ，而是可以只用声明我们想要它在每一次状态改变时都被触发执行呢？这样能够将我们从负责在代码库中任何可能影响 report 结果的地方调用 report 的工作中解放出来。我们只需要确定最后的 report 被打印出来。但是不想花费精力来维护部分代码。 幸运的是这正是 MobX 能够为你做的。自动执行代码只取决于状态。所以我们的 report 方法自动更新，就像电子表格中的图表一样。为了实现这一点，TodoStore 必须变成可观察的，这样 MobX 就能够追踪所有产生的修改。我们修改一下这个类来实现这样的功能。 同样，completedTodosCount 属性可以自动从 todo 列表继承。通过使用 @observable 和 @computed 装饰器，我们能够在一个对象中引入可观察属性： 1234567891011121314151617181920212223242526272829303132class ObservableTodoStore &#123; @observable todos = []; @observable pendingRequests = 0; constructor() &#123; mobx.autorun(() =&gt; console.log(this.report)); &#125; @computed get completedTodosCount() &#123; return this.todos.filter( todo =&gt; todo.completed === true ).length; &#125; @computed get report() &#123; if (this.todos.length === 0) return "&lt;none&gt;"; return `Next todo: "$&#123;this.todos[0].task&#125;". ` + `Progress: $&#123;this.completedTodosCount&#125;/$&#123;this.todos.length&#125;`; &#125; addTodo(task) &#123; this.todos.push(&#123; task: task, completed: false, assignee: null &#125;); &#125;&#125;const observableTodoStore = new ObservableTodoStore(); 就是它！我们将一些属性标记为 @observable 来通知 MobX 这些值可能随时变化。计算用 @computed 装饰以标识这些可以从 state 继承。 pendingRequests 和 assignee 属性目前还没有使用，但是会在这个教程的后面的部分用到。为了简洁，本页的所有示例都是用 ES6，JSX 和装饰器。但是不用担心，MobX 中的所有装饰器在 ES5 中都有对等的概念。 在构造函数中，我们创建了一个用来打印 report 的方法，并用 autorun包裹起来。Autorun 创建一个运行一次的 reaction，创建之后每当应用程序内部使用的任意可观察数据发生改变时自动再次执行。因为 report 使用了 可观察的 todos 属性，它将会在任何合适的时候打印 report 。下一个列表中会证实这一点。点击 run 按钮运行代码： 12345observableTodoStore.addTodo("read MobX tutorial");observableTodoStore.addTodo("try MobX");observableTodoStore.todos[0].completed = true;observableTodoStore.todos[1].task = "try MobX in own project";observableTodoStore.todos[0].task = "grok MobX tutorial"; 很有趣对吧？report 自动地，同步地打印出来，不会泄漏中间值。如果仔细观察日志，你会发现第四行没有产生新的日志行。因为 report 没有因为重命名而真正地改变，尽管后端的数据的确改变了。另一方面，改变第一条 todo 的名称的确更新了 report，因为更新的名称出现在了 report 中。这很好地证明了不只是 todos 数组被 autorun 观察了，todo 数组元素的内部属性也被观察了。 让 React 变得响应式好的，目前我们实现了一个很蠢的响应式 report。是时候用这个同样的 store 实现一个响应式的用户界面了。React 组件（不管名字如何）并不是开箱即用的响应式。mobx-react 包中的 @observer 装饰器通过将 React 组件的 render 方法包裹在 autorun 中解决了这个问题，自动保持组件与 state 同步。这在概念上和我们前面处理 report 的方式没什么不同。 下面的清单定义了一些 React 组件。其中唯一与 MobX 有个的东西就是 @observer 装饰器。这些就足以保证每个组件在数据发生变化时能够独立完成重渲染。你不再需要调用 setState ，也不需要搞清楚如何使用选择期或者需要配置的高阶组件来订阅应用程序状态的正确部分。基本上所有的组件都变得更加聪明了。然而他们是以一种愚蠢的陈述性的方式声明的。 点击 run code 按钮来看看下面代码的运行结果。下面的代码列表是可编辑的，所以请随意玩耍。可以试试移除所有的 @observer 调用，或者只移除装饰 TodoView 的那个。右边预览区域的数字会在每次组件重新渲染时高亮。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@observerclass TodoList extends React.Component &#123; render() &#123; const store = this.props.store; return ( &lt;div&gt; &#123; store.report &#125; &lt;ul&gt; &#123; store.todos.map( (todo, idx) =&gt; &lt;TodoView todo=&#123; todo &#125; key=&#123; idx &#125; /&gt; ) &#125; &lt;/ul&gt; &#123; store.pendingRequests &gt; 0 ? &lt;marquee&gt;Loading...&lt;/marquee&gt; : null &#125; &lt;button onClick=&#123; this.onNewTodo &#125;&gt;New Todo&lt;/button&gt; &lt;small&gt; (double-click a todo to edit)&lt;/small&gt; &lt;RenderCounter /&gt; &lt;/div&gt; ); &#125; onNewTodo = () =&gt; &#123; this.props.store.addTodo(prompt('Enter a new todo:','coffee plz')); &#125;&#125;@observerclass TodoView extends React.Component &#123; render() &#123; const todo = this.props.todo; return ( &lt;li onDoubleClick=&#123; this.onRename &#125;&gt; &lt;input type='checkbox' checked=&#123; todo.completed &#125; onChange=&#123; this.onToggleCompleted &#125; /&gt; &#123; todo.task &#125; &#123; todo.assignee ? &lt;small&gt;&#123; todo.assignee.name &#125;&lt;/small&gt; : null &#125; &lt;RenderCounter /&gt; &lt;/li&gt; ); &#125; onToggleCompleted = () =&gt; &#123; const todo = this.props.todo; todo.completed = !todo.completed; &#125; onRename = () =&gt; &#123; const todo = this.props.todo; todo.task = prompt('Task name', todo.task) || todo.task; &#125;&#125;ReactDOM.render( &lt;TodoList store=&#123; observableTodoStore &#125; /&gt;, document.getElementById('reactjs-app')); 下面的代码很好地展示了我们除了更新数据以外不需要做其他任何事情。MobX 将会自动地从 store 中的状态继承并更新用户界面。 12345const store = observableTodoStore;store.todos[0].completed = !store.todos[0].completed;store.todos[1].task = "Random todo " + Math.random();store.todos.push(&#123; task: "Find a fine cheese", completed: true &#125;);// etc etc.. add your own statements here... 使用引用上面我们已经创建了可观察对象（基于原型的对象和纯对象），数组和基础值。你可能想知道，MobX 中如何处理引用？我的状态能否形成一个图？在前面的清单中你可能已经注意到了 todos 中包含了 assignee 属性。我们通过引入另一个包含了people的 “store“ （好吧，这只是一个美化的数组）来给他们赋值，然后分派任务给他们。 1234567var peopleStore = mobx.observable([ &#123; name: "Michel" &#125;, &#123; name: "Me" &#125;]);observableTodoStore.todos[0].assignee = peopleStore[0];observableTodoStore.todos[1].assignee = peopleStore[1];peopleStore[0].name = "Michel Weststrate"; 我们现在有两个独立的 store 了。一个包含了 people，一个包含了 todos。当我们将一个 assignee 指配给一个 people store 中的人时，我们只是指配了一个引用。这些改变回自动被 TodoView 获取。有了 MobX 以后就不用先对数据进行标准化也不用写选择器来保证组件被更新。事实上 store 中保存的数据是什么都不重要了。只要对象被变成了可观察的，MobX 就能够追踪他们。真正的 JavaScript 引用将起作用。如果他们是和 derivation 有关系的，那么 MobX 将会自动追踪他们。为了测试这一点，试试在下面的的输入框内改变你的名字（要确保先点击了上面的 run code 按钮） Your name: 顺便一提，上面输入框的 HTML 很简单： 1&lt;input onkeyup=&quot;peopleStore[1].name = event.target.value&quot; /&gt; 异步 action因为我们的 Todo 应用程序中的每一部分都是从 state 派生出的，所以 state 什么时候改变都不重要。这使得创建异步 action 非常直接。直接点击下面的按钮（多次点击）来模仿异步加载新的 todo 项： Load todo 这部分背后的代码也相当直接。我们从更新 store 属性 pendingRequests 开始来让 UI 反应出当前加载状态。一旦加载结束，我们就更新 store 中的 todos，并且减少 pendingRequests 计数器。直接对比这个代码段和前面的 TodoList 定义来看看 pendingRequests 是如何运用的。 12345observableTodoStore.pendingRequests++;setTimeout(function() &#123; observableTodoStore.addTodo(&apos;Random Todo &apos; + Math.random()); observableTodoStore.pendingRequests--;&#125;, 2000); 开发工具mobx-react-devtools 提供了开发工具，显示在屏幕的右上方并且可以被任意 MobX + ReactJS 应用使用。点击第一个按钮将会高亮每一个正在被重渲染的 @observer 组件。如果点击第二个按钮，然后再点击预览中的任意一个组件，这个组件的依赖树就会显示出来，这样你可以准确地观察任意给定时刻正在被观察的数据。 结论以上就是全部了！没有反复套用的模板。只是一些组成我们的整个 UI 的简单的，声明式的组件。这些组件都是完全地，响应式地从我们的 state 中派生出来的。你现在可以在你的应用程序中使用 mobx 和 mobx-react 了。学到这里简单的总结一下： 使用 @observable 装饰器或者 observable(object 或者 array) 方法来为 MobX 创建出可追踪对象。 @computed 装饰器可以被用来创建能够自动从 state 中派生出值的方法。 使用 autorun 来自动运行依赖于一些 ovservable state 的方法。这对于输出日志，发起网络请求等是很有用的。 使用 mobx-react 中的 @observer 装饰器来让你的 React 组件变得真正响应式。他们将会自动并且高效地更新。即使应用于具有大量数据的大型复杂应用。 可以随意调试上面的可编辑代码块来感受一下 MobX 是如何对你的修改作出反应的。例如你可以在 report 方法被调用时添加日志描述。或者完全不显示 report 看看是如何影响 TodoList 渲染的。或者只在特定情况下显示。 MobX 不是一个状态容器人们镜常用 MobX 来替代 Redux。 但是请注意 MobX 只是用来解决一个技术问题的库，不是一个框架，甚至内部没有包含状态容器。从这个意义上来说，上面的例子都是人为的。建议使用适当的工程实践，例如在方法中封装逻辑，在 store 或者 controller 中组织他们等等。或者如 HackerNews 所述： “MobX, it’s been mentioned elsewhere but I can’t help but sing its praises. Writing in MobX means that using controllers/ dispatchers/ actions/ supervisors or another form of managing dataflow returns to being an architectural concern you can pattern to your application’s needs, rather than being something that’s required by default for anything more than a Todo app.” Learn moreIntrigued? Here are some useful resources: MobX on GitHub Api documentation (Blog) Making React reactive: the pursuit of high performing, easily maintainable React apps (Blog) Becoming fully reactive: an in-depth explanation of Mobservable JSFiddle with a simple todo app MobX, React, TypeScript boilerplate MobX, React, Babel boilerplate MobX demo from Reactive2015 conference MobX + React TodoMVC]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么没有CSS4，解释CSS level]]></title>
    <url>%2F2019%2F03%2F21%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B2%A1%E6%9C%89CSS4%EF%BC%8C%E8%A7%A3%E9%87%8ACSS-level%2F</url>
    <content type="text"><![CDATA[原文– Where there is no CSS4 - explaining CSS Levels ​ 我们已经有了 CSS1 和 CSS2，我们甚至还有过 CSS2.1，后来我们接着有了 CSS3，CSS3 真的存在吗？这篇文章将会快速介绍当今 CSS 是如何制定版本号的。 ​ CSS 版本 1 和 2 都是属于单体声明。即 CSS 中所有概念都被包含在一个庞大的文档中。Selector，Position，Colour — 全部都在其中。 ​ 单体声明有一个问题，就是为了结束一个规范的版本，必须要所有的组件都一起完成该版本的修订。但是随着 CSS 的发展变得越来越复杂了，新特性不断添加进来，为了制定一个 CSS 版本而让所有部分都停工作，这样没有任何意义。因此 CSS2.1 之后，就将 2.1 版本规范中的所有部分都被拆分成了模块。旧特性组成的 CSS 模块加上新添加的特性，都将出现在 Level 3 中。于是和我一样将 CSS 理解为一个单体规范的人们就将这一组 Level 3 模块称之为 “CSS3”。 ​ 然而将所有新的 CSS 特性称之为 CSS3 并没有反映出如今 CSS 的本质。如果你阅读过一些关于 CSS3 选择器的文章，那么你可能知道 CSS3 选择器实际上就是 CSS Selectors Level 3 规范的一部分。事实上 CSS 选择器是标记为已完成和推荐的规范之一。CSS 工作组目前正在制定 Selectors Level 4，它由一些新提议的特性加上 Level 3（以及 CSS 1 和 2 ）的一部分选择器组成。是 CSS 规范的一小部分。 ​ 我们已经有一些为特性制定的规范，这些特性不属于 CSS 1 和 2 的一部分，所以这些特性的规范现在就是 Level 1。他们都是全新的。Level 1 的特性规范的例子有 CSSGrid Layout and Flexbox 。Flexbox 已经是一个候选推荐（CR，Candidate Recommendation）的规范了，Grid 也已经被投票参选 CR 了。因此从现在起提议的任何新特性都将可能出现在下一个 Level 的规范中 — Flexbox Level 2 和 CSS Grid Level 2。 ​ 如果你想看看各种 CSS 特性的状态，以及他们当前所在的 level，可以查看 CSS 工作组 Current Work document 。为了理解一个规范的不同状态，可以看看工作进展文档中 Maturity Levels 上的信息。]]></content>
      <categories>
        <category>FE</category>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>Layout</tag>
        <tag>CSS布局</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JS原型]]></title>
    <url>%2F2019%2F02%2F27%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JS%E5%8E%9F%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本文不会过多介绍基础知识，而是把重点放在原型的各个难点上。 大家可以先仔细分析下该图，然后让我们进入主题 prototype首先来介绍下 prototype 属性。这是一个显式原型属性，只有函数才拥有该属性。基本上所有函数都有这个属性，但是也有一个例外 1let fun = Function.prototype.bind() 如果你以上述方法创建一个函数，那么可以发现这个函数是不具有 prototype 属性的。 prototype 如何产生的当我们声明一个函数时，这个属性就被自动创建了。 1function Foo() &#123;&#125; 并且这个属性的值是一个对象（也就是原型），只有一个属性 constructor constructor 对应着构造函数，也就是 Foo。 constructorconstructor 是一个公有且不可枚举的属性。一旦我们改变了函数的 prototype ，那么新对象就没有这个属性了（当然可以通过原型链取到 constructor）。 那么你肯定也有一个疑问，这个属性到底有什么用呢？其实这个属性可以说是一个历史遗留问题，在大部分情况下是没用的，在我的理解里，我认为他有两个作用： 让实例对象知道是什么函数构造了它 如果想给某些类库中的构造函数增加一些自定义的方法，就可以通过 xx.constructor.method 来扩展 _proto_这是每个对象都有的隐式原型属性，指向了创建该对象的构造函数的原型。其实这个属性指向了 [[prototype]]，但是 [[prototype]] 是内部属性，我们并不能访问到，所以使用 _proto_ 来访问。 因为在 JS 中是没有类的概念的，为了实现类似继承的方式，通过 _proto_ 将对象和原型联系起来组成原型链，得以让对象可以访问到不属于自己的属性。 实例对象的 _proto_ 如何产生的从上图可知，当我们使用 new 操作符时，生成的实例对象拥有了 _proto_属性。 1234function Foo() &#123;&#125;// 这个函数是 Function 的实例对象// function 就是一个语法糖// 内部调用了 new Function(...) 所以可以说，在 new 的过程中，新对象被添加了 _proto_ 并且链接到构造函数的原型上。 new 的过程 新生成了一个对象 链接到原型 绑定 this 返回新对象 在调用 new 的过程中会发生以上四件事情，我们也可以试着来自己实现一个 new 123456789101112function create() &#123; // 创建一个空的对象 let obj = new Object() // 获得构造函数 let Con = [].shift.call(arguments) // 链接到原型 obj.__proto__ = Con.prototype // 绑定 this，执行构造函数 let result = Con.apply(obj, arguments) // 确保 new 出来的是个对象 return typeof result === 'object' ? result : obj&#125; 对于实例对象来说，都是通过 new 产生的，无论是 function Foo() 还是 let a = { b : 1 } 。 对于创建一个对象来说，更推荐使用字面量的方式创建对象。因为你使用 new Object() 的方式创建对象需要通过作用域链一层层找到 Object，但是你使用字面量的方式就没这个问题。 12345function Foo() &#123;&#125;// function 就是个语法糖// 内部等同于 new Function()let a = &#123; b: 1 &#125;// 这个字面量内部也是使用了 new Object() Function.proto === Function.prototype对于对象来说，xx.__proto__.contrcutor 是该对象的构造函数，但是在图中我们可以发现 Function.__proto__ === Function.prototype，难道这代表着 Function 自己产生了自己? 答案肯定是否认的，要说明这个问题我们先从 Object 说起。 从图中我们可以发现，所有对象都可以通过原型链最终找到 Object.prototype ，虽然 Object.prototype 也是一个对象，但是这个对象却不是 Object 创造的，而是引擎自己创建了 Object.prototype 。所以可以这样说，所有实例都是对象，但是对象不一定都是实例。 接下来我们来看 Function.prototype 这个特殊的对象，如果你在浏览器将这个对象打印出来，会发现这个对象其实是一个函数。 我们知道函数都是通过 new Function() 生成的，难道 Function.prototype 也是通过 new Function() 产生的吗？答案也是否定的，这个函数也是引擎自己创建的。首先引擎创建了 Object.prototype ，然后创建了 Function.prototype ，并且通过 __proto__ 将两者联系了起来。这里也很好的解释了上面的一个问题，为什么 let fun = Function.prototype.bind() 没有 prototype 属性。因为 Function.prototype 是引擎创建出来的对象，引擎认为不需要给这个对象添加 prototype 属性。 所以我们又可以得出一个结论，不是所有函数都是 new Function() 产生的。 有了 Function.prototype 以后才有了 function Function() ，然后其他的构造函数都是 function Function() 生成的。 现在可以来解释 Function.__proto__ === Function.prototype 这个问题了。因为先有的 Function.prototype 以后才有的 function Function() ，所以也就不存在鸡生蛋蛋生鸡的悖论问题了。对于为什么 Function.__proto__ 会等于 Function.prototype ，个人的理解是：其他所有的构造函数都可以通过原型链找到 Function.prototype ，并且 function Function() 本质也是一个函数，为了不产生混乱就将 function Function() 的 __proto__ 联系到了 Function.prototype 上。 总结 Object 是所有对象的爸爸，所有对象都可以通过 __proto__ 找到它 Function 是所有函数的爸爸，所有函数都可以通过 __proto__ 找到它 Function.prototype 和 Object.prototype 是两个特殊的对象，他们由引擎来创建 除了以上两个特殊对象，其他对象都是通过构造器 new 出来的 函数的 prototype 是一个对象，也就是原型 对象的 __proto__ 指向原型， __proto__ 将对象和原型连接起来组成了原型链]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSONP原理及实现]]></title>
    <url>%2F2019%2F02%2F26%2FJSONP%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[JSONP的原理就不细说了，就是利用script可以跨域的特点来实现跨域，首先我们考虑一个最简单的jsonp，就是简简单单创建script标签，添加url的功能，如下： 123456function jsonp(url) &#123; const script = document.createElement('script'); script.src = url; script.type = 'text/javascript'; document.body.appendChild(script);&#125; 此时我们使用服务端的代码如下： 123456789101112131415const http = require('http');const data = &#123;'data':'hello'&#125;;const url = require('url');const queryString = require('querystring');http.createServer(function(req, res) &#123; var params = url.parse(req.url); console.log(params); if(params.query &amp;&amp; queryString.parse(params.query).callback) &#123; console.log(1231232); const str = queryString.parse(params.query).callback + '(' + JSON.stringify(data) + ')'; return res.end(str) &#125; res.end(JSON.stringify(data));&#125;).listen(5000); 这是我们调用jsonp，假设我们只是想要alert出返回的数据，如下： 12345function msg(res) &#123; alert(res.data);&#125;jsonp('http://localhost:5000?callback=msg'); 这时候我们运行代码可以发现已经正确弹出了相应的数据。但是我们会发现这里的callback回调函数是一个全局的，这是不可取的，因此我们需要进行一些修改，将处理修改为一个局部的，我们可以将其作为一个回调函数来处理，如下： 1234567891011function jsonp(url, callback) &#123; window.jsonpCallback = callback; const script = document.createElement('script'); script.src = url + '?callback=jsonpCallback'; script.type = 'text/javascript'; document.body.appendChild(script);&#125;jsonp('http://localhost:5000', function(res) &#123; alert(res.data);&#125;); 这时候我们会发现我们不再需要在url中声明相应的callback了，但是我们还是会发现一个问题，就是我们将所有的callback都设置成了一个全局变量，这样的原因是因为我们需要在数据请求完成之后调用这个方法，因此不得不设置为一个全局变量。但是当我们有多个请求，并且每个请求的处理都是不一样的时候，这个变量将会被覆盖。这是不行的，因此我们应该为每一次请求设置一个唯一且不会冲突的变量，因此增加一个生成callback名字的方法如下： 12345678910111213141516171819202122function generateJsonpCallback() &#123; return `jsonpcallback_$&#123;Date.now()&#125;_$&#123;Math.floor(Math.random() * 100000)&#125;`;&#125;function jsonp(url, callback) &#123; const funcName = generateJsonpCallback(); window[funcName] = callback; const script = document.createElement('script'); script.src = `$&#123;url&#125;?callback=$&#123;funcName&#125;`; script.type = 'text/javascript'; document.body.appendChild(script);&#125;jsonp('http://localhost:5000', function(res) &#123; alert(res.data);&#125;);jsonp('http://localhost:5000', function(res) &#123; const text = document.createTextNode(res.data); document.body.appendChild(text);&#125;); 这时候我们会发现我们已经利用了一个类似于随机ID的形式完成了多次请求。但是还是有一个问题大量的请求之后，window中会含有大量的全局变量，而且还有大量的script标签，这显然不是我们想要的，所以我们可以在请求完成之后删除变量和script标签。 1234567891011121314151617181920212223242526272829303132333435function generateJsonpCallback() &#123; return `jsonpcallback_$&#123;Date.now()&#125;_$&#123;Math.floor(Math.random() * 100000)&#125;`;&#125;function removeScript(id) &#123; document.body.removeChild(document.getElementById(id));&#125;function removeFunc(name) &#123; delete window[name];&#125;function jsonp(url, timeout = 3000, callback) &#123; const funcName = generateJsonpCallback(); window[funcName] = callback; const script = document.createElement('script'); script.src = `$&#123;url&#125;?callback=$&#123;funcName&#125;`; script.id = funcName; script.type = 'text/javascript'; document.body.appendChild(script); setTimeout(() =&gt; &#123; removeScript(funcName); removeFunc(funcName); &#125;, timeout)&#125;jsonp('http://localhost:5000', 3000, function(res) &#123; alert(res.data);&#125;);jsonp('http://localhost:5000', 3000, function(res) &#123; const text = document.createTextNode(res.data); document.body.appendChild(text);&#125;); 我们通过将利用一个timeout时间定时为我们清除相应的script标签和全局变量就可以了，这个定时时间的作用类似于ajax的timeout时间。我们所有的内容都是使用es6的，那为什么不使用Promise来处理呢，还要使用烦人的回调，接下来那就来Promise化吧。 123456789101112131415161718function jsonp(url, options = &#123;timeout:3000&#125;) &#123; const timeout = options.timeout; return new Promise((resolve, reject) =&gt; &#123; const funcName = generateJsonpCallback(); window[funcName] = (res) =&gt; &#123; resolve(res); setTimeout(() =&gt; &#123; removeScript(funcName); removeFunc(funcName); &#125;, timeout) &#125;; const script = document.createElement('script'); script.src = `$&#123;url&#125;?callback=$&#123;funcName&#125;`; script.id = funcName; script.type = 'text/javascript'; document.body.appendChild(script); &#125;)&#125; 调用只需要如下就可以了 123456jsonp('http://localhost:5000').then((res) =&gt; alert(res.data));jsonp('http://localhost:5000').then((res) =&gt; &#123; const text = document.createTextNode(res.data); document.body.appendChild(text);&#125;); 到目前为止，一个较为完整的jsonp就实现了，但是我们还是会觉得少了一些什么，相信你已经看出来了，那就是错误处理。迄今为止，并没有测试过如果这个script标签加载不成功如何处理，判断资源加载失败，显然使用的是onerror事件，我们这就把他加上： 12345678910111213141516171819202122232425function jsonp(url, options = &#123;timeout:3000&#125;) &#123; const timeout = options.timeout; let timeId; return new Promise((resolve, reject) =&gt; &#123; const funcName = generateJsonpCallback(); window[funcName] = (res) =&gt; &#123; resolve(res); timeId = setTimeout(() =&gt; &#123; removeScript(funcName); removeFunc(funcName); &#125;, timeout) &#125;; const script = document.createElement('script'); script.src = `$&#123;url&#125;?callback=$&#123;funcName&#125;`; script.id = funcName; script.type = 'text/javascript'; document.body.appendChild(script); script.onerror = () =&gt; &#123; reject(new Error(`fetch $&#123;url&#125; failed`)); removeScript(funcName); removeFunc(funcName); if(timeId) clearTimeout(timeId); &#125; &#125;)&#125; 我们可以测试一下，输入一个不存在的url: 1jsonp('http://localhost:7000').then((res) =&gt; alert(res.data)); 可以发现这时正常处理错误了,可以在控制台看到相应的url获取失败，至此，完工； 至此所有的代码简单封装如下： 12345678910111213141516171819202122232425262728293031323334353637383940(function(global)&#123; function generateJsonpCallback() &#123; return `jsonpcallback_$&#123;Date.now()&#125;_$&#123;Math.floor(Math.random() * 100000)&#125;`; &#125; function removeScript(id) &#123; document.body.removeChild(document.getElementById(id)); &#125; function removeFunc(name) &#123; delete global[name]; &#125; function jsonp(url, options = &#123;timeout:3000&#125;) &#123; const timeout = options.timeout; let timeId; return new Promise((resolve, reject) =&gt; &#123; const funcName = generateJsonpCallback(); global[funcName] = (res) =&gt; &#123; resolve(res); timeId = setTimeout(() =&gt; &#123; removeScript(funcName); removeFunc(funcName); &#125;, timeout) &#125;; const script = document.createElement('script'); script.src = `$&#123;url&#125;?callback=$&#123;funcName&#125;`; script.id = funcName; script.type = 'text/javascript'; document.body.appendChild(script); script.onerror = () =&gt; &#123; reject(new Error(`fetch $&#123;url&#125; failed`)); removeScript(funcName); removeFunc(funcName); if(timeId) clearTimeout(timeId); &#125; &#125;) &#125; window.jsonp = jsonp;&#125;)(window); 测试代码如下： 12345678jsonp('http://localhost:5000').then((res) =&gt; alert(res.data));jsonp('http://localhost:5000').then((res) =&gt; &#123; const text = document.createTextNode(res.data); document.body.appendChild(text);&#125;);jsonp('http://localhost:7000').then((res) =&gt; alert(res.data));]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[探索JavaScript构造函数与原型继承]]></title>
    <url>%2F2019%2F02%2F15%2F%E6%8E%A2%E7%B4%A2JavaScript%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8E%9F%E5%9E%8B%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[In javascript, every object has a constructor property that refers to the constructor function that initializes the object. Sounds nice: it makes constructors sound static like classes in Java. Even the new Constructor() syntax looks like it. And it seems true: 123function MyConstructor() &#123;&#125;var myobject = new MyConstructor();myobject.constructor == MyConstructor; // true But life isn’t that simple: 12345function MyConstructor() &#123;&#125;MyConstructor.prototype = &#123;&#125;;var myobject = new MyConstructor();myobject.constructor == MyConstructor; // false What’s going on? Some definitionsObjects and methodsJavascript1 objects are simply bags of named properties that you can read and set. Javascript does not have classes. Functions in javascript are first-class objects. Methods in javascript are just properties that are functions. PrototypesThe prototype of an object is an internal property that I’ll refer to here as {Prototype}. In other words, obj.prototype is in general not the obj’s {Prototype}. The standard does not provide any way to retrieve the {Prototype} property from an object. Property lookupJavascript objects can delegate properties to their {Prototype} and their {Prototype} can do the same; all the way up to Object.prototype. Whenever a property propname of an object is read, the system checks if that object has a property named propname. If that propery does not exist, the system checks the object’s {Prototype} for that property, recursively. This means that objects that share a {Protoype} also share the properties of that {Prototype}. Setting propertiesWhenever a property propname of an object is set, the property is inserted into that object, ignoring the {Prototype} chain of that object. The {Prototype} property is set from the (public) prototype property of the constructor function when constructor function is called. What’s going on? Line by line.This is what the relevant prototype and {Prototype} properties look like. The ellipses are objects, the arrows are properties that reference other objects. The {Prototype} chain(s) are in green. #1: Define constructor function1function MyConstructor() &#123;&#125; Fairly simple. MyConstructor.prototype is an object that’s automatically created which in turn has a constructor property pointing back at MyConstructor. Remember that: the only objects that in fact have a constructor property by default are the automatically createdprototype properties of functions. The rest isn’t really relevant but may confuse and enlighten (and hopefully in that order): MyConstructor’s {Prototype} is Function.prototype, not MyConstructor.prototype. Also note that the {Prototype} chain for each object ends up at Object.prototype. Object.prototype’s {Prototype} is actually null indicating that it’s the end of the chain. 2 For the next steps I’m leaving out the {Prototype} chain of MyConstructor for clarity, since it doesn’t change and it’s not relevant. #2: Assign new prototype property1MyConstructor.prototype = &#123;&#125; We’ve now done away with the predefined MyConstructor.protoype object and replaced it with an anonymous object, shown here as {}. This object does not have a constructor property, #3: Call constructor to create new object1var myobject = new MyConstructor(); From this graph, following the L rules, we can now see that myobject.constructor is delegated to Object.prototype.constructor, which points to Object. In other words: 12345function MyConstructor() &#123;&#125;MyConstructor.prototype = &#123;&#125;;var myobject = new MyConstructor();myobject.constructor == Object // true What about instanceof ?Javascript provides the instanceof operator that’s intended to check the prototype chain of the object you’re dealing with. From the above you might think that the following would return false: 12345function MyConstructor() &#123;&#125;MyConstructor.prototype = &#123;&#125;;var myobject = new MyConstructor();myobject instanceof MyConstructor // true But in fact it works. It also notices that myobject delegates to Object.prototype: 12345function MyConstructor() &#123;&#125;MyConstructor.prototype = &#123;&#125;;var myobject = new MyConstructor();myobject instanceof Object // true When instanceof is called it checks the prototype property of the given constructor and checks it agains the {Prototype} chain of the given object. In other words, it’s not dependent on the constructor property. All nice and dandy, but you can still break it if you try hard enough: 1234567function MyConstructor() &#123;&#125;var myobject = new MyConstructor();MyConstructor.prototype = &#123;&#125;;[ myobject instanceof MyConstructor, // false ! myobject.constructor == MyConstructor, // true ! myobject instanceof Object ] // true This is what the prototype chains look like after running that: Constructors are not classesIn a class-based object system, typically classes inherit from each other, and objects are instances of those classes. Methods and properties that are shared between instances are (at least conceptually) properties of a class. Properties (and for some languages, methods) that should not be shared are properties of the objects themselves. Javascript’s constructors do nothing like this: in fact constructors have their own {Prototype} chain completely separate from the {Prototype} chain of objects they initialize. Constructors do not work like class-based initializersA constructor call associates a new object with a {Prototype} the constructor function mayset additional properties on the object. Constructor calls do not call “inherited” constructors, and they shouldn’t because the object’s {Prototype} (the constructor’sprototype) is assumed to be shared and (probably) already initialized. Constructors are just functionsAny user-defined function in javascript automatically gets a prototype property which in turn has a constructor property that refers back to the function. Any user-defined function in javascript can be called as a constructor by prepending new to the call. This will pass a new this object to the function and its {Prototype} property will be set to the prototype property of the function. ReferencesA comp.lang.javascript question123Subject: &quot;x.constructor == Foo&quot; vs &quot;x instanceof Foo&quot;.Message-ID: &lt;fniu6a$2cn$1@reader2.panix.com&gt;&gt;http://groups.google.com/group/comp.lang.javascript/msg/102ab20c68aa738f Ecma-262Standard ECMA-262. ECMAScript Language Specification 3rd edition (December 1999) Flanagan 2006JavaScript: The Definitive Guide, Fifth Edition. ISBN 10: 0-596-10199-6 | ISBN 13:9780596101992]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript中的New关键字]]></title>
    <url>%2F2019%2F02%2F15%2FJavaScript%E4%B8%AD%E7%9A%84New%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[The new keyword in JavaScript can be quite confusing when it is first encountered, as people tend to think that JavaScript is not an object-oriented programming language. What is it? What problems does it solve? When is it appropriate and when not? It does 5 things: It creates a new object. The type of this object is simply object. It sets this new object’s internal, inaccessible, [[prototype]] (i.e. proto) property to be the constructor function’s external, accessible, prototype object (every function object automatically has a prototype property). It makes the this variable point to the newly created object. It executes the constructor function, using the newly created object whenever this is mentioned. It returns the newly created object, unless the constructor function returns a non-null object reference. In this case, that object reference is returned instead. Note: constructor function refers to the function after the new keyword, as in 1new ConstructorFunction(arg1, arg2) Once this is done, if an undefined property of the new object is requested, the script will check the object’s [[prototype]] object for the property instead. This is how you can get something similar to traditional class inheritance in JavaScript. The most difficult part about this is point number 2. Every object (including functions) has this internal property called [[prototype]]. It can only be set at object creation time, either with new, with Object.create, or based on the literal (functions default to Function.prototype, numbers to Number.prototype, etc.). It can only be read with Object.getPrototypeOf(someObject). There is noother way to set or read this value. Functions, in addition to the hidden [[prototype]] property, also have a property called prototype, and it is this that you can access, and modify, to provide inherited properties and methods for the objects you make. Here is an example: 123456789101112131415161718192021222324252627ObjMaker = function() &#123;this.a = &apos;first&apos;;&#125;;// ObjMaker is just a function, there&apos;s nothing special about it that makes // it a constructor.ObjMaker.prototype.b = &apos;second&apos;;// like all functions, ObjMaker has an accessible prototype property that // we can alter. I just added a property called &apos;b&apos; to it. Like // all objects, ObjMaker also has an inaccessible [[prototype]] property// that we can&apos;t do anything withobj1 = new ObjMaker();// 3 things just happened.// A new, empty object was created called obj1. At first obj1 was the same// as &#123;&#125;. The [[prototype]] property of obj1 was then set to the current// object value of the ObjMaker.prototype (if ObjMaker.prototype is later// assigned a new object value, obj1&apos;s [[prototype]] will not change, but you// can alter the properties of ObjMaker.prototype to add to both the// prototype and [[prototype]]). The ObjMaker function was executed, with// obj1 in place of this... so obj1.a was set to &apos;first&apos;.obj1.a;// returns &apos;first&apos;obj1.b;// obj1 doesn&apos;t have a property called &apos;b&apos;, so JavaScript checks // its [[prototype]]. Its [[prototype]] is the same as ObjMaker.prototype// ObjMaker.prototype has a property called &apos;b&apos; with value &apos;second&apos;// returns &apos;second&apos; It’s like class inheritance because now, any objects you make using new ObjMaker() will also appear to have inherited the ‘b’ property. If you want something like a subclass, then you do this: 1234567891011121314151617181920212223SubObjMaker = function () &#123;&#125;;SubObjMaker.prototype = new ObjMaker(); // note: this pattern is deprecated!// Because we used &apos;new&apos;, the [[prototype]] property of SubObjMaker.prototype// is now set to the object value of ObjMaker.prototype.// The modern way to do this is with Object.create(), which was added in ECMAScript 5:// SubObjMaker.prototype = Object.create(ObjMaker.prototype);SubObjMaker.prototype.c = &apos;third&apos;; obj2 = new SubObjMaker();// [[prototype]] property of obj2 is now set to SubObjMaker.prototype// Remember that the [[prototype]] property of SubObjMaker.prototype// is ObjMaker.prototype. So now obj2 has a prototype chain!// obj2 ---&gt; SubObjMaker.prototype ---&gt; ObjMaker.prototypeobj2.c;// returns &apos;third&apos;, from SubObjMaker.prototypeobj2.b;// returns &apos;second&apos;, from ObjMaker.prototypeobj2.a;// returns &apos;first&apos;, from SubObjMaker.prototype, because SubObjMaker.prototype // was created with the ObjMaker function, which assigned a for us I read a ton of rubbish on this subject before finally finding this page, where this is explained very well with nice diagrams. 手写一个 new 的实现 1234567891011function New(func) &#123; var res = &#123;&#125;; if (func.prototype !== null) &#123; res.__proto__ = func.prototype; &#125; var ret = func.apply(res, Array.prototype.slice.call(arguments, 1)); if ((typeof ret === "object" || typeof ret === "function") &amp;&amp; ret !== null) &#123; return ret; &#125; return res;&#125;]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript作用域]]></title>
    <url>%2F2019%2F02%2F13%2FJavaScript%E4%BD%9C%E7%94%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[​ 作用域（Scope ）是 JavaScript 语言的基础概念之一，可能是让我在编写复杂程序的时候煎熬最多的。记不清多少次迷失在追踪函数到函数之间传递控制时 this 关键字指向的问题中了，我发现自己经常以各种令人困惑的方式扭曲我的代码，试图对理解变量在哪些地方可以访问的问题上保留一点理智。 ​ 这篇文章将会正面解决问题，概述作用域和上下文的定义，测试两种允许我们操作上下文的 JavaScript 方法，并深入探讨我遇到过的 90% 的问题的解决方案。 this？是什么？ 调用一个对象的函数 ​ 在经典的面向对象编程中，我们需要一种方法来标识和指向我们正在操作的对象。this 优秀地满足了这个目的，为我们的对象提供了访问自己和指向自有属性的目的。 123456789&lt;script type="text/javascript"&gt; var deep_thought = &#123; the_answer: 42, ask_question: function () &#123; return this.the_answer; &#125;&#125;;var the_meaning = deep_thought.ask_question();&lt;/script&gt; ​ 上面的示例构造了 一个对象，名为 deep_thought ，并将它的 this_answer 属性设置为 42，然后创建了一个 ask_question 方法。当 deep_thought.ask_question() 函数被执行的时候，JavaScript 为函数调用创建了一个执行上下文，将 this 设置为调用语句最后一个 ”.” 前面的变量所引用的对象，在这个例子中就是 deep_thought 。这个方法可以在后面通过 this 访问到 deep_thought 的镜像，并查看它的自有属性，并返回 this.the_answer 中保存的值：42。 构造函数 ​ 同样的，在定义一个用来作为可以使用 new 关键字的构造函数的方法时，this 可以被用来指向被创建的对象。 我们重写一下上面的例子来体现这个场景： 12345678910&lt;script type="text/javascript"&gt; function BigComputer(answer) &#123; this.the_answer = answer; this.ask_question = function () &#123; return this.the_answer; &#125;&#125;var deep_thought = new BigComputer(42);var the_meaning = deep_thought.ask_question();&lt;/script&gt; ​ 我并没有显示地创建 deep_thought 对象，而是写了一个方法来创建 BigComputer 对象，然后通过 new 关键字将 deep_thought 实例化为一个实例变量。当 new BigComputer() 被执行的时候，一个全新的对象在后台透明地创建了。BigComputer() 方法被调用，然后它的 this 关键字被设置为指向 这个新创建的对象。这个函数可以将属性和方法设置到 this 上，然后在 BigComputer 执行结束后透明地将其返回。 ​ 注意，尽管如此，deep_thought.ask_question() 仍然像以前一样工作。发生了什么，为什么 this 在 the_question 中的含义与在 BigComputer 中的不同？简单来说，我们是通过 new 进入 BigComputer 的，所以 this 表示 新创建的对象 ，另一方面，我们通过 deep_thought 进入 ask_question ，所以当我们执行这个方法的时候， this 就代表着 deep_thought 指向的任意对象。this 并不是像其他变量一样从作用域链中读取的，而是基于上下文与上下文间重置的。 方法调用 ​ 如果我们只是调用一个简单的，没有这些眼花缭乱的对象的方法呢？ this 在这样的情景下指向哪里呢？ 123456&lt;script type="text/javascript"&gt;function test_this() &#123; return this;&#125;var i_wonder_what_this_is = test_this();&lt;/script&gt; ​ 在这种情况下，我们没有通过 new 来提供一个上下文，也没有提供一个对象形式的上下文。在这里 this 会尽可能指向最全局的对象：对 网页来说，就是 window 对象。 事件处理函数 Event Handler For a more complicated twist on the normal function call, let’s say that we’re using a function to handle an onclick event. What does this mean when the event triggers our function’s execution? Unfortunately, there’s not a simple answer to this question.If we write the event handler inline, this refers to the global window object: 对于一个 However, when we add an event handler via JavaScript, this refers to the DOM element that generated the event. (Note: The event handling shown here is short and readable, but otherwise poor. Please use a real addEvent function instead.): 12345678function addhandler() &#123;document.getElementById(‘thebutton’).onclick = click_handler;&#125;window.onload = addhandler;&lt;/script&gt;…&lt;button id='thebutton'&gt;Click me!&lt;/button&gt; ComplicationsLet’s run with that last example for a moment longer. What if instead of running click_handler, we wanted to ask deep_thought a question every time we clicked the button? The code for that seems pretty straightforward; we might try this: 12345678910111213141516&lt;script type="text/javascript"&gt;function BigComputer(answer) &#123; this.the_answer = answer; this.ask_question = function () &#123; alert(this.the_answer); &#125;&#125;function addhandler() &#123; var deep_thought = new BigComputer(42), the_button = document.getElementById(‘thebutton’); the_button.onclick = deep_thought.ask_question;&#125;window.onload = addhandler;&lt;/script&gt; Perfect, right? We click on the button, deep_thought.ask_question is executed, and we get back “42.” So why is the browser giving us undefined instead? What did we do wrong? The problem is simply this: We’ve passed off a reference to the ask_question method, which, when executed as an event handler, runs in a different context than when it’s executed as an object method. In short, the this keyword in ask_question is pointing at the DOM element that generated the event, not at a BigComputer object. The DOM element doesn’t have a the_answer property, so we’re getting back undefined instead of “42.” setTimeout exhibits similar behavior, delaying the execution of a function while at the same time moving it out into a global context. This issue crops up all over the place in our programs, and it’s a terribly difficult problem to debug without keeping careful track of what’s going on in all the corners of your program, especially if your object has properties that do exist on DOM elements or the window object. Manipulating Context With .apply() and .call()We really do want to be able to ask deep_thought a question when we click the button, and more generally, we do want to be able to call object methods in their native context when responding to things like events and setTimeout calls. Two little-known JavaScript methods, apply and call, indirectly enable this functionality by allowing us to manually override the /files/includes/default.css value of this when we execute a function call. Let’s look at callfirst: 1234567891011121314&lt;script type="text/javascript"&gt;var first_object = &#123; num: 42&#125;;var second_object = &#123; num: 24&#125;;function multiply(mult) &#123; return this.num * mult;&#125;multiply.call(first_object, 5); // returns 42 * 5multiply.call(second_object, 5); // returns 24 * 5&lt;/script&gt; In this example, we first define two objects, first_object and second_object, each with a num property. Then we define a multiply function that accepts a single argument, and returns the product of that argument, and the num property of its this object. If we called that function by itself, the answer returned would almost certainly be undefined, since the global windowobject doesn’t have a num property unless we explicitly set one. We need some way of telling multiply what its this keyword ought refer to; the call method of the multiply function is exactly what we’re looking for. The first argument to call defines what this means inside the executed function. The remaining arguments to call are passed into the executed function, just as if you’d called it yourself. So, when multiply.call(first_object, 5) is executed, the multiply function is called, 5 is passed in as the first argument, and the this keyword is set to refer to object first_object. Likewise, when multiply.call(second_object, 5) is executed, the multiply function is called, 5 is passed in as the first argument, and the this keyword is set to refer to object second_object. apply works in exactly the same way as call, but allows you to wrap up the arguments to the called function in an array, which can be quite useful when programatically generating function calls. Replicating the functionality we just talked about using apply is trivial: 12345&lt;script type="text/javascript"&gt;...multiply.apply(first_object, [5]); // returns 42 * 5multiply.apply(second_object, [5]); // returns 24 * 5&lt;/script&gt; apply and call are very useful on their own, and well worth keeping around in your toolkit, but they only get us halfway to solving the problem of context shifts for event handlers. It’s easy to think that we could solve the problem by simply using call to shift the meaning of this when we set up the handler: 12345function addhandler() &#123; var deep_thought = new BigComputer(42), the_button = document.getElementById('thebutton'); the_button.onclick = deep_thought.ask_question.call(deep_thought);&#125; The problem with this line of reasoning is simple: call executes the function immediately. Instead of providing a function reference to the onclick handler, we’re giving it the result of an executed function. We need to exploit another feature of JavaScript to really solve this problem. The Beauty of .bind()I’m not a huge fan of the Prototype JavaScript framework, but I am very much impressed with the quality of its code as a whole. In particular, one simple addition it makes to the Function object has had a hugely positive impact on my ability to manage the context in which function calls execute: bind performs the same general task as call, altering the context in which a function executes. The difference is that bind returns a function reference that can be used later, rather than the result of an immediate execution that we get with call. If we simplify the bind function a bit to get at the key concepts, we can insert it into the multiplication example we discussed earlier to really dig into how it works; it’s quite an elegant solution: 1234567891011121314151617181920212223242526&lt;script type="text/javascript"&gt;var first_object = &#123; num: 42&#125;;var second_object = &#123; num: 24&#125;;function multiply(mult) &#123; return this.num * mult;&#125;Function.prototype.bind = function(obj) &#123; var method = this, temp = function() &#123; return method.apply(obj, arguments); &#125;;return temp;&#125;var first_multiply = multiply.bind(first_object);first_multiply(5); // returns 42 * 5var second_multiply = multiply.bind(second_object);second_multiply(5); // returns 24 * 5&lt;/script&gt; First, we define first_object, second_object, and the multiply function, just as before. With those taken care of, we move on to creating a bind method on the Function object’s prototype, which has the effect of making bind available for all functions in our program. When multiply.bind(first_object) is called, JavaScript creates an execution context for the bind method, setting this to the multiply function, and setting the first argument, obj, to reference first_object. So far, so good. The real genius of this solution is the creation of method, set equal to this (the multiplyfunction itself). When the anonymous function is created on the next line, method is accessible via its scope chain, as is obj (this couldn’t be used here, because when the newly created function is executed, this will be overwritten by a new, local context). This alias to this makes it possible to use apply to execute the multiply function, passing in obj to ensure that the context is set correctly. In computer-science-speak, temp is a closure that, when returned at the end of the bind call, can be used in any context whatsoever to execute multiply in the context of first_object. This is exactly what we need for the event handler and setTimeout scenarios discussed above. The following code solves that problem completely, binding the deep_thought.ask_questionmethod to the deep_thought context, so that it executes correctly whenever the event is triggered: 12345function addhandler() &#123; var deep_thought = new BigComputer(42), the_button = document.getElementById('thebutton'); the_button.onclick = deep_thought.ask_question.bind(deep_thought);&#125; Beautiful. References JavaScript Closures is the best resource on the net for a thorough discussion of closures: what they do, how they do it, and how to use them without going insane. The Protype JavaScript Framework is full of little nuggets like bind. The version available here not only allows the binding of a particular this value, but also of some or all of a function’s arguments, which comes in handy all too often. Douglas Crockford’s JavaScript essays are excellent resources for both basic and advanced JavaScript programmers. The man knows what he’s talking about, and explains difficult concepts in an easy-to-grasp manner. Variable Scope for New Programmers is a good article if you’d like more discussion of scope from a beginner’s perspective. Written by Jonathan Snook, and published in this very magazine at the end of last year, it’s still an informative and useful read.]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置 Nginx HTTPS 服务器]]></title>
    <url>%2F2019%2F01%2F17%2F%E9%85%8D%E7%BD%AE-Nginx-HTTPS-%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[译自官方文档—— Configuring HTTPS servers 要配置 HTTPS 服务器，必须在 server 区的监听（listen）套接字上允许 ssl 参数，同时要声明服务器证书和私钥文件的位置： 123456789server &#123; listen 443 ssl; server_name www.example.com; ssl_certificate www.example.com.crt; ssl_certificate_key www.example.com.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ...&#125; ​ 服务器证书是一个公开的实体。它会被发送给所有连接到服务器的客户端。私钥是一个安全实体，应该被保存在一个限制访问的文件中，但是要允许 Nginx 的主线程可读。私钥也可以保存在和证书同一个文件中： ssl_certificate www.example.com.cert; ssl_certificate_key www.example.com.cert; ​ 这种情况下文件的访问权限也应当被限制。尽管证书和私钥被保存在同一个文件中，只有证书会被发送给客户端。 ​ ssl_protocols 和 ssl_ciphers 指令可以用来限制只允许高版本和强加密的 SSL/TLS 的连接。Nginx 默认使用 “ssl_protocols TLSv1 TLSv1.1 TLSv1.2” 和 “ssl_ciphers HIGH:!aNULL:!MD5”，所以通常不需要特意配置它们。要知道这些指令的默认配置变过几次。 HTTPS server optimization HTTPS 服务器优化​ SSL 操作消耗额外的 CPU 资源。在多处理器系统中应该启动多个工作进程，数量不少于可用的 CPU 内核。最消耗 CPU 的操作是 SSL 握手。有两种方法可以让每个客户端的握手次数降低到最小：第一种是通过允许 keepalive 连接，这样就可以实现连接复用，即通过一个连接发送多个请求；第二种是重用 SSL 会话参数来避免并发请求和自请求的 SSL 握手。这些会话被保存在一个被工作进程共享的 SSL 会话缓存中，可以通过 ssl_session_cache 指令来配置。1MB 缓存可以包含 4000 个会话。默认的缓存过期时间是 5 分钟。可以通过 ssl_session_timeout 指令增加过期时间。下面是一个简单的配置，通过设置 10MB 共享会话缓存来优化一个多核系统： 12345678910111213141516worker_processes auto;http &#123; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; server &#123; listen 443 ssl; server_name www.example.com; keepalive_timeout 70; ssl_certificate www.example.com.crt; ssl_certificate_key www.example.com.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ... SSL 证书链​ 某些浏览器可能会抱怨由知名证书颁发机构签名的证书，而其他一些浏览器可能毫无问题的接受证书。发生这种情况是因为颁发机构使用中间证书对服务器进行了签名，该中间证书不存在于与特定浏览器一起分发的众所周知的可信任的证书颁发机构的证书库中。 这种情况下，颁发机构提供了一组链式证书，通过证书链应该能够链接到签名的服务器证书。在合并文件中，服务器证书必须出现在链式证书之前： $ cat www.example.com.crt bundle.crt &gt; www.example.com.chained.crt 结果文件应该用在 ssl_certificate 指令中： 1234567server &#123; listen 443 ssl; server_name www.example.com; ssl_certificate www.example.com.chained.crt; ssl_certificate_key www.example.com.key; ...&#125; ​ 如果服务器证书和链式证书用错误的顺序连接了，nginx将不能正常启动，并现实 错误信息： SSL_CTX_use_PrivateKey_file(“ … /www.example.com.key&quot;) failed (SSL: error:0B080074:x509 certificate routines:​ X509_check_private_key:key values mismatch) ​ 因为 nginx 尝试用私钥和链式证书中的第一个证书而不是服务器证书。 ​ 浏览器通常会保存接受到的由可信任颁发机构签发的中间证书，所以频繁使用的浏览器可能已经获取过中间证书，所以遇到没有包含链式证书的服务器证书就不会出现警告。为确保服务器发送了完整的证书链，可以用 openssl 命令行工具测试，例如： 1234567891011121314151617181920212223$ openssl s_client -connect www.godaddy.com:443...Certificate chain 0 s:/C=US/ST=Arizona/L=Scottsdale/1.3.6.1.4.1.311.60.2.1.3=US /1.3.6.1.4.1.311.60.2.1.2=AZ/O=GoDaddy.com, Inc /OU=MIS Department/CN=www.GoDaddy.com /serialNumber=0796928-7/2.5.4.15=V1.0, Clause 5.(b) i:/C=US/ST=Arizona/L=Scottsdale/O=GoDaddy.com, Inc. /OU=http://certificates.godaddy.com/repository /CN=Go Daddy Secure Certification Authority /serialNumber=07969287 1 s:/C=US/ST=Arizona/L=Scottsdale/O=GoDaddy.com, Inc. /OU=http://certificates.godaddy.com/repository /CN=Go Daddy Secure Certification Authority /serialNumber=07969287 i:/C=US/O=The Go Daddy Group, Inc. /OU=Go Daddy Class 2 Certification Authority 2 s:/C=US/O=The Go Daddy Group, Inc. /OU=Go Daddy Class 2 Certification Authority i:/L=ValiCert Validation Network/O=ValiCert, Inc. /OU=ValiCert Class 2 Policy Validation Authority /CN=http://www.valicert.com//emailAddress=info@valicert.com... ​ 当用 SNI 测试配置的时候，指定 -servername 选项是很重要的，因为 openss 默认不使用 SNI 。 ​ 在该示例中，www.godaddy.com 服务器证书 #0 的主体由发行者（“ i ”）签名，发行者（“ i ”）本身是证书 #1 的主体，证书 #1 签名的发行者又是 证书 #2 的主体，证书 #2 是由知名发行方 ValiCert, Inc 签名的，ValiCert, Inc. 的证书保存在浏览器的内置证书库中。 ​ 如果缺少证书链，浏览器只能看到服务器证书 #0。 单 HTTP/HTTPS 服务器可以配置一个单独的服务器来同时处理 HTTP 和 HTTPS 请求： 12345678server &#123; listen 80; listen 443 ssl; server_name www.example.com; ssl_certificate www.example.com.crt; ssl_certificate_key www.example.com.key; ...&#125; ​ 早在 0.7.14 版本之前，还不能像上面那样为个别 socket 监听选择性启用 SSL。SSL 只能通过 ssl 指令用于整个 server 配置，使得不可能配置一个单独的 HTTP/HTTPS 服务器。于是在listen 指令中添加 ssl 参数来解决这个问题。但是不鼓励在现代版本中使用 ssl 指令。 基于域名的 HTTPS 服务器当配置两个或者多个 HTTPS 服务器监听同一个 IP 地址时会出现的一个常见的问题： server {​ listen 443 ssl;​ server_name www.example.com;​ ssl_certificate www.example.com.crt;​ …} server {​ listen 443 ssl;​ server_name www.example.org;​ ssl_certificate www.example.org.crt;​ …} ​ 使用此配置,浏览器接受默认服务器的证书，即 www.example.com ，不论请求的服务器名称如何。这是由 SSL 协议的行为所致。SSL 连接是在浏览器发送 HTTP 请求之前建立的，nginx 不知道请求的服务器的名称。所以，它只能提供默认的服务器证书。 ​ 解决这个问题的最古老也是最稳定的办法就是为每个 HTTPS 服务器分配一个单独的 IP 地址： server {​ listen 192.168.1.1:443 ssl;​ server_name www.example.com;​ ssl_certificate www.example.com.crt;​ …} server {​ listen 192.168.1.2:443 ssl;​ server_name www.example.org;​ ssl_certificate www.example.org.crt;​ …} 具有多个域名的 SSL 证书​ 也有其他的方法允许在多个 HTTPS 服务器之间共享一个单独的 IP 地址。但是，所有这些办法都有副作用。一种方法是在证书的 SubjectAltName 字段上使用多个域名，例如 www.example.com 和 www.example.org。但是，`SubjectAltName` 字段的长度有限。 ​ 另一个方法是让证书使用通配符域名，例如，.example.org。一个通配符证书能够加固指定域名的所有子域名，但仅限于一个级别。证书匹配 www.example.org，但是不能匹配 example.org 和 www.sub.example.org 。 这两种方法也可以合并。一个证书可以在 SubjectAltName 字段中包含准确的和通配符的域名，例如，`example.org and .example.org`。 ​ 最好将多域名证书文件和对应的私钥文件放在 http 级别的配置区域，以使证书的单个内存拷贝能够在所有服务器配置中共享： 1234567891011121314ssl_certificate common.crt;ssl_certificate_key common.key;server &#123; listen 443 ssl; server_name www.example.com; ...&#125;server &#123; listen 443 ssl; server_name www.example.org; ...&#125; 服务器域名指示（SNI）​ 一个用于在单个 IP 地址上承载多个 HTTPS 服务器的更加通用的解决方案是使用 TLS Server Name Indicationj 扩展（SNI, RFC 6066），SNI 允许浏览器在 SSL 握手期间上传请求的服务器域名，于是服务器就能知道应该将哪个证书用于这个连接。SNI 现在已经被大多数现代浏览器支持，但是一些老版本的或者特定的浏览器还没有支持。 ​ SNI 中只能传递域名，但是如果一个请求中包含了字面的 IP 地址，有些浏览器可能错误地传递这个服务器的 IP 地址。不能完全依赖 SNI。 ​ 为了在 nginx 中使用 SNI，必须在构建 nginx 二进制的 OpenSSL 库以及在运行时动态链接到的库中支持它。OpenSSL 从 0.9.8f 版本开始支持 SNI ，需要在编译时指定编译选项 ”--enable-tlsext“。从 OpenSSL 0.9.8j 版本开始，这个选项是默认开启的。如果 nginx 编译时支持了 SNI，运行 nginx 命令时加上 “-V” 开关会显示出来： 1234$ nginx -V...TLS SNI support enabled... ​ 然而，如果开启了 SNI 的 nginx 动态链接到了不支持 SNI 的 OpenSSL 二进制，nginx 会显示警告： nginx was built with SNI support, however, now it is linkeddynamically to an OpenSSL library which has no tlsext support,therefore SNI is not available]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript原型图解]]></title>
    <url>%2F2018%2F12%2F13%2FJavaScript%E5%8E%9F%E5%9E%8B%E5%9B%BE%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[介绍 JavaScript 原型JavaScript 引擎默认提供了 Object() 构造函数和一个可以被 Object.prototype 引用到的匿名对象。 12console.log(Object);console.log(Object.prototype); Object.prototype 对象有许多内置属性，例如 toString() ，valueOf()等等。也有一个名为 constructor 的属性，它指向 Object() 构造函数。 1console.log(Object.prototype.constructor === Object); // true 假设原型代表一个函数，方块代表一个对象。下面的图形就描绘出了 Object() 函数和 Object.prototype 对象之间的关系： 首先，我们定义一个名为 Foo 的函数如下： 123function Foo(name) &#123; this.name = name;&#125; Foo() 函数接收一个参数，添加 name 属性到对象中，并设置 name 属性的值为传入的参数。 在这个情景的背后，JavaScript 引擎创建了一个函数 Foo() 和一个匿名对象。这个 Foo() 函数有一个名为 prototype 的属性指向这个匿名对象。这个匿名对象也有一个 constructor 属性指向这个 Foo() 函数。 另外，Foo.prototype 对象通过 [[Prototype]] 连接到 Object.prototype ，这就是我们知道的原型链接。原型链接由下图中的 [[Prototype]] 表示。 第二步，添加一个名为 whoAmI() 的方法到这个 Foo.prototype 对象。 123Foo.prototype.whoAmI = function() &#123; return "I am " + this.name;&#125; 第三步，创建一个 Foo 对象的实例。 1var a = new Foo('a'); JavaScript 引擎在内部创建了一个新的对象，名为 a ，并通过原型链接将 a 对象连接到了 Foo.prototype 对象。 对象 a，Foo.prototype，和 Object.prototype 之间的连接就叫作原型链。 第四步，创建 Foo 对象的另一个实例 b。 1var b = new Foo('b'); 第步，在 b 对象中添加一个 say() 方法。 123b.say = function() &#123; console.log('Hi from ' + this.whoAmI());&#125; JavaScript 引擎在 b 对象中添加 say() 方法，而不是 Foo.prototype 对象。 现在看看下面的代码。 1console.log(a.constructor); // Foo 对象 a 没有 constructor 属性，所以 JavaScript 引擎会沿原型链向上查找。因为 a 对象通过原型链接连接到了 Foo.prototype， 并且 Foo.prototype 有 constructor 属性，JavaScript 引擎会返回 Foo。所以下面的 表达式结果为 true。 1console.log(a.constructor === Foo); // true 获取原型链接proto 是 Object.prototype 对象的一个访问器属性。它暴露了一个对象内部的原型链接（[[Prototype]]），同时也是通过原型链接被访问的。 proto 在 ES6 中被标准化，为了浏览器的兼容性。然而未来可能会被废除以支持 Object.getPrototypeOf() 。所以，最好不要在生产代码中使用 proto。 你可以在前面的图标中看到，a.proto 暴露了指向 Foo.prototype 的 [[Prototype]] 。相似的，b.proto 也指向了和 a.proto 相同的对象： 12console.log(a.proto === Foo.prototype); // trueconsole.log(a.proto === b.proto); // true 前面提到过，你应该使用 Object.getPrototypeOf() 方法而不是 proto 。Object.getPrototypeOf() 方法返回一个指定对象的原型。 1console.log(a.proto === Object.getPrototypeOf(a)); // true 在 Object.getPrototypeOf() 方法还不能用的时候，程序员经常使用的另一种获得原型链接的方法是通过 constructor 属性，如下： 1a.constructor.prototype a.constructor 返回 Foo，所以 a.constructor.prototype返回原型对象。 影子看看下面的方法调用。 1console.log(a.whoAmI()); // I am a a 对象没有 whoAmI() 方法，所以当 这个方法被从 a 调用时， JavaScript 引擎会沿着原型链向上查找，直到找到它。这样一来，就在 Foo.prototype 对象中发现并执行了这个调用。 我们在 a 对象中添加一个新的方法，和 Foo.prototype 对象中的方法名字相同。 123a.whoAmI = function() &#123; console.log('This is ' + this.name);&#125; 然后调用这个 whoAmI 方法： 1console.log(a.whoAmI()); // This is a 因为我们在 a 对象中有 whoAmI() 方法了， JavaScript 引擎不会在原型链中查找，而是立即执行调用。 这是一个关于 影子 的示例。a 对象的 whoAmI() 方法隐藏了 a 连接到的原型对象上的 whoAmI() 方法。 现在你就理解了关于 JavaScript 原型的所有重要概念，包括 原型链，原型链接，proto，以及影子。]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解JavaScript对象]]></title>
    <url>%2F2018%2F12%2F12%2F%E7%90%86%E8%A7%A3JavaScript%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[原文：Understanding JavaScript Objects 如果你写过 C++，Java 或者 C#，那你通常会定义类，类是对象的蓝图，然后从这个类创建一些跟这个类具有相同属性和方法的对象。 JavaScript 面向对象编程的方式有所不同。JavaScript 中没有其他面向对象编程语言中的类的概念（ES6中才开始定义了类）。 JavaScript 将对象定义为一组包含了初始值，对象与函数的属性的无序集合。换句话说，对象就是一组键值对（哈希），值就是数据或者函数。 对象可以在内部类或者用户定义类的基础上创建。创建一个自定义类的最简单的方法就是创建一个 Object 的实例，然后向其中添加属性和方法。 12345678910var machine = new Object(); // propertymachine.isOn = false; // methodmachine.start = function() &#123; this.isOn = true; console.log('Machine has been starting');&#125; 在这个例子中，我们定义了 Object 的一个 machine 实例，并且添加了 isOn 属性和 start() 方法。 另一个方法，可能是更简单的办法，就是用对象表达式创建一个对象。下面的例子创建的 machine 对象和前面例子中的 machine 对象是一样的。 1234567var machine = &#123; isOn: false, start: function() &#123; this.isOn = true; console.log('Machine has been starting'); &#125;&#125;; 属性的类型JavaScript 通过用两对方括号包围着内部属性来指定属性的特性，例如 [[Enumerable]]。JavaScript 有两种类型的属性：数据属性和访问器属性。 数据属性数据属性中包含数据值的单个地址。一个数据属性有四个元属性，描述如下： [[Configurarable]] – 决定一个数据属性是否可以被 delete 或者重定义操作删除。 [[Enumerable]] – 表示数据属性可以在 for…in 循环中遍历访问。 [[Writable]] – 指示数据属性的值是否可以被改变。 [[Value]] – 包含了数据属性实际的值。是该属性读取和写入值的位置。 默认情况下，直接在一个对象上定义的所有属性的[[Configurable]]，[[Enumerable]]，和 [[Writable]] 属性的值都被设置为 true 。[[Value]] 属性的默认值是 undefined。 为了改变一个属性的元属性，你可以使用 Object.defineProperty() 方法。Object.defineProperty() 方法接收三个参数： 被定义属性的对象 该对象上定义的属性的名称 元属性描述对象有四个属性: configurable, enumerable, writable, 和value 如果你用 Object.defineProperty() 方法来定义一个对象的属性，[[Configurable]], [[Enumerable]], 和 [[Writable]]的默认值都是 false ，除非专门指定。 1234var machine = &#123;&#125;;machine.isOn = false;delete machine.isOn;console.log(machine.isOn); // undefined 因为默认情况下 [[Configurable]] 属性的值为 true ，我们可以用 delete 操作负删除该属性。 下面的例子创建了一个 machine 对象，然后用 Object.defineProperty()方法添加了 isOn 属性。 12345678var machine = &#123;&#125;; Object.defineProperty(machine, 'isOn', &#123; configurable: false, value: false&#125;); delete machine.isOn; // undefined// Uncaught TypeError: Cannot delete property 'isOn' of #&lt;Object&gt; 上面的例子中，我们将 configurable 属性设置为 false ，因此删除 isOn 属性在严格模式中会报错。 另外，如果一个属性被设置为不可配置，它就不可能再变成可配置的了。如果用 Object.defineProperty() 方法来更改 writable 以外的任何属性，都会出错。 1234Object.defineProperty(machine, 'isOn', &#123; configurable: true&#125;);// Uncaught TypeError: Cannot redefine property: isOn 默认情况下，在对象上定义的所有属性的 enumerable 属性都是 true 。意味着你可以用 for…in 循环来遍历属性，如下所示： 12345678var machine = &#123;&#125;;machine.isOn = false;machine.name = 'computer'; for (var prop in machine) &#123; console.log(prop);&#125; // isOn// name 下面的代码通过将 enumerable 属性设置为 false ，让 name 属性变成不可遍历的。 123456789// make the name non-enumerableObject.defineProperty(machine, 'name', &#123; enumerable: false&#125;); for (var prop in machine) &#123; console.log(prop);&#125;// isOn 访问器属性和数据属性相同，访问器属性也有 [[Configurable]] 和 [[Enumerable]] 属性。然而，访问器属性有 [[Get]] 和 [[Set]] 属性而不是 [[Value]] 和 [[Writable]] 。 当你从访问器属性读取数据时， [[Get]] 方法被调用，返回一个值。[[Get]]方法的默认返回值是 undefined 。相似的，当你给属性赋值一个值时， [[Set]] 方法被调用。 要定义一个访问器属性，必须使用 Object.defineProperty()方法。看下面的例子： 12345678910111213141516171819202122232425var person = &#123; firstName: 'John', lastName: 'Doe'&#125; Object.defineProperty(person, 'fullName', &#123; get: function() &#123; return this.firstName + ' ' + this.lastName; &#125;, set: function(value) &#123; var parts = value.split(' '); if (parts.length == 2) &#123; this.firstName = parts[0]; this.lastName = parts[1]; &#125; else &#123; throw 'Invalid name format'; &#125; &#125;&#125;); console.log(person.fullName); // person.fullName = 'John Cho'; console.log(person.firstName); // Johnconsole.log(person.lastName); // Choconsole.log(person.fullName); // John Cho 定义多个属性你可以用 Object.defineProperty() 在单个表达式中定义多个属性。 1234567891011121314151617181920let product = &#123;&#125;; Object.defineProperties(product, &#123; name: &#123; value: 'iPhone' &#125;, price: &#123; value: 799 &#125;, tax: &#123; value: 0.1 &#125;, netPrice: &#123; get: function() &#123; return this.price * (1 + this.tax); &#125; &#125;&#125;); console.log('The net price of ' + product.name + ' is ' + product.netPrice.toFixed(2) + ' USD'); 获取属性的元属性ES5中引入了新的方法 Object.getOwnPropertyDescriptor() ，允许你用它来获取一个对象属性的描述对象。 Object.getOwnPropertyDescriptor() 方法接收两个参数：对象和对象的属性，返回对象的描述器。 1234var descriptor = Object.getOwnPropertyDescriptor(product, 'name'); console.log(descriptor.configurable); // falseconsole.log(descriptor.writable); // falseconsole.log(descriptor.enumerable); // falseconsole.log(descriptor.value); // iPhone]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript的数据类型转换]]></title>
    <url>%2F2018%2F12%2F10%2FJavaScript%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[简介JavaScript是一种松散类型。这并不意味着它就没有数据类型，只是变量的值或者 JavaScript 对象属性不需要为其分配特定类型的值，也不必总是保持相同的类型。JavaScript 可以自由地将一种类型的值转为他们使用变量的上下文中需要的类型。 JavaScript 的松散类型以及轻松的类型转换仍然拯救不了程序员们需要思考他们正在处理的值的实际类型。一个浏览器脚本中非常常见的错误就是，读取一个表单空间的 value 属性，用户应该在其中输入一个数字，然后将该值与另一个数字相加。因为表单空间的 value 属性其实是字符串（尽管其包含的字符序列表示的是一串数字），如果尝试将这串字符串与另一个值相加，即使另一个值碰巧是一个数字，结果也会导致第二个值被类型转换成一个字符串，然后拼接到第一个字符串的末尾。 这个问题源于 + 操作符的数字相加和字符串拼接的双重性质。因此，这个操作符的实际作用取决于上下文，只有操作符两边的操作数都是数字时， + 操作符才用作数值相加。除此之外，它都会将操作数转换成字符型，然后执行字符串拼接。 to Boolean在计算 if 表达式的时候，JavaScript 解释器会自动将表达式的运算结果转换为布尔类型。还有一些其他的操作符会将操作数转换为布尔型，包括逻辑操作符：&amp;&amp; ，|| ，! 。通常用 || 来得到一个表达时的布尔型转换值。 1var boolValue = !!x; 下面的表格也是用 || 来生成各种类型对应的布尔型。 还有一种生成布尔型值的方法是将值作为参数传入 Boolean 构造函数，这样得到的是一个布尔类型的包装对象而不是一个布尔的初始值了： 1var boolValue = Boolean(x); -1.6 -0 +0 1 1.6 8 16 16.8 123e-2 -Infinity +Infinity NaN !!col true false false true true true true true true true true false 数字转换成 bool 型时，0 为 false ，其他所有值都是 true。特殊数字 NaN 除外，它表示将其他类型转换为数字型时，转换无效不能得到有意义的数字。NaN 始终是 false 。Infinity 和 -Infinity 都是 true。 “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” !!col false true true true true true true true true true true true true true true 字符串转布尔型更简单，除空字符串以外，都是 true，空字符串是 false 。 undefined null true false new Object() function(){ return; } !!col false false true false true true 对于其他类型， undefined 和 null 转换为 false ，对象和函数始终是 true 。 这是类型转换为布尔型最有价值的方面，因为它允许脚本区分属性是未定义还是指向一个对象。经常用 if 语句将要访问的对象包裹起来测试对象是否未定义，以此来避免出错，如果对象未定义，则返回 false，如果已存在，则返回 true。 123if(document.documentElement)&#123; scrollX = document.documentElement.scrollLeft;&#125; to String上面讲到了，类型转换为字符串经常是由 + 操作符在其中一个操作数不是数字的情况下导致的。转换为字符传类型最简单的办法就是用该值拼接一个空字符串。我们用这个方法来生成下面的表格。 另一种方法是用 String 构造函数，这样得到的不是一个字符型的初始值，而是一个 String 类型的包装对象： 1var stringValue = String(x); -1.6 -0 +0 1 1.6 8 16 16.8 123e-2 -Infinity +Infinity NaN “” + col -1.6 0 0 1 1.6 8 16 16.8 1.23 -Infinity Infinity NaN 注意，上面表格中的源码 123e-2 转换后得到了字符串 1.23 ，这是因为 JavaScript 内部数字的字符串表示形式，然而 JavaScript 内部数字表示采用了 IEEE 标准规范的双精度浮点数字形式，这意味着 JavaScript 无法精确地表示所有数字。数学运算的结果可能产生近似值，当他们转换成字符串时，字符串可能出乎意料地表示为近似值。经常使用自定义函数来生成指定格式的数字字符串，类型转换机制很少适用于用来生成用于表示的数字输出。 undefined null true false new Object() function(){ return; } “” + col undefined null true false [object Object] function(){ return; } 当对象或者函数被转换成字符串时，会调用它们的 toString 方法。这个方法默认继承于 Object.prototype.toString 和 Function.prototype.toString，但是可以通过给对象/函数的 “toString” 属性赋值一个方法来重写。函数类型转换为字符串不一定会得到函数的源代码。Function.prototype.toString 因具体实现会有很大的不同，“宿主对象” 和方法（由环境提供的对象和方法，例如 DOM元素）也是如此。 to Number转换为数字类型，尤其是字符串转为数字，是非常常见的需求，有很多方法可用。除连接/加法操作符以外的任何数学运算操作符都会强制类型转换。所以字符串转数字可能要对数字字符串执行不影响结果数值的数学运算，例如减去 0 或者乘以 1。 12345var numValue = stringValue - 0;/* or */var numValue = stringValue * 1;/* or */var numValue = stringValue / 1; 然而，一元的 + 运算符也可以将操作数转换成数字，因为它不会做任何额外的数学运算，这是将字符串转换为数字的最快的方法。 顺便说一下，一元的 - （减法）操作符除了随后会取负其值以外，也会对操作数执行类型转换（必要的情况下）。 1var numValue = (+stringValue); 同样也可以调用 Number 构造函数，将字符串作为够攒函数的参数，返回一个数字的包装对象： 1var numValue = Number(stringValue); Number 构造函数是类型转换方法中最慢的一种，当速度不是最重要的考虑因素时，它的代码逻辑会比较清晰。 下面的表格使用一元 + 运算符生成。 “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” +col 0 -1.6 0 1 1.6 8 16 16.8 1.23 10 16 255 -10 NaN NaN 字符串转数字时最重要的考虑是结果可能不是数字。空字符转换成数字 0，取决于应用，这样做可能会带来危害。在其他上下文中，遵循 JavaScript 八进制数字格式的字符串（0 开头）可能会有问题，类型转换会将它们按10进制数字看待。然而遵循16进制数字格式的字符串（ox 或者 oX 开头）会读作 16 进制。不能被读作数字的字符串会被类型转换为 NaN ，NaN 的测试方法是另其不等于自身。指数计数格式（&quot;123e-2&quot;）的数字字符串与前导的负号一起被转换。 undefined null true false new Object() function(){ return; } +col NaN 0 1 0 NaN NaN 对象和函数始终转换成 NaN，undefined 也是如此，但是 null 会类型转换为 0。可能是因为它先转换为布尔型，然后转换为数字的，null 先转换成 false ，false 会转换成数字 0。几乎不可能会出现需要将这些类型转换成数字的情况。 Parsing to Number另一种转换字符串为数字的方法是使用一些设计用来返回一个数字的全局函数。parseFloat 函数接收一个字符串参数，将字符串解析为一个浮点数，并返回该浮点数。非字符参数会先按上面说的方式转换为字符串。 字符串解析函数会逐个字符地读取字符串直到遇到一个不能转换为数字的字符为止，这是它会停下来，并将已解析的可转换为数字的字符转换为数字，然后返回该数字。这个特性在某些情况下非常有用，例如，有一个代表 CSS 长度的值 34.5em ，parseFloat 会自动忽略 em ，因为这些字符不能与前面的数字字符合并转为数字。返回的值会是 34.5，CSS 字符串截取后不包含单位的数字部分。 parseFloat “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” parseFloat(col) NaN -1.6 0 1 1.6 8 16 16.8 1.23 10 0 0 -10 0 NaN parseFloat将空字符串以及不能进行数字解释的字符串转换为 NaN 。指数计数法格式可以被理解，八进制格式中的前导 0 不会妨碍字符串作为十进制数来解释。十六进制字符串解释为数字 0 ，因为后面跟着 x 不能解释为数字的一部分，所以解析在前导的 0 之后就结束了。 undefined null true false new Object() function(){ return; } parseFloat(col) NaN NaN NaN NaN NaN NaN 非字符串值会先被 parseFloat 转换为字符串。因为类型转换为字符串不会得到一个能解释为数字的字符串，所以结果是 NaN。对象和函数可能有自定义的 toString 方法，可能会返回能够进行数字解释的字符串，但那是非常规的需求。 parseIntparseInt 函数与 parseFloat 的作用非常相似，不同之处在于它尝试将字符串参数解释为整数，因此可以识别较少的字符作为该数字的一部分。 parseInt 偶尔被用于将一个浮点数转换为整数。它非常不适合这样用，因为如果它的参数是数字类型，它会先被转换成一个字符串，然后在转换成数字，非常低效。 2e-200这样的数字 可能会产生错误的结果 ，近似的整数是 0，但是 parseInt 返回了 2。由于 JavaScript 使用的数字格式，数字经常被表示为近似值。所以，例如 1/2+1/3+1/6 = 0.99999999999999，如果用 parseInt 来转换该表达式，会返回 0。 对于将数字舍入为整数，优先使用Math.round ，Math.ceil 和 Math.floor 这三个方法。 -1.6 -0 +0 1 1.6 8 16 16.8 123e-2 -Infinity +Infinity NaN parseInt(col) -1 0 0 1 1 8 16 16 1 NaN NaN NaN 当它作用于数字时，参数的初始值类型转换为字符串的过程在结果中体现地很明显。注意，123e-2 的内部数字是 1.23 ，类型转换为字符串得到 &quot;1.23&quot;，上面表格中的转换结果看上去奇怪，其实是正确的。 “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” parseInt(col) NaN -1 0 1 1 8 16 16 123 8 16 255 -8 -16 NaN 八进制和十六进制数字格式的字符串的确表示整数，并且parseInt能够根据 JavaScript 的源码解释它们，即使是以负号开头。 undefined null true false new Object() function(){ return; } parseInt(col) NaN NaN NaN NaN NaN NaN 由于 parseInt 会将非字符型参数类型转换为字符串，所以对于 boolean ，null，undefined 对象和函数类型的参数来说，parseInt 得到的结果总是与 parseFloat 相同（假设对象和函数没有自定义 toString 方法）。 有一个基数参数的 parseInt很少会允许 parseInt 推导出字符串中数字表示的基数，因为前导的 0 很少用于指示八进制格式的数据（尤其是在用户输入中）。为了解决这个问题，parseInt 能够识别第二个指示基数的参数，可以用于指定解释字符中数字的基数。第二个参数指定为 10 会导致 parseInt 以 10 为基数解释字符。 “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” parseInt(col, 10) NaN -1 0 1 1 8 16 16 123 10 0 0 -10 0 NaN 八进制格式的字符串现在可以以 10 为基数来解释，16 进制字符串则只能转换为 0 ，因为遇到 &quot;x&quot; 的时候，转换就会停止。 parseInt 可以用于以 2 到 36 为基数的数字。下面是以 16 为基数。 “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” parseInt(col, 16) NaN -1 0 1 1 8 22 22 4670 16 16 255 -16 -16 NaN 十六进制的 0x 格式在以 16 为解释基数时可以被识别。 最后以 3 为基数： -1.6 -0 +0 1 1.6 8 16 16.8 123e-2 -Infinity +Infinity NaN parseInt(col, 3) -1 0 0 1 1 NaN 1 1 1 NaN NaN NaN 数字参数转换为字符串的结果很明显。数字 8 转换为 NaN 是因为 &quot;8&quot; 这个字符不能以 3 为基数解释，得到一个为空的可接受字符的序列，产生与空字符串一样的结果。 “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” parseInt(col, 3) NaN -1 0 1 1 NaN 1 1 5 3 0 0 -3 0 NaN ToInt32ToInt32 是一个只在 JavaScript 实现中可用的内部函数，不能在脚本中以 parseInt 一样的方式直接调用。JavaScript 转换为数字时很少用到这个函数，但是一些情况下可以用到。按位操作符，例如按位或（|）和 按位与（&amp;）操作符作用于数字，所以它们会将操作数转换为数字。然而它们只能作用于 32 位有符号整型，所以对于给定的（可能是转换得到的）数字，它们会将它作为参数传入 ToInt32 函数，用返回值作操作数。返回的数字始终是一个 32 位有符号整型。 这种效果就像 parseInt 结合了类型转换为数字。然而结果只能限定在 32 位范围内，而且始终是数字，不可能是 NaN 或者 ±Infinity。 就像在对结果数值没有影响的操作中使用数学运算符一样，也可以在对 ToInt32 返回的结果没有影响的操作中使用按位操作符。下面的表格就是用 按位或 0 操作生成的。 -1.6 -0 +0 1 1.6 8 16 16.8 123e-2 -Infinity +Infinity NaN col\ 0 -1 0 0 1 1 8 16 16 1 0 0 0 NaN 和 ±Infinity 变成了 0 ，浮点数被截取成了整数。 “” (empty string) “-1.6” “0” “1” “1.6” “8” “16” “16.8” “123e-2” “010” (Octal) “0x10” (Hex) “0xFF” (Hex) “-010” “-0x10” “xx” col\ 0 0 -1 0 1 1 8 16 16 1 10 16 255 -10 0 0 类型转换为 NaN 的字符串会从 ToInt32 中返回 0 。 undefined null true false new Object() function(){ return; } col\ 0 0 0 1 0 0 0 甚至 undefined ，对象和函数都被这个操作转换为 0 。注意 布尔值 true 被转换成数字 1。 转换用户输入多数获得用户输入的机制，例如 &lt;input type=text&gt; 和 prompt 这些，提供了字符串格式的输入结果。如果希望用户输入一个数字，他们仍然可以输入任何东西（至少他们可能打错字）。如果字符串需要转换成数字用于后续的操作，上面提到的方法可以根据哪个最接近期待的用户输入来选择，但是一些由错误的输入得到的结果可能会难以识别和处理。 正则表达式示例123456789/^\d+$/ //All-digit/^\s*[-+]?\d+\s*$/ //Unbroken Signed integer &amp; spaces/^\d&#123;1,5&#125;$/ //1 to 5 digits/^\d+\.\d\d$/ //Money/^\d+(\.\d&#123;2&#125;)$/ //Money/^\d&#123;1,3&#125;(,\d\d\d)*\.\d\d$/ //comma-separated money - 12,432.57 // optional comma-separated money - 12,432.57 or 12432.57/^\d&#123;1,3&#125;(,\d\d\d)*\.\d\d$|^\d+\.\d\d$/]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript的数据类型]]></title>
    <url>%2F2018%2F12%2F10%2FJavaScript%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[JavaScript的两种类型JavaScript中有两种数据：初始值和对象。对象以外的类型就是初始值类型，初始值类型不包含方法。 JS中共有6中初始值类型：Boolean，Number，String，Null，Undefined，Symbol Boolean 布尔类型表示true 和 false 这两个值的其中一个，可以将布尔型想象成 开/关，或者是/否。 12var boo1 = true;var boo2 = false; NumberJavaScript中只有一种数字类型：基于 IEEE754标准的双精度64位二进制格式的值（-(263 -1) 到 263 -1）。数字类型不带小数点就是整数，JavaScript 没有为整数声明一种特殊的类型。除了能表示浮点数以外，还可以带符号的特殊值：Infinity， -Infinity， NaN（Not a Number） 。 12var num1 = 32;var num2 = +Infinity; String字符型用于表示文本数据，它由一组16位无符号整型数值表示的“元素”组成。字符型必须用单引号或者双引号括起来。在 JS 中，字符型是不可变的。修改一个字符串的过程是，创建一个改变过的新字符串，再将新字符串赋值给变量。 12var str1 = 'hello, it is me';var str2 = "hello, it's me"; NullNull 类型只有一个值：null。 1var nothing = null; Undefined已声明未赋值的变量的值就是 undefined， 也是其所述类型的唯一一个值。 12var testVar;console.log(testVar); // undefined Symbol符号类型是ES6新引入的类型。符号型是唯一的，也是不可变的初始值类型，只能用作对象属性的键，具体可以看这里 。 1const mySymbol = Symbol(&apos;mySymbol&apos;); 对象是什么?对象不是初始值类型。 对象是一组属性的集合。这些属性以键值对的形式保存。属性可以指向任意类型的数据，包括数值值和对象。 1234567var obj = &#123; key1: &apos;value&apos;, key2: &apos;value&apos;, key3: true, key4: 32, key5: &#123;&#125;&#125; 松散类型JavaScript 是一种松散类型的语言。这意味着你不必声明变量的类型。JavaScript自动替你决定变量类型。同时也意味着，变量类型是可以改变的。示例如下： 我们创建一个变量 car ，并给它赋值一个字符串： 1var car = &apos;ford&apos;; 然后，我们想要car保存它生产的年份，于是我们将 car 的值改成一个数字： 1car = 1998; 成功了，在JavaScript中你可以更随心所欲。因为它是松散类型的，我们可以随意改变变量类型。]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript现代模式，use strict]]></title>
    <url>%2F2018%2F12%2F02%2FJavaScript%E7%8E%B0%E4%BB%A3%E6%A8%A1%E5%BC%8F%EF%BC%8Cuse-strict%2F</url>
    <content type="text"><![CDATA[很久以来，JavaScript 的发展过程中都不存在兼容性问题。新特性不断添加，但是并没有改变旧的功能。 这样的好处就是永远不会破坏已有的代码。但是不好的一面是，任何由 JavaScript 作者带来的错误或者设计缺陷都将永远伴随这门语言。 直到 ECMAScript 5（ES5）出现，状况才有所改观。它新增了语言特性的同时也修改了一些旧的特性。为了让代码能够正常工作，多数改动都是默认关闭的。开发者需要用 use strict 指令显示地启用它们。 “use strict”这个指令看上去就像一个字符串：&quot;use strict&quot; 或者 &#39;use strict&#39; 。当它被放在脚本的顶部时，整个脚本就会以 现代的方式运行。 例如 1234"use strict";// this code works the modern way... &quot;use strict&quot; 也可以用在一个 function 的开头（大多数 fucntion）而不一定是脚本的起始位置。这样就会只在 function 内部启用严格模式。但是通常人们会对整个脚本使用严格模式。 确保 “use strict” 在代码顶部 务必保证 &quot;use strict&quot; 在代码顶部，否则严格模式不会启用。 下面的代码中就没有启用严格模式： 1234567&gt; alert("some code");&gt; // "use strict" below is ignored, must be on the top&gt; &gt; "use strict";&gt; &gt; // strict mode is not activated&gt; 只有注释可以出现在 &quot;use strict&quot; 的顶部。 不能取消 use strict 没有一个叫 &quot;no use strict&quot;或者类似的指令可以让 Javascript 返回旧的行为模式。 一旦我们进入了严格模式，就不能返回了。 始终“use strict” &quot;use strict&quot; 指令将引擎切换到 “现代” 模式，改变内置特性的行为。 &quot;use strict&quot; 出现在顶部会启用严格模式。也有一些语言特性，像 “class” 和 “module” 会自动启用严格模式。 所有浏览器都支持严格模式。 始终建议用 &quot;use strict&quot; 来开始编写脚本。]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS元素尺寸与滚动]]></title>
    <url>%2F2018%2F12%2F02%2FCSS%E5%85%83%E7%B4%A0%E5%B0%BA%E5%AF%B8%E4%B8%8E%E6%BB%9A%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[原文：Element size and scrolling 我们可以从很多 JavaScript 属性中得到关于元素宽度，高度和几何特性的信息。 当在 JavaScript 中移动或者定位元素时，我们需要这些信息来计算坐标。 示例元素我们将用会用下面的示例元素来演示这些属性： 123456789101112&lt;div id="example"&gt; ...Text...&lt;/div&gt;&lt;style&gt; #example &#123; width: 300px; height: 200px; border: 25px solid #E8C48F; padding: 20px; overflow: auto; &#125;&lt;/style&gt; 示例元素包含了 border，padding以及 scrolling。全套特性。这里没有 margin ，因为 margin 并不属于元素本身的一部分，对元素来说也不是特殊的属性。 这个元素长这样： 你可以 在sandbox中打开文档。 注意滚动条 上面这幅图展示了当元素包含一个滚动条时的最复杂的情况。一些浏览器（并不是所有）通过占据元素的空间来为滚动条保留空间。 所以，有滚动条的情况下，内容宽度是 300px，但是如果滚动条是 16px 宽（宽度可能会因浏览器或者设备而不同）则内容宽度就只会剩 300-16 = 284px ，我们应该考虑滚动条的宽度。这就是为什么这个示例中会包含一个滚动条。如果没有滚动条，事情就会简单一些了。 padding-bottom 可能会填充文字 通常情况下 padding 在插图中显示的是空白的，但是如果元素中存在大量文字，并且溢出了，浏览器就会在 padding-bottom 中显示溢出的文字，于是你就可以看到了。但是 padding 仍然存在于那里的，除非有其他指定。 几何提供宽度，高度以及其几何性质的元素属性的值都是数字。一般认为他们的单位是像素。 这里是整体的图片： 这里有很多属性，很难将它们展示在同一张图片中，但是他们的值很简单，也很容易理解。 我们从外向内来探索它们。 offsetParent, offsetLeft/Top这些属性很少需要用到，但是他们是最外层的几何属性，所以我们从它们开始说。 offsetParent 是距离最近的一个满足下述条件的祖先元素： 具有 CSS 定位（position 为 absolute， relative， fixed 或者 sticky）， 或者 &lt;td&gt;， &lt;th&gt;， &lt;table&gt;， 或者 &lt;body&gt;。 在大多数实际情况下，我们可以使用 offsetParent 来得到最近的 CSS 定位的 祖先元素。并且 offsetLeft / offsetTop 提供了相对于它的左上角的 x / y 坐标。 在下面的例子中，内部的 &lt;div&gt; 有一个 &lt;main&gt; 作为 offsetParent ， 并且 offsetLeft / offsetTop 从它的左上角移开了（180像素）: 12345678910&lt;main style=&quot;position: relative&quot; id=&quot;main&quot;&gt; &lt;article&gt; &lt;div id=&quot;example&quot; style=&quot;position: absolute; left: 180px; top: 180px&quot;&gt;...&lt;/div&gt; &lt;/article&gt;&lt;/main&gt;&lt;script&gt; alert(example.offsetParent.id); // main alert(example.offsetLeft); // 180 (note: a number, not a string &quot;180px&quot;) alert(example.offsetTop); // 180&lt;/script&gt; 有几种情况下 offsetParent 为 null ： 对于未显示的元素（display:none 或者不在文档中）。 对于 &lt;body&gt; 和 &lt;html&gt; 元素。 对于 position:fixed 的元素。 offsetWidth/Height 现在我们来看看元素本身。 这两个属性是最简单的。它们提供了元素的外部 width/height。或者，换句话说，包含 border 的完整尺寸。 对于我们的示例元素： offsetWidth = 390 – 外部宽度，可以计算为内部宽度（300px） + padding（2*20px）+ border （2*25px）。 offsetHeight = 290 – 外部高度。 未显示的几何属性的值为 0/null 几何属性只计算已显示的元素。 如果一个元素（或者它的任意祖先）有 display:none 或者不在文档中，则所有几何属性都是 0 或者 null，0 或者 null 取决于这个属性是什么。 例如，offsetParent 是 null ，offsetWidth ，offsetHeight 是 0。 我们可以用这个来检查一个元素是否隐藏，像这样： 123function isHidden(elem) &#123; return !elem.offsetWidth &amp;&amp; !elem.offsetHeight;&#125; 请注意，这个 isHidden 对于没有显示在屏幕上，但是大小为 0 的元素（例如一个空的 &lt;div&gt;）返回 true 。 clientTop/Left在这个元素内部，我们有 border 属性。 有 clientTop 和 clientLeft 属性可以用来测量它们。 在我们的示例中： clientLeft = 25 – 左边框宽度 clientTop = 25 – 上边框宽度 但是确切地说，它们并不是 border ，只是内侧于外侧的相对坐标。 有什么区别？ 当文档是从右指至左（操作系统时阿拉伯语或者希伯来语）时可见。滚动条将不会出现在右侧，而是在左侧，clientLeft 也包括了滚动条宽度。 在这种情况下， clientLeft 就不是 25 而是加上滚动条的宽度 25+16=41： clientWidth/Height这些属性提供了元素边界内部区域的尺寸。 它们包括了内容宽度，也包括了 padding ，但是不包括滚动条宽度： 在上面的图中，我们先看看 clientHeight：很容易计算。这里没有横向滚动条，所以就是边界内部各种长度的综合：CSS 高度 200px + top 和 bottom padding （2*20px），总共是 240px。 现在计算 clientWidth ，内容宽度不是 300px，而是 284px，16px 被滚动条占用了。所以 284px + 左右 padding ，总共是 324px。 如果没有 padding ，那么 clientWidth / Height 就直接是边界内部的内容区域和滚动条（如果存在）的宽度/高度。 所以当不存在 padding 时，我们可以用 clientWidth / clientHeight 来得到内容区域的大小。 scrollWidth/Height 属性 clientWidth / clientHeight 只对元素的可视部分有效。 元素 scrollWidth / scrollHeight 也包括了滚出（隐藏）的部分： 在上面的图中： scrollHeight = 723 – 是整个内容区域包括滚出部分的内部高度。 scrollWidth = 324 – 是整个内部宽度，这里我们没有横向滚动条，所以它就等于 clientWidth。 我们可以用这些属性来将元素宽度扩展为整个的宽度/高度。 像这样: 12// 将元素扩展到整个内容的宽度element.style.height = `$&#123;element.scrollHeight&#125;px`; 点击按钮来展开元素： text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text text textelement.style.height = ${element.scrollHeight}px scrollLeft/scrollTop属性 scrollLeft / scrollTop 是元素中隐藏的，滚出部分的 width/height。 在下面的图片中，我们可以看到一个具有垂直滚动条的块的 scrollHeight 和 scrollTop 。 换句话说，scrollTop 其实是 向上滚动了多少。 scrollLeft/scrollTop 可以被修改。 大多数几何属性都是只读的，但是 scrollLeft/scrollTop 可以被修订，并且浏览器将会滚动元素。 如果你点击下面的元素，代码 elem.scrollTop +=10 会执行。这会使元素内容向下滚动 10px。 > > ClickMe123456789 > > 设置 scrollTop 为 0 或者 Infinity 将会分别使元素滚动到 top/bottom 的位置。 不要用 CSS 取 width/height我们刚刚讲了 DOM 元素的几何属性。它们通常被用来获取宽度，高度以及计算 距离。 但是我们从 Style and classes 这一章知道了，可以用 getComputedStyle 来获取 CSS 的高度和宽度。 所以，为什么不能像这样读取元素的宽度呢？ 123let elem = document.body;alert( getComputedStyle(elem).width ); // show CSS width for elem 为什么我们应该使用几何属性？有两个原因： 首先，CSS 的 width/height 决定于另外一个属性：定义了 CSS 的 width 和 height “是什么的”box-sizing 。一个出于某种 CSS 目的的对 box-sizing 的改动就可能破坏了这段 JavaScript 代码。 第二，CSS width/height 可能是 auto，例如一个 inline 元素： 12345&lt;span id="elem"&gt;Hello!&lt;/span&gt;&lt;script&gt; alert( getComputedStyle(elem).width ); // auto&lt;/script&gt; 站在 CSS 的角度来看，width:auto 是非常正常的，但是在 JavaScript 中我们需要一个可以用来计算的精确的像素尺寸。所以这种情况下 CSS width 一点用处都没有。 也有一些其他的原因：滚动条。有时候代码在没有滚动条的时候工作地很好，出现滚动条时就出问题了，因为滚动条会在一些浏览器中会占据内容的空间。所以内容真正可用的空间比 CSS width 要少。 clientWidth / clientHeight 会考虑这一点。 但是对于 getComputedStyle(elem).width ，情况就不同了。一些浏览器（例如，Chrome）返回真正的实际的内部宽度，负的滚动条，一些浏览器（例如，火狐）返回 CSS width（忽略滚动条）。这样的跨浏览器差异就是不要使用 getComputedStyle ，而是依靠几何属性的原因。 如果你的浏览器保留了滚动条的空间（Windows的大多数浏览器都有），那么你可以在下面测试。 这个填充文字的元素有 CSS width:300px。 在一个 Windows 桌面操作系统中，Firefox，Chrome，Edge 全部保留了滚动条的空间。但是Firefox 显示 300px ，而 Chrome 和 Edge 显示的更少。这是因为 Firefox 返回的是 CSS width，其他浏览器返回的是 实际 宽度。 请注意，我们所说的只是关于用 JavaScript 读取 getComputedStyle(elem).width的差异 ，视觉上这些都是正确的。 总结元素有下面这些几何属性： offsetParent – 是距离最近的 定位 的祖先，或者 td, th, table, body。 offsetLeft/offsetTop – 相对于 offsetParent 左上角的坐标。 offsetWidth/offsetHeight – 一个元素包含 border 的“外部” width/height 。 clientLeft/clientTop – 从左上外角到左上内角的距离。对于从左至右的操作系统，它们总是左/上边界的宽度。对于从右至左的操作系统，垂直滚动条在左侧，所以 clientLeft 也包含滚动条的宽度。 clientWidth/clientHeight – 内容的 width/height ，包括 padding 但是不包括滚动条。 scrollWidth/scrollHeight – 内容的 width/height 包括滚出去的部分。也包括 padding 但是不包括滚动条。 scrollLeft/scrollTop – 元素滚出部分的 width/heigh ，从左上角开始。 All properties are read-only except scrollLeft/scrollTop. They make the browser scroll the element if changed. 所有属性都是只读的，除了 scrollLeft/scrollTop。如果发生改变，会让浏览器滚动元素。 任务底部滚动距离是多少？难度: 5 elem.scrollTop 属性是滚出部分的大小。如何得到 “scrollBottom ” — 也就是到底部的距离？ 写出对任意一个元素 elem 有效的代码。 P.S. 请检查代码：如果元素没有滚动，或者滚到底了，就要返回 0。 答案: 12&gt; let scrollBottom = elem.scrollHeight - elem.scrollTop - elem.clientHeight;&gt; 也就是: (全部高度) - (滚出的顶部高度) - (可见部分) – 这就是底部滚出距离。 滚动条宽度是多少？难度: 3 写代码，返回滚动条宽度： 对于 Windows 操作系统，这个值在 12px 和 20px 之间。如果浏览器不保留滚动条宽度，就可能是 0px。 P.S. 代码应该对任何 HTML 文档有效，不取决于内容。 为了得到滚动条宽度，我们可以创建一个元素，有滚动条，但是没有 border 和 padding 。 全宽 offsetWidth 和内容区域的宽度 clientWidth 之差就是滚动条的宽度了： 123456789101112131415&gt; // create a div with the scroll&gt; let div = document.createElement('div');&gt; &gt; div.style.overflowY = 'scroll';&gt; div.style.width = '50px';&gt; div.style.height = '50px';&gt; &gt; // must put it in the document, otherwise sizes will be 0&gt; document.body.append(div);&gt; let scrollWidth = div.offsetWidth - div.clientWidth;&gt; &gt; div.remove();&gt; &gt; alert(scrollWidth);&gt; 将球放到草坪中间难度: 5 这是原始文档的样子： 草坪中心的坐标是多少？ 计算中心坐标，然后将球放到草坪中心: 元素应该用 JavaScript 移动， 而不是 CSS。 代码应该适用于任意大小的球（10， 20， 30 像素），任意大小的草坪，不应该只是给定的值。 P.S. 当然，居中可以用 CSS 实现，但是这里我们只想用 JavaScript 。以后我们将会碰到其他的话题和更复杂的情况只能用 JavaScript。这里我们只是一个“热身”。 在sandbox中查看任务 这个球有 position:absolute ，意味着它的 left/top 坐标是相对于最近的定位祖先元素，那就是#草坪 （因为它有 position:relative）。 坐标从草坪内部的左上角开始： 草坪内部的 width/height 是 clientWidth/clientHeight所以草坪中心坐标是 (clientWidth/2, clientHeight/2)。 …但是如果我们设置 ball.style.left/top 为这样的值，那么并不是整个球，而是这个球的左上边缘在中间了: 123&gt; ball.style.left = Math.round(field.clientWidth / 2) + 'px';&gt; ball.style.top = Math.round(field.clientHeight / 2) + 'px';&gt; 这是它的样子 To align the ball center with the center of the field, we should move the ball to the half of its width to the left and to the half of its height to the top: 为了让球在草坪上居中，我们应该将球左移自身宽度的一半，再上移自身宽度的一半： 123&gt; ball.style.left = Math.round(field.clientWidth / 2 - ball.offsetWidth / 2) + 'px';&gt; ball.style.top = Math.round(field.clientHeight / 2 - ball.offsetHeight / 2) + 'px';&gt; 注意：陷阱！ 当 &lt;img&gt; 没有 width/height 时这段代码不可用： 12&gt; &lt;img src=&quot;ball.png&quot; id=&quot;ball&quot;&gt;&gt; 当浏览器不知道图片的 width/height 时（根据元素属性或者CSS），那么它会假设它们等于 0 直到图片完成加载。 在实际情况下，浏览器初次加载时常常会缓存图片，下次加载时它会立刻得到大小。 但是第一次加载时 ball.offsetWidth 的值时 0 。这会导致错误的坐标。 We should fix that by adding width/height to &lt;img&gt;: 我们应该通过给 &lt;img&gt; 添加 width/height 来解决: 12&gt; &lt;img src="ball.png" width="40" height="40" id="ball"&gt;&gt; …或者在 CSS 中提供大小： 12345&gt; #ball &#123;&gt; width: 40px;&gt; height: 40px;&gt; &#125;&gt; 在sandbox中查看答案 对比: CSS width VS clientWidth难度: 5 getComputedStyle(elem).width 和elem.clientWidth有什么不同？ 给出至少 3 个差异。越多越好。 差异: clientWidth是数值，而getComputedStyle(elem).width 返回一个以 px 结尾的字符串。 getComputedStyle 可能对内联元素返回非数字，像 &quot;auto&quot;。 clientWidth 是元素内部的内容区域加上内边距，而 CSS width (在标准 box-sizing下) 是内部内容区域 不包含内边距。 如果存在滚动条，并且浏览器保留了滚动条的空间，一些浏览器从 CSS width 减去滚动条宽度（导致内容宽度 受到影响），一些浏览器不会这样做。clientWidth 属性总是一致的：滚动条大小被减去了，如果保留了的话。]]></content>
      <categories>
        <category>FE</category>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React中用Index做列表的key值是反模式]]></title>
    <url>%2F2018%2F11%2F19%2FReact%E7%94%A8Index%E5%81%9A%E5%88%97%E8%A1%A8%E7%9A%84key%E5%80%BC%E6%98%AF%E5%8F%8D%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[翻译原文：Index as a key is an anti-pattern 经常见到程序员用 index 作为列表项的 key 值传给 React 来渲染列表： 123456&#123;todos.map((todo, index) =&gt; &lt;Todo &#123;...todo&#125; key=&#123;index&#125; /&gt;)&#125; 这看起来还比较优雅，的确也消除了警告。但是这里有什么危险？ 它可能会破坏你的应用，甚至显示错误数据 让我来解释一下， key 是 React 用来区分 DOM 元素的唯一标识。如果你在中途向 list 中增加了一个 元素，或者删除了一些东西，会发生什么？如果更新后的 key 的值跟之前是一样的，那 React 就会认为这个 key 对应的 DOM 元素和之前是一样的。但是实际上不是。 为了证明这种潜在的危险，我创建了一段简单的示例代码。 结果表名，当没有传 key 的时候，React 默认使用 index 作为 key ，因为此时这是最合适的选择。而且 React 会警告你，这不是最理想的（这个警告说的有点容易让人误解）。如果你提供了 index 作为 key 值，React 就会认为你知道自己在做什么，想想上面的示例代码，这会导致不可预测的后果。 更好的办法每一个这样的项目都应该有一个永恒的唯一的属性。理想情况下，应该在被创建的时候就赋值。当然，我说的是这个 id。然后我们就可以像下羡慕这样来用它了： 1234&#123;todos.map((todo) =&gt; &lt;Todo &#123;...todo&#125; key=&#123;todo.id&#125; /&gt;)&#125; 注意：首先看看列表项的已有属性。他们很可能已经有一些可以用来当作 id 的属性了。 一个办法就是在抽象中用一个递增的数值来代替 id。用一个全局的 index 来保证任意两个列表项都有不同的 id。 12345678todoCounter = 1;function createNewTodo(text) &#123; return &#123; completed: false, id: todoCounter++, text &#125;&#125; 比更好还要好的办法在生产环境中应该用一种更具有鲁棒性的方法，要能处理列表项的分布式创建。对这种情况，我推荐使用 shortid 类库。它可以快速生成 “短小的非序列且 URL 友好的唯一” id。代码如下： 12345678var shortid = require('shortid');function createNewTodo(text) &#123; return &#123; completed: false, id: shortid.generate(), text &#125;&#125; 长话短说：为每一个列表项生成一个唯一 id，并在渲染列表的时候将它设置为 key。 更新：例外情况 许多人会问他们是否总是需要生成 id。还有一些人建议了一些非常适合用 index 来作为 key 的用例。 的确，有的时候生成新的 id 是多余的，也可以避免。例如许可条款和贡献者列表的翻译。 为了帮你做决定，我将这些示例共有的三个条件放在一起： 列表和列表项都是静态的-不是计算出来的值，也不会改变； 列表中的列表项没有 id； 列表不可能会创新渲染，也不会发生过滤。 如果满足上面的全部，你就可以安全地用 index 了当 key 值了。 更新2: React，Preact 和 *react 尽管这篇文章写的是关于 React 的，但是这个问题却不局限于 React。在相似的类库中，例如 Preact，也同样存在这中问题。尽管效果可能不同。 相关文章 Dynamic Children and Keyed Fragments in React Docs Explanation from Paul O’Shannessy The importance of component keys in React.js React.js and Dynamic Children — Why the Keys are Important React animations for a single component, section The key is using key Why you need keys for collections in React by Paul Gray]]></content>
      <categories>
        <category>FE</category>
        <category>React</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在Node.js中启用ES6 Import]]></title>
    <url>%2F2018%2F11%2F16%2F%E5%A6%82%E4%BD%95%E5%9C%A8Node-js%E4%B8%AD%E5%90%AF%E7%94%A8ES6-Import%2F</url>
    <content type="text"><![CDATA[到目前，Node.js 还没有支持 ES6 的 import 模块。但是你可以通过 Babel 的协助来使用它。 下面是一个 express.js server 的示例。 1. 安装依赖1npm install babel-register babel-preset-env --save-dev 2. 改造Server.js这是 server.js 的示例代码 12345678910const express = require('express')const app = express()// respond with "hello world" when a GET request is made to the homepageapp.get('/', function (req, res) &#123; res.send('hello world')&#125;)app.listen(3000, () =&gt; console.log('Example app listening on port 3000!'))copy 我们用 ES6 import 代替 require(…) 12345678910import express from 'express'const app = express()// respond with "hello world" when a GET request is made to the homepageapp.get('/', function (req, res) &#123; res.send('hello world')&#125;)app.listen(3000, () =&gt; console.log('Example app listening on port 3000!'))copy 如果你现在就执行 node server.js , 还是会报错 SyntaxError: Unexpected token import 。之所以这样是因为我们还没有让 Babel 在 Node.js 代码中生效，还需要进一步配置。 3. 添加一个入口文件 start.js这个文件会充当我们的 Node.js 应用程序的入口，其中包含了注册 babel 的代码： 12345678// Transpile all code following this line with babel and use 'env' (aka ES6) preset.require('babel-register')(&#123; presets: [ 'env' ]&#125;)// Import the rest of our application.module.exports = require('./server.js')copy And that’s all, from now on, instead of running node server.js, start your app as node start.js and you will get a hassle-free ES6 Imports support in your node.js application. 到这里就差不多了，现在要运行 node start.js 而不是 node server.js 了，你的 node.js 应用程序就可以无障碍地使用 ES6 import 模块了。]]></content>
      <categories>
        <category>FE</category>
        <category>ES6</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[指针基础]]></title>
    <url>%2F2018%2F11%2F16%2F%E6%8C%87%E9%92%88%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[翻译原文：Pointer Basics 这是翻译的斯坦福大学官网上的 CSLibrary 中的一篇课程文档 这个文档介绍指针的基础知识，因为很多计算机语言中都会用到它，例如：C，C++，Java，以及 Pascal。 Section 1 – 指针的三个基本规则 Section 2 – 一个简单的代码示例 Section 3 – 习题和答案 这是 Stanford CS Education Library 的106号文档。其他免费资料在 cslibrary.stanford.edu 中可以获取到。 1 – 指针规则1关于指针，好的地方是控制他们工作的规则非常简单。这些规则可以组合得到复杂的结果，但是单个的规则还是很简单。 1) 指针与指针对象指针存放了对一些东西的引用 。不幸的是，指针指向的目标还没有一个固定的术语，不同的计算机语言中，指针指向的内容很多。我们用术语 指针对象 来代指指针指向的事物，我们就来研究一下那些在所有语言中都正确的 指针/指针对象 关系的基本性质。术语 “引用”和 “指针”的意思非常相似——“引用”意在更高层的讨论，而“指针”是指传统的编译语言对地址指针的实现。对于这里所讲的基本的 指针/指针对象 规则，这两个术语可以认为是等同的。 上面的图中画出了一个名为 x 的指针，指向了一个保存了数值42 的指针对象。指针通常被画成一个矩形盒子，指针中保存的引用被画成一个箭头，从指针的盒子开始，指向它的指针对象。 分配指针和给指针分配指针对象是分开的两个步骤。你可以认为 指针/指针对象 结构是在两个层级的操作。两个层级都必须设置才能正常工作。最常见的错误集中于编写手动操作指针的代码时，忘记了设置指针对象。有时候不接触指针对象的指针操作被称为“浅”，而操作指针对象的指针操作称为“深”。 2) 解引用解引用 操作从指针开始，沿着箭头一直访问到它的指针对象。目的可能是查看指针对象的状态或者改变指针对象的状态。 对一个指针执行的解引用操作只在这个指针有一个指针对象——这个指针对象必须已经被分配并且指针必须已经设置为指向它—— 的情况下有效。最常见的错误就是代码中忘记为指针设置指针对象。在 Java 中，运行时会礼貌地标记错误的解引用。在编译语言中，例如 C，C++，和Pascal中，错误的解引用有时会崩溃，有时会以一些微妙而随机的方式破坏内存。因此编译语言中的指针异常很难追踪。 3) 指针赋值两个指针之间的 指针赋值 会使他们指向同一个指针对象。所以 y=x; 的赋值会让 y 指向与 x 相同的指针对象。指针赋值不接触指针对象。它只是改变一个指针来让它拥有与其他指针相同的引用。指针赋值后，这两个指针被称为 共享 指针对象。 2 – 代码示例有不同计算机语言的代码示例。所有的版本都有相同的结构，证明相同的基本规则和指针只是；他们只有语法上的不同。不考虑特定语言，示例的基本结构如下… 1. 分配 x 和 y 两个指针。让他们不指向任何指针对象。 2. 分配一个指针对象，然后设置 x 指向它。每种语言都有自己的语法来实现这一步操作。重要的是指针对象的内存是动态分配的，然后让x 指向这个指针对象 3.解引用 x 将42保存到指针对象中。这是解引用操作的基本示例。从 x 开始，沿着箭头方向访问到指针对象。 4. 尝试解引用 y 来保存 13 到指针对象中.这一步会崩溃——因为它还没有被赋值一个指针对象。 5. 赋值 y=x; 让 y 指向 x 的指针对象。现在 x 和 y 指向了相同的指针对象——他们是共享的。 6. 尝试解引用 y 来保存 13到指针对象中。这一次成功了，因为上一步赋值操作为 y 分配了指针对象。 版本下面是不同语言版本的示例。他们做了相同的事情——只是每种语言的语法不同。 C 版本指针 x 和 y 分配成本地变量。类型 int* 表示“指针指向 int 类型”。指针不会自动得到指针对象。x 的指针对象是另外用标准库 malloc() 动态分配的。语法 *x 解引用 x 来访问它的指针对象。 123456789101112131415void main() &#123; int* x; // Allocate the pointers x and y int* y; // (but not the pointees) x = malloc(sizeof(int)); // Allocate an int pointee, // and set x to point to it *x = 42; // Dereference x to store 42 in its pointee *y = 13; // CRASH -- y does not have a pointee yet y = x; // Pointer assignment sets y to point to x's pointee *y = 13; // Dereference y to store 13 in its (shared) pointee&#125; C语言（或者C++）中另一种使用指针的方式是使用 &amp; 符号（ampersand ）运算符来计算栈中指向本地内存的指针。然而，指针对象通常是在堆中动态分配的，所以这就是我们展示的。 Java 版本Java中最常见的 指针/指针对象结构是一个本地变量作为指针，指向一些类的对象作为指针对象。所以为了按计划创建一个保存了整数类型的指针对象，我们定义一个 IntObj 类来保存一个整型。然后我们可以创建一个 IntObj 指针对象来保存 int。用 IntObj x; 这样的代码来分配指针不会自动分配指针对象。 IntObj 指针对象通过调用 new 来分配。x.value 解引用 x 来访问指针对象中的 .value 字段。 123456789101112131415161718192021class IntObj &#123; public int value;&#125;public class Binky() &#123; public static void main(String[] args) &#123; IntObj x; // Allocate the pointers x and y IntObj y; // (but not the IntObj pointees) x = new IntObj(); // Allocate an IntObj pointee // and set x to point to it x.value = 42; // Dereference x to store 42 in its pointee y.value = 13; // CRASH -- y does not have a pointee yet y = x; // Pointer assignment sets y to point to x's pointee y.value = 13; // Deference y to store 13 in its (shared) pointee &#125;&#125; C++ 版本与 上面 C 语言版本唯一的不同是使用了标准操作符 new 来代替 malloc() 123456789101112131415void main() &#123; int* x; // Allocate the pointers x and y int* y; // (but not the pointees) x = new int; // Allocate an int pointee, // and set x to point to it *x = 42; // Dereference x to store 42 in its pointee *y = 13; // CRASH -- y does not have a pointee yet y = x; // Pointer assignment sets y to point to x's pointee *y = 13; // Dereference y to store 13 in its (shared) pointee&#125; Pascal 版本这跟 C 语言版本在结构一致，但是使用了 Pascal 语法。^Integer 意思是“指向整型的指针”。分配指针不会自动分配它的指针对象。标准程序 New() 取一个指针参数，分配一个新的指针对象，设置指针指向这个指针对象。表达式 x^ 解引用访问这个指针对象。 1234567891011121314Procedure main var x:^Integer; /* Allocate the pointers x and y */ var y:^Integer; /* (but not the pointees) */Begin New(x); /* Allocate a pointee and set x to point to it */ x^ := 42; /* Deference x to store 42 in its pointee */ y^ := 13; /* CRASH -- y does not have a pointee yet */ y := x; /* Pointer assignment makes y point to x's pointee */ y^ := 13; /* Dereference y to store 13 in its (shared) pointee */End; 3 – 习题这些习题考察指针的基本特性。其中两个问题大量使用内存图。内存图是思考指针问题的很好的方法。 Question 1在上面代码的末尾，y 被指定了一个指针对象，然后解引用它保存数字13到指针对象中，在这发生后，x 的指针对象的值是多少？ 答案：13，因为 x 的指针对象也是 y 的指针对象，这就是指针共享的全部作用——多个指针指向一个指针对象。 Question 2思考下面这张图… 选择中语言，写代码创建上面的指针结构。 答案：基本步骤是… 分配两个指针 分配两个指针对象，然后设置两个指针分别指向他们 保存数字 1 和 2 到这两个指针对象中 赋值第一个指针指向第二个指针对象。这会丢失对第一个指针对象的引用，这是很少见的，但题目就是这样要求的。 C Code 123456789&#123; int* x; int* y; x = malloc(sizeof(int)); y = malloc(sizeof(int)); *x = 1; *y = 2; x = y;&#125; Java Code 123456789&#123; IntObj x; IntObj y; x = new IntObj(); y = new IntObj(); x.value = 1; y.value = 2; x = y;&#125; Question 3假设你有一个指针对象叫作 “Node”，包含两个东西，一个 int 和一个 指向另一个 Node 的指针（这个Node 类型的的定义在下面）。你可以用这样的指针对象类型在一个结构中构造三个 Node 互相指向的指针对象，像这样… 名叫 x 的指针指向第一个 Node 指针对象。第一个 Node 包含一个指针指向第二个 Node ，第二个包含一个指针指向第三个 Node ，第三个 Node 又包含一个指针指向了第一个 Node。这个结构只能用我们已经见过的指针对象分配，解引用和赋值的规则来创建。使用下面的定义，每一个 Node 都包含了一个 Integer 名为 value ，和一个指针指向另一个名为 next 的 Node。 C Code 1234struct Node &#123; int value; struct Node* next; &#125;; Java Code 1234class Node &#123; public int value; public Node next;&#125;; 写代码创建上面图中的结构。为了方便，你可以使用 x 以外的临时指针来访问指针对象中的字段——所以 -&gt;value 访问 x 指针对象中的 名为value 字段。 Answer The basic steps are… 答案 基本步骤… 分配三个指针：x 指向第一个 Node，然后临时指针 y 和 z 指向其他两个 Node。 分配三个 Node 指针对象并保存他们的解引用到三个指针中。 解引用每一个指针对象，保存合适的数值到其指针对象的 value 字段中。 解引用每个指针来访问其指针对象中的 .next 字段，并使用指针赋值来设置 .next 字段指向合适的 Node。 C Code 123456789101112131415161718&#123; // Allocate the pointers struct Node* x; struct Node* y; struct Node* z; // Allocate the pointees x = malloc(sizeof(Node)); y = malloc(sizeof(Node)); z = malloc(sizeof(Node)); // Put the numbers in the pointees x-&gt;value = 1; y-&gt;value = 2; z-&gt;value = 3; // Put the pointers in the pointees x-&gt;next = y; y-&gt;next = z; z-&gt;next = x;&#125; Java Code 123456789101112131415161718&#123; // Allocate the pointers Node x; Node y; Node z; // Allocate the pointees x = new Node(); y = new Node(); z = new Node(); // Put the numbers in the pointees x.value = 1; y.value = 2; z.value = 3; // Put the pointers in the pointees x.next = y; y.next = z; z.next = x;&#125; 这里介绍的 Node 结构实际上是一种真实的数据类型，被用来创建 “链表” 数据结构。链表是指针的实际应用的用途，是提升指针技能的绝佳领域。看Stanford CS Library 中的Linked List Basics 和 Linked List Problems 了解更多链表知识。 Up to the CS Education Library Home]]></content>
      <categories>
        <category>Language</category>
        <category>C</category>
      </categories>
      <tags>
        <tag>Langauge</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见面试算法题]]></title>
    <url>%2F2018%2F11%2F15%2F%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E7%AE%97%E6%B3%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[算法常常被拿来考察程序员的编程功底，即便是前端，找工作的时候一些大厂也会出几道算法题来刁难一下你，毕竟好的工作资源相对较少，想要从一众求职者中脱颖而出，只掌握了大家都会的技能是不够的。面试官要从应聘者中挑出最优秀的人，也就要用更难的题来筛选。所以即使前端用到算法的地方屈指可数，想要提升自己，得到更好的机会，就得去学习更底层的知识。 持续更新。。。 大数相加描述对于两个超过了JS安全范围的整数，用加法求和并不能得到准确的结果，现在希望写一种方式能够对两个超过了JS安全范围的整数求和得到准确的结果。 思路将大数保存到两个数组中，然后按位从底到高依次累加进位，将每一位的计算结果保存到一个新的数组中，一开始根据自己的理解实现了一个版本，数组迭代都用的索引，写起来繁琐，而且极其容易出错，代码如下： 123456789101112131415161718192021222324252627function addbig(a,b)&#123; let arrA = Array.from(a+“”); let arrB = Array.from(b+“”); let la = arrA.length; let lb = arrB.length; let lm = Math.max(la,lb); let delta = 0; let result = []; for(var i = 0;i&lt;lm;i++)&#123; var a = getItem(arrA,i); var b = getItem(arrB,i); var sum = a + b + delta; result[lm-1-i] = sum&lt;10?sum:sum-10; delta = sum&lt;10?0:1; &#125; if(delta&gt;0)&#123; result.unshift(1); &#125; return Number.parseInt(result.join(''));&#125;function getItem(arr,index)&#123; let n = arr.length; if(index &lt; n)&#123; return Number.parseInt(arr[n-1-index]) &#125; return 0;&#125; 后来使用 JavaScript Array 原生接口来代替一些循环迭代，用 + 操作符代替parseInt的类型转换，巧用 / 和 % 运算符来取整和求余 ，优化后的代码只剩不到二十行，简洁清晰 1234567891011121314151617function addbig(a,b)&#123; let arrA = Array.from(a.toString()); let arrB = Array.from(b.toString()); let i = Math.max(arrA.length,arrB.length); let delta = 0; let result = []; while(i&gt;0)&#123; var sum = (+arrA.pop() || 0) + (+arrB.pop()||0) + delta; result.unshift(sum % 10); delta = parseInt(sum/10); i--; &#125; if(delta)&#123; result.unshift(delta); &#125; return +result.join('');&#125; 再次优化，将取两个数值字符串中最大长度变成取最小长度，可以减少遍历次数 1234567891011121314function addbig(a,b)&#123; let arrA = Array.from(a.toString()); let arrB = Array.from(b.toString()); let i = Math.min(arrA.length,arrB.length); let delta = 0; let result = []; while(i--)&#123; var sum = (+arrA.pop() || 0) + (+arrB.pop()||0) + delta; result.unshift(sum % 10); delta = parseInt(sum/10); &#125; result.unshift(+arrA.join('') || +arrB.join('')+delta); return +result.join('');&#125;]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解inline元素的CSS盒模型]]></title>
    <url>%2F2018%2F11%2F14%2F%E7%90%86%E8%A7%A3inline%E5%85%83%E7%B4%A0%E7%9A%84CSS%E7%9B%92%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[原文：Understanding the CSS box model for inline elements ​ 页面上的每一个元素都会被浏览器渲染成一个个的矩形的盒子。box model解释了元素的 content, padding, border, 和 margin 是如何决定元素占据的空间以及与页面上其他元素之间的关系。 ​ 页面元素因 display 属性设置不同可能出现两种类型：block box（块级元素）或者 inline box（内联元素）。盒模型对这两种类型的处理方式不同。本文就聊一聊盒模型如何作用于 inline box。 Inline box 和 line boxinline box 横向分布于 line box 中： 如果水平方向没有足够的空间来将所有元素在一行内显示，浏览器就会在当前行的后面创建一个新的 line box。一个 inline 元素就有可能被拆分到两行中： inline box 的盒模型​ 当 inline box被拆分成多行的时候，它在逻辑上仍然是一个盒子。这就是说，任何水平的 padding, border, 或者 margin 的设置只会作用于元素占据的第一行的起始位置和最后一行的末尾。 ​ 例如，在下面的截图中，高亮的 span 被分成了 2 行。水平的 padding 没有作用于第一行的末尾，也没有作用于第二行的开头。 ​ 对 inline 元素设置的任何垂直的 padding, border, 或者 margin 都不能将元素上下的相邻元素推开： ​ 然而，请注意垂直的 padding 和 border 仍然应用了，padding 也将border 推开了： 如果你需要调整行距，要用 line-height 。]]></content>
      <categories>
        <category>FE</category>
        <category>HTML</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>HTML</tag>
        <tag>Inline</tag>
        <tag>Box</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript对象拷贝的误区]]></title>
    <url>%2F2018%2F11%2F14%2FJavaScript%E5%AF%B9%E8%B1%A1%E6%8B%B7%E8%B4%9D%E7%9A%84%E8%AF%AF%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[JavaScript 对象拷贝暗藏陷阱，JavaScript 提供了许多种方式来拷贝一个对象，但非都是深拷贝，大多数情况下浅拷贝是默认行为。 深拷贝 VS 浅拷贝​ 浅拷贝能够成功地复制数字和字符串等原始值 （基本类型），但是不会递归地复制任何对象的引用，而是复制得到的新对象将会引用之前的同一个对象。 ​ 如果一个对象 A 引用了另一个对象 B ，当对对象 A 执行 浅拷贝 的时候，你只是拷贝了对 B 的引用，复制得到的新对象仍然引用了 B 。 ​ 当执行深拷贝的时候，外部的 B 对象也会一并拷贝，所以新复制得到的对象是完全独立于 B 对象的。 最简单的选择：使用 Lodash建议工作中执行深拷贝时最好用一些经过严格测试的第三方类库，比如很受欢迎的一直在维护的：Lodash。 Lodash 提供了非常方便的 clone 和 deepclone 函数来实现浅拷贝和深拷贝。 Lodash 有一个很棒的特性：你可以只导入单个函数来降低你的项目依赖数量。 在 Node.js 中： 12const clone = require('lodash.clone')const clonedeep = require('lodash.clonedeep') 这里是两个函数的使用示例： 1234567891011121314151617181920212223242526272829303132333435363738const clone = require('lodash.clone')const clonedeep = require('lodash.clonedeep')const externalObject = &#123; color: 'red'&#125;const original = &#123; a: new Date(), b: NaN, c: new Function(), d: undefined, e: function() &#123;&#125;, f: Number, g: false, h: Infinity, i: externalObject&#125;const cloned = clone(original)externalObject.color = 'blue'console.info('⬇️ shallow cloning 🌈')console.info( '✏️ Notice the i.color property we changed on original is also changed in the shallow copy')console.log(original)console.log(cloned)const deepcloned = clonedeep(original)externalObject.color = 'yellow'console.log('')console.info('⬇️ deep cloning 🌈')console.info('✏️ Notice the i.color property does not propagate any more')console.log(original)console.log(deepcloned) In this simple example we first create a shallow copy, and edit the i.color property, which propagates to the copied object. In the deep clone, this does not happen. See this live in Glitch. Object.Assign()Object.assign() 执行浅拷贝，不是深拷贝. 1const copied = Object.assign(&#123;&#125;, original) Being a shallow copy, values are cloned, and objects references are copied (not the objects themselves), so if you edit an object property in the original object, that’s modified also in the copied object, since the referenced inner object is the same: 浅拷贝只会复制值类型和对象类型的引用（而不是对象本身）。所以如果你编辑了原始对象的属性，复制对象中的这个属性也会被修改，因为原始对象和复制对象内部的引用指向是相同的： 12345678910111213const original = &#123; name: 'Fiesta', car: &#123; color: 'blue' &#125;&#125;const copied = Object.assign(&#123;&#125;, original)original.name = 'Focus'original.car.color = 'yellow'copied.name //Fiestacopied.car.color //yellow 使用对象展开表达式这个 ES6/ES2015 特性提供了非常方便的浅拷贝方法，它和Object.assign() 做的事情相同。 1const copied = &#123; ...original &#125; 错误的方式使用 Object.create() 不推荐这样实现对象拷贝 1const copied = Object.create(original) ​ 这是错误的做法，它并没有做任何拷贝的操作。 ​ 相反, original 对象会被当成 copied 对象的 prototype 。 ​ 表面上它可以成功，但是实际上没有： 12345678const original = &#123; name: 'Fiesta'&#125;const copied = Object.create(original)copied.name //Fiestaoriginal.hasOwnProperty('name') //truecopied.hasOwnProperty('name') //false JSON 序列化 也不推荐 ​ 网上有一些建议是将对象转换成 JSON，然后再从 JSON 反向生成对象 1const cloned = JSON.parse(JSON.stringify(original)) ​ 但是这样做可能有预料不到的后果： ​ 这样做你可能会失去任何在 JSON 中找不到对等类型的 JavaScript 属性，比如 Function 或者 Infinity。 任何赋值为 undefined 的属性也会直接被 JSON.stringify 忽略掉，导致这些属性在复制对象中消失了。 ​ 此外，也有一些对象只是简单地转成字符串，例如 Date 对象（同样，不考虑时区，默认为UTC），Set，Map以及许多其他类型： 123456789101112JSON.parse( JSON.stringify(&#123; a: new Date(), b: NaN, c: new Function(), d: undefined, e: function() &#123;&#125;, f: Number, g: false, h: Infinity &#125;)) 这种方式只适用于对象不包含任何内部对象和函数，只有值类型的情况。 下面是用原生 JS 手动实现的两种深拷贝的方式 1234567891011121314151617181920var array = [ &#123; number: 1 &#125;, &#123; number: 2 &#125;, &#123; number: 3 &#125;];function copy (obj) &#123; var newobj = obj.constructor === Array ? [] : &#123;&#125;; if(typeof obj !== 'object')&#123; return; &#125; for(var i in obj)&#123; newobj[i] = typeof obj[i] === 'object' ? copy(obj[i]) : obj[i]; &#125; return newobj&#125;var copyArray = copy(array)copyArray[0].number = 100;console.log(array); // [&#123;number: 1&#125;, &#123; number: 2 &#125;, &#123; number: 3 &#125;]console.log(copyArray); // [&#123;number: 100&#125;, &#123; number: 2 &#125;, &#123; number: 3 &#125;] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253(function($) &#123; 'use strict'; var types = 'Array Object String Date RegExp Function Boolean Number Null Undefined'.split(' '); function type() &#123; return Object.prototype.toString.call(this).slice(8, -1); &#125; for (var i = types.length; i--;) &#123; $['is' + types[i]] = (function(self) &#123; return function(elem) &#123; return type.call(elem) === self; &#125;; &#125;)(types[i]); &#125; return $;&#125;)(window.$ || (window.$ = &#123;&#125;)); //类型判断function copy(obj, deep) &#123; if (obj === null || (typeof obj !== "object" &amp;&amp; !$.isFunction(obj))) &#123; return obj; &#125; if ($.isFunction(obj)) &#123; return new Function("return " + obj.toString())(); &#125; else &#123; var name, target = $.isArray(obj) ? [] : &#123;&#125;, value; for (name in obj) &#123; value = obj[name]; if (value === obj) &#123; continue; &#125; if (deep) &#123; if ($.isArray(value) || $.isObject(value)) &#123; target[name] = copy(value, deep); &#125; else if ($.isFunction(value)) &#123; target[name] = new Function("return " + value.toString())(); &#125; else &#123; target[name] = value; &#125; &#125; else &#123; target[name] = value; &#125; &#125; return target; &#125; &#125;]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[弄清 ECMAScript 6 模块]]></title>
    <url>%2F2018%2F11%2F13%2F%E5%BC%84%E6%B8%85-ECMAScript-6-%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[原文: ECMAScript 6 modules: the final syntax 1. JavaScript 的模块系统现状JavaScript 没有内建的模块系统，但是社区创造了很多给力的解决方案。 两种最重要（不幸的是互不兼容）的标准是: CommonJS Modules: 这个标准的主要 实现是在Node.js中（Node.js 模块有一些特性领先于 CommonJS)。 特性： 语法紧凑 设计用于同步加载 主要应用于服务器端 Asynchronous Module Definition (AMD): 这个标准的主要实现是 RequireJS。 特性： 语法稍微复杂，使AMD能够在没有 eval()（或者无须编译）的情况下工作。 设计用于异步加载 主要用于浏览器端 上面只是对当前状况的简单介绍，如果想要详细了解，可以看看 Addy Osmani 写的 “Writing Modular JavaScript With AMD, CommonJS &amp; ES Harmony” 2. ECMAScript 6 模块ECMAScript 6（后面简称ES6） 模块的设计目标是要创造一种让 CommonJS 和 AMD 的用户都能愉快使用的模块系统： 类似 CommonJS ，ES6 模块也有紧凑的语法，偏向于单个导出，支持循环依赖。 类似 AMD，ES6 模块直接支持异步加载和可配置模块加载。 内置于语言中，使得 ES6 模块超越 CommonJS 和 AMD （后面会详细说明）: 语法甚至比 CommonJS 更加紧凑 结构可以静态分析（用于静态检查，优化等） 支持循环引用这一点要优于 CommonJS ES6 模块分为两个部分: 声明语法（用于导入和导出） 可编程的加载器 API：配置模块的加载方式以及按条件模块加载 3. ES6 模块语法概述有两种导出方式：命名导出（一对多模块）和默认导出（一对一模块）。 3.1 命名导出 （一对多模块）一个模块可以通过在声明前添加关键字 export 来导出多个东西。这些导出按名称区分，成为命名导出。 12345678//------ lib.js ------export const sqrt = Math.sqrt;export function square(x) &#123; return x * x;&#125;export function diag(x, y) &#123; return sqrt(square(x) + square(y));&#125; 1234//------ main.js ------import &#123; square, diag &#125; from 'lib';console.log(square(11)); // 121console.log(diag(4, 3)); // 5 也有其他的方式声明命名导出（后面详细介绍），但是我发现这个非常方便：直接在js文件里写好代码，然后在你想导出的每一个东西的定义前加上一个 export 关键字。 你也可以引入整个模块，然后通过属性表达式引用其命名导出： 1234//------ main.js ------import * as lib from 'lib';console.log(lib.square(11)); // 121console.log(lib.diag(4, 3)); // 5 CommonJS 语法中相同的代码：曾经有段时间，我尝试过用一些聪明的办法，来减少 Node.js 中模块导出的冗余。现在我更喜欢下面的简单但略显冗长的风格: 12345678910111213//------ lib.js ------var sqrt = Math.sqrt;function square(x) &#123; return x * x;&#125;function diag(x, y) &#123; return sqrt(square(x) + square(y));&#125;module.exports = &#123; sqrt: sqrt, square: square, diag: diag,&#125;; 12345//------ main.js ------var square = require('lib').square;var diag = require('lib').diag;console.log(square(11)); // 121console.log(diag(4, 3)); // 5 3.2 默认导出 （一对一模块）导出单一值的模块在 Node.js 社区大受欢迎。但是在前端开发中也很常见，在一些有构造函数/类的模型，且每个模型对应一个模块的地方。一个 ES6 模块可以选择默认导出，作为最重要的导出值。默认导出特别易于导入。 下面的 ES6 模块默认导出是一个函数： 123456//------ myFunc.js ------export default function () &#123; ... &#125;;//------ main1.js ------import myFunc from 'myFunc';myFunc(); 一个默认导出是一个类的 ES6 模块如下: 123456//------ MyClass.js ------export default class &#123; ... &#125;;//------ main2.js ------import MyClass from 'MyClass';let inst = new MyClass(); 注意：默认导出的操作对象是一个表达式语句，通常没有名称；然而，它可以通过模块的名称（模块的文件名）来识别。 3.3 在一个模块中同时使用命名导出和默认导出下面的模式在 JavaScript 中很常见：一个类库是单一的函数，但是通过改函数的属性提供了附加服务。jQuery 和 Underscores.js 都是这种方式的例子。下面是将 Underscore.js 写成 CommonJS 模块的草图： 123456789//------ underscore.js ------var _ = function (obj) &#123; ...&#125;;var each = _.each = _.forEach = function (obj, iterator, context) &#123; ... &#125;;module.exports = _; 1234//------ main.js ------var _ = require('underscore');var each = _.each;... 从 ES6 来看，函数 _ 是默认导出，each 和 forEach 是命名导出。事实证明，你实际上可以同时使用命名导出和默认导出。看看下面的示例，前面的 CommonJS 模块用 ES6 模块的方式来写： 12345678//------ underscore.js ------export default function (obj) &#123; ...&#125;;export function each(obj, iterator, context) &#123; ...&#125;export &#123; each as forEach &#125;; 123//------ main.js ------import _, &#123; each &#125; from 'underscore';... ​ 注意，CommonJS 的版本和 ES6 的版本只是粗略的相似，后者具有更加扁平的结构，前者则是嵌套的。更偏向哪种风格是个人的喜好，但是扁平风格具有静态检查的优势（为什么这样做很好，下面解释）。CommonJS 风格似乎是部分受到了将对象作为命名空间的需求的驱动，这种需求通常可以通过 ES6 模块和命名导出的方式来实现。 默认导出只是另一种形式的命名导出​ 默认导出实际上是一种特殊的命名为 default 的命名导出。也就是说，下面的两种表达是等同的： 12import &#123; default as foo &#125; from 'lib';import foo from 'lib'; ​ 类似的，下面两个模块有相同的默认导出： 123456//------ module1.js ------export default 123;//------ module2.js ------const D = 123;export &#123; D as default &#125;; 我们为什么需要命名导出你可能想知道 — 如果我们可以简单地默认导出对象（像 CommonJS 一样），为什么需要命名导出？答案就是，你不能通过对象来强行使用静态结构，这会失去所有相关的有点（下一节中解释）。 4. 设计目标如果你想弄懂 ES6 模块，理解是什么样的目标影响了设计可能会帮到你，主要的目标就是： 默认导出是有利的 静态模块结构 同时支持同步和异步加载 支持模块间循环引用 下面的小节解释这些目标。 4.1 默认导出是有利的模块语法暗示了将默认导出当作模块可能看起来有些奇怪，但是如果你考虑到其中一个主要目标就是让默认导出尽可能方便的话就能说的通了。引用 David Herman: ECMAScript 6 favors the single/default export style, and gives the sweetest syntax to importing the default. Importing named exports can and even should be slightly less concise. 4.2 静态模块结构​ 在现代 JavaScript 模块系统中，你必须运行代码才能知道导入和导出的是什么。这就是 ES6 打破了这些系统的主要原因：通过将模块系统建立到语言中，你可以在语法上强制执行静态模块结构。我们先看看这意味着什么，再看看它带来了什么好处： ​ 模块结构是静态的意味着你可以在编译时（静态的）决定导入和导出 — 你只需要看看源码，不必执行它。下面为什么 CommonJS 不可能做到静态检查的示例。在这个示例中，你必须运行代码才能知道它导入了什么： 123456var mylib;if (Math.random()) &#123; mylib = require('foo');&#125; else &#123; mylib = require('bar');&#125; 第二个例子中，你必须运行代码才能知道导出了什么： 123if (Math.random()) &#123; exports.baz = ...;&#125; ​ ES6 提供更少的灵活性，它会迫使你保持静态。你也会因此受益[2]，下面介绍。 好处 1: 更快速的查找​ 如果你用 CommonJS require 一个类库，你会得到一个 object ： 12var lib = require('lib');lib.someFunc(); // property lookup ​ 因此，通过 lib.someFunc 访问一个命名导出意味着你必须执行属性查询，这是很慢的，因为它是动态的。 ​ 相反，如果你用 ES6 模块语法 import 一个类库，你可以静态地知道其内容并可以优化访问： 12import * as lib from 'lib';lib.someFunc(); // statically resolved 好处 2: 变量检查​ 有了静态模块结构，你就总能静态地知道模块内任意位置的哪些变量是可见的： Global variables: increasingly, the only completely global variables will come from the language proper. Everything else will come from modules (including functionality from the standard library and the browser). That is, you statically know all global variables. Module imports: You statically know those, too. Module-local variables: can be determined by statically examining the module.This helps tremendously with checking whether a given identifier has been spelled properly. This kind of check is a popular feature of linters such as JSLint and JSHint; in ECMAScript 6, most of it can be performed by JavaScript engines. 另外，任何对命名导出的访问（例如 lib.foo）也可以静态检查。 好处3: 准备好了宏​ 宏仍然在 JavaScript 未来的技术路线图中。如果 JavaScript 引擎支持了宏，你就可以通过类库添加新的语法。Sweet.js 就是一个实验性的 JavaScript 宏系统。下面是一个来自 Sweet.js 官网的示例：class 的宏 12345678910111213141516171819202122232425// Define the macromacro class &#123; rule &#123; $className &#123; constructor $cparams $cbody $($mname $mparams $mbody) ... &#125; &#125; =&gt; &#123; function $className $cparams $cbody $($className.prototype.$mname = function $mname $mparams $mbody; ) ... &#125;&#125;// Use the macroclass Person &#123; constructor(name) &#123; this.name = name; &#125; say(msg) &#123; console.log(this.name + " says: " + msg); &#125;&#125;var bob = new Person("Bob");bob.say("Macros are sweet!"); ​ 对于宏，JavaScript 引擎在编译前会进行一个预处理步骤：如果解析器生成的 token 流中的 token 序列与宏的模式部分匹配，那么它将会被宏体生成的 token 替换。预处理步骤只在能够静态查找到宏定义的情况下有效。所以如果你想通过模块引入宏，那么模块必须是静态结构的。 好处4: 准备好了类型​ 静态类型检查强加了类似于宏的约束：它在定义能被静态地找到的情况下有用。同样，如果类型具有静态结构，只能从模块导入。 ​ 类型很有吸引力，因为他们支持静态类型的 JavaScript 快速变体，其中可以编写性能关键代码。一个这样的变体就是 Low-Level JavaScript (LLJS)。它现在被编译到了 asm.js 好处 5: 支持其他语言​ 如果你想要支持将使用宏和静态类型的语言编译到 JavaScript 中，JavaScript 的模块就应该有一个静态结构，这在前面两节讲过了。 同时支持同步和异步加载​ ES6 模块必须在不论引擎同步（例如服务器端）还是异步（例如浏览器中）加载模块的情况下工作。它的语法非常适合同步加载，异步加载是通过静态结构实现的：因为你可以静态地决定所有的导入，所以可以在评估模块主题之前就加载他们（以一种类似 AMD 模块的方式） 4.3 支持模块间的循环引用​ 如果 A （可能间接/可传递地）导入了 B，同时 B 导入了 A，那么模块 A 和 B 就形成了循环依赖。如果可能，应该尽量避免循环依赖，它导致了 A 和 B 的紧耦合 — 它们只能同时引入和使用。 为什么要支持循环依赖?​ 循环依赖本身并不是邪恶的。特别是对于对象，有时候你甚至需要这种依赖。例如，在一些树（例如 DOM 文档树）中，父亲指向孩子，同时孩子也指向父亲。在类库中，你通常会通过仔细的设计来避免循环依赖。在大型系统中，这种情况可能发生，尤其是在重构期间。然后，如果模块系统支持循环引用的话就非常有用了，因为重构时不会导致系统崩溃。 ​ Node.js 文档中承认了循环依赖的重要性[3] , Rob Sayre 提供了补充证明： Data point: I once implemented a system like [ECMAScript 6 modules] for Firefox. I got asked for cyclic dependency support 3 weeks after shipping. That system that Alex Fritze invented and I worked on is not perfect, and the syntax isn’t very pretty. But it’s still getting used 7 years later, so it must have gotten something right. ​ 我们来看看 CommonJS 和 ES6 如何处理循环依赖。 CommonJS 中的循环依赖​ 在 CommonJS 中，如果模块 B 依赖模块 A , 而 A 的主体正在评估中，那么它将返回 A 在当前状态中的导出对象（下面示例中的第一行）。这就允许 B 引用其导出内对象的属性（第二行）。这些属性在 B 的评估结束后填充，此时 B 的导出工作正常。 1234567891011121314//------ a.js ------var b = require('b');exports.foo = function () &#123; ... &#125;;//------ b.js ------var a = require('a'); // (1)// Can’t use a.foo in module body,// but it will be filled in laterexports.bar = function () &#123; a.foo(); // OK (2)&#125;;//------ main.js ------var a = require('a'); 作为一般规则，需要记住，对于循环依赖，你无法访问模块正文中的导入。这是该现象固有的，并不能被 ES6 模块改变。 CommonJS 的方式有一些限制： Node.js 风格的单值导出不起作用。在 Node.js 中，你可以像这样导出单个值而不是对象： module.exports = function () { ... } 如果你在模块 A 中这样做了，你就无法在模块 B 中使用导出的方法，因为 B 的变量 a 仍然指向 A 的原始导出对象。 你不能直接使用命名导出。也就是说，模块 B 不能像这样导入 a.foo ：var foo = require(&#39;a&#39;).foo; foo 将会是 undefined。换句话说，你没有其他选择，只能通过导出对象 a 来引用 foo。 ​ CommonJS 有一个独一无二的特点：你可以在导入之前导出。这种导出保证可以在引用的模块中被访问到。也就是说，如果 A 这样做了，那么它就可以在 B 中被访问到。然而在导入前导出的特性很少有用。 ES6 中的循环引用为了消除上述的两条限制，ES6 模块导出了绑定而不是值。也就是说与模块体内声明的变量的连接是保持鲜活的。在下面的代码中证明： 1234567891011//------ lib.js ------export let counter = 0;export function inc() &#123; counter++;&#125;//------ main.js ------import &#123; inc, counter &#125; from 'lib';console.log(counter); // 0inc();console.log(counter); // 1 ​ 因此，对于循环依赖，不论你是直接访问命名导出还是通过模块访问都无关紧要：两种情况之间有间接联系，而且始终有效。 5. 再说一点导入和导出5.1 导入​ ES6提供了下面这些方式的导入: 1234567891011121314// Default exports and named exportsimport theDefault, &#123; named1, named2 &#125; from 'src/mylib';import theDefault from 'src/mylib';import &#123; named1, named2 &#125; from 'src/mylib';// Renaming: import named1 as myNamed1import &#123; named1 as myNamed1, named2 &#125; from 'src/mylib';// Importing the module as an object// (with one property per named export)import * as mylib from 'src/mylib';// Only load the module, don’t import anythingimport 'src/mylib'; 5.2 导出​ 有两种方式可以导出当前模块中的东西。一种是你可以在声明前添加 export 关键字。 12345678910111213export var myVar1 = ...;export let myVar2 = ...;export const MY_CONST = ...;export function myFunc() &#123; ...&#125;export function* myGeneratorFunc() &#123; ...&#125;export class MyClass &#123; ...&#125; ​ 默认导出的操作符是一个表达式（包括函数表达式和类表达式）。例如： 1234567891011export default 123;export default function (x) &#123; return x&#125;;export default x =&gt; x;export default class &#123; constructor(x, y) &#123; this.x = x; this.y = y; &#125;&#125;; ​ 另一方面，你可以将需要导出的任何东西列在模块末尾。 123456const MY_CONST = ...;function myFunc() &#123; ...&#125;export &#123; MY_CONST, myFunc &#125;; ​ 你也可以用不同的名字导出： 1export &#123; MY_CONST as THE_CONST, myFunc as theFunc &#125;; ​ 注意，不能用保留字（例如，default 和 new ）作为变量名，但是你可以用他们作为导出名称（你也可以在 ES5 中用它们作为属性名称）。如果你想直接导入这样命名的导出，你必须要重命名成合适的名字。 5.3 重导出​ 重导出意思是将另一个模块的导出添加到当前模块的导出中。你要么可以添加其他模块的全部导出： 1export * from 'src/other_module'; ​ 要么可以更有选择性（也可以重命名）： 1234export &#123; foo, bar &#125; from 'src/other_module';// Export other_module’s foo as myFooexport &#123; foo as myFoo, bar &#125; from 'src/other_module'; 6. eval() 和 模块​ eval() 不支持模块语法。它根据脚本的语法规则解析传入的参数，而脚本不支持模块语法（后面解释）。如果你想要评估模块代码，可以使用模块加载 API（接下来介绍） 7. ES6 模块加载 API除了使用模块的声明式语法外，还有一个编程 API，它允许你： 用编程方式使用模块和脚本 配置模块加载 ​ 加载器处理解析模块标识符（位于import…from 后面的字符串 ID），加载模块等。他们的构造函数是 Reflect.Loader 。每个平台都在全局变量 System（系统加载器）中保留一个自定义实例，实现其特定的模块加载方式。 7.1 引入模块和加载脚本你可以通过基于 ES6 promise 的 API，编程化的导入一个模块： 12 System.import() 允许你: 使用元素内的模块（这里不支持模块语法） 按条件加载模块 System.import() 获取一个模块, 你可以用 Promise.all() 来导入多个模块: 123456Promise.all( ['module1', 'module2', 'module3'] .map(x =&gt; System.import(x))).then(([module1, module2, module3]) =&gt; &#123; // Use module1, module2, module3&#125;); 更多加载器方法: System.module(source, options?) 将source中的 JavaScript 代码评估为模块（这种方式通过 promise 异步传输） System.set(name, module) 这个方法用于注册一个模块（例如，一个你通过 System.module()创建的模块）。 System.define(name, source, options?) 同时评估 source 中的模块代码和注册生成的模块。 7.4 配置模块加载模块加载器 API 有各种用于配置的 hooks（钩子），它仍在进行中。第一个用于浏览器的系统加载器目前已经实现并通过测试。目标是要弄清楚如何最好的实现模块加载可配置化。 The loader API will permit many customizations of the loading process. For example: 加载器 API 将会允许许多加载处理过程的自定义设置。例如： 导入Lint模块(e.g. 通过 JSLint 还是 JSHint). 导入自动转椅模块(代码中可能包含 CoffeeScript 或者 TypeScript 代码). 使用遗留模块(AMD, Node.js). 配置模块加载在 CommonJS 和 Node.js 中是受限制的]]></content>
      <categories>
        <category>FE</category>
        <category>ES6</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神奇的NaN]]></title>
    <url>%2F2018%2F11%2F13%2F%E7%A5%9E%E5%A5%87%E7%9A%84NaN%2F</url>
    <content type="text"><![CDATA[这是一个大约需要花10-15分钟看完的技术讲义，关于 NaN 是什么？它会在哪里出现？以及对于它大家需要知道些什么？ 讲义的作者是 Lewis J Ellis，有一份这个讲义的演讲视频录像，还可以在 Github 上找到这个讲义的项目。 “NaN” 的意思是:Not a Number 什么东西会给我们一个NaN? 令人头晕的数学计算123456console.log( 0 / 0, Infinity / Infinity, 0 * Infinity, Infinity - Infinity); 1&gt; NaN NaN NaN NaN 复杂的数字123456console.log( Math.sqrt(-1), Math.log(-1), Math.acos(2), Math.asin(2)); 1&gt; NaN NaN NaN NaN 将其他类型转换为数字123456console.log( parseInt('hello'), parseFloat('world'), Number(undefined), Number(&#123;&#125;), +undefined, +&#123;&#125;, +new Date('hello')); 1&gt; NaN NaN NaN NaN NaN NaN NaN 在 JavaScript 中，NaN 是什么 “Not a Number” 是…1console.log(NaN); 1&gt; NaN … 一个特殊的 JavaScript 值. (非常 特殊) “Not a Number” 是…1console.log(typeof NaN); 1&gt; number …一个 Number. “Not a Number” 是…1console.log(NaN === NaN); 1&gt; false … 不是一个”Not a Number”. “Not a Number” 是…12var assert = require('assert');assert.equal(NaN, NaN); 1&gt; AssertionError: NaN == NaN …棘手的测试. “NaN” 实际上意思是:Not a NaN 所以我们知道了 NaN 在什么地方出现, 但是我们如何判断一个值是 NaN ？放轻松！只需要使用 isNaN 方法:1console.log(isNaN(NaN)); 1&gt; true 也许可能不是…1console.log(isNaN('foo'), isNaN(['bar']), isNaN(&#123;&#125;)); 1&gt; true true true 1console.log(typeof 'foo', typeof ['bar'], typeof &#123;&#125;); 1&gt; string object object 我们自己写一个方法来判断:123456function myIsNaN(x) &#123; return typeof x === 'number' &amp;&amp; isNaN(x);&#125;console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(isNaN));console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(myIsNaN)); 12&gt; true true true true&gt; true false false false 或者我们可以回调 “Not a NaN”:123456function myIsNaN(x) &#123; return x !== x;&#125;console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(isNaN));console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(myIsNaN)); 12&gt; true true true true&gt; true false false false 这个方法有用是因为 NaN 是 JavaScript 中唯一一个等号操作符是非自反的值。 幸运的是, ES2015 中增加了 Number.isNaN:12console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(isNaN));console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(Number.isNaN)); …它正是我们想要的方法: 12&gt; true true true true&gt; true false false false 或者我们也可以 用 Object.is:12console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(isNaN));console.log([NaN, 'foo', ['bar'], &#123;&#125;].map(n =&gt; Object.is(n, NaN))); 12&gt; true true true true&gt; true false false false 这种方法用到了 SameValue 这个内部操作，它的对比方式与 Set 区分元素的方法（大部分）相似。 但是 NaN 不仅仅是 JavaScript 中才有的！ NaN 实际上是在 IEEE 754 浮点标准中定义的。 如果你知道 NaN 在一种语言中可能出现的地方，以及它的表现，那么它在其他语言中也大致相似。 IEEE 754 规范定义了 pow 方法：1234pow(2, 3) -&gt; 8pow(-1, 1.5) -&gt; NaNpow(NaN, anything) -&gt; NaNpow(anything, NaN) -&gt; NaN If either input is NaN, or if the base is negative and the exponent is not an integer, the result is NaN. 如果输入是 NaN ，或者基数为负且指数不是整数，则结果为 NaN。 三种不明确的 pow:123pow(0, 0) -&gt; 1pow(Infinity, 0) -&gt; 1pow(1, Infinity) -&gt; 1 这种行为 继承自 C99 和 POSIX 2001 多数语言都遵循这一条规则 这是 Python 的行为 :1[0 ** 0, float("inf") ** 0, 1 ** float("inf")] 1&gt; [1 1.0 1.0] Ruby :1[0 ** 0, Float::INFINITY ** 0, 1 ** Float::INFINITY] 1&gt; [1 1.0 1.0] Lua :1print(math.pow(0, 0), math.pow(math.huge, 0), math.pow(1, math.huge)) 1&gt; 1 1 1 但是JavaScript? 1Math.pow(0, 0); 1Math.pow(0, 0); 1&gt; 1 1Math.pow(0, 0); 1&gt; 1 1Math.pow(Infinity, 0); 1Math.pow(0, 0); 1&gt; 1 1Math.pow(Infinity, 0); 1&gt; 1 1Math.pow(0, 0); 1&gt; 1 1Math.pow(Infinity, 0); 1&gt; 1 1Math.pow(1, Infinity); 1Math.pow(0, 0); 1&gt; 1 1Math.pow(Infinity, 0); 1&gt; 1 1Math.pow(1, Infinity); 1&gt; NaN 为什么？ ES1 声明pow: 1997 C99 声明pow: 1999 POSIX 声明pow: 2001 IEEE 754 声明pow: 2008 就像关于 JavaScript 的其他问题一样，答案就是… 向后兼容 所以不论如何，看看 IEEE 754 告诉我们要如何表示 NaN？ float32 类型值的 bit 表达方式：10 10000000 01000000000000000000000 1 位符号 8 位指数, 偏移量 127 23 位有效位数 (前面的第24位隐藏) (-1) ^ s * 2 ^ (exp - 127) * 1.significand 例如 float32 的值:10 10000000 01000000000000000000000 (-1) ^ 0 = 1 2 ^ (10000000b - 127) = 2 1.01b = 1.25 1 * 2 * 1.25 = 2.5 特殊值的 bit 表达方式:120 11111111 00000000000000000000000 -&gt; Infinity1 11111111 00000000000000000000000 -&gt; -Infinity Infinity 的值有一个最大的指数和一个为零的有效位数。 特殊值的 bit 表达方式:10 11111111 10000000000000000000000 -&gt; NaN NaN 的值有一个最大的指数和一个非零的有效位数。 这些也都是 NaN:123451 11111111 10000000000000000000000 -&gt; NaN (quiet, negative)0 11111111 10000000000000000000001 -&gt; NaN (quiet, but different)0 11111111 00000000000000000000001 -&gt; NaN (signaling)0 11111111 00000000000000000000010 -&gt; NaN (signaling, but different)0 11111111 00000000000000000000011 -&gt; NaN (we can start counting!) 这些也都是 NaN:123451 11111111 10000000000000000000000 -&gt; NaN (quiet, negative)0 11111111 10000000000000000000001 -&gt; NaN (quiet, but different)0 11111111 00000000000000000000001 -&gt; NaN (signaling)0 11111111 00000000000000000000010 -&gt; NaN (signaling, but different)0 11111111 00000000000000000000011 -&gt; NaN (we can start counting!) 一共有多少个NaN，真的吗？ 2^24 - 2 = 16,777,214 这只是类型位 float32 的情况下!那么如果是 double64 呢? 2^53 - 2 = 9,007,199,254,740,990 也就是 9 * 10^15, 或者 9 万亿.9PB相当于可以播放20000年的音乐 如果有这么多可能的 NaN ，那这一切才看起来合理了些… …就是说一个随机的 NaN 几乎不可能等于另一个随机的 NaN！ 因此, NaN !== NaN[^1].[^1]: With probability 1/9,007,199,254,740,990. 相关链接 http://ariya.ofilabs.com/2014/05/the-curious-case-of-javascript-nan.html http://www.2ality.com/2012/02/nan-infinity.html https://en.wikipedia.org/wiki/NaN https://tc39.github.io/ecma262/#sec-applying-the-exp-operator]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从JavaScript数组中移除元素的几种方法]]></title>
    <url>%2F2018%2F11%2F13%2F%E4%BB%8EJavaScript%E6%95%B0%E7%BB%84%E4%B8%AD%E7%A7%BB%E9%99%A4%E5%85%83%E7%B4%A0%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[​ ​ JavaScript 数组允许你对元素进行分组和迭代，你可以用不同的方式添加或者删除数组元素，但不幸的是，却并没有一个简单的 Array.remove 的方法。 ​ JavaScript 数组有各种各样的方法来删除数组元素，而不是用 delete 方法。如果我们用 delete arr[index]的方式删除了数组元素，则只是将该数组中索引值为 index 的元素置为 undefined ，该位置上是一个空元素，并且数组长度不会减少。 ​ 从数组头部删除元素用 shift ，从尾部删除元素用 pop ，从中间删除元素用 splice ，还可以用 filter 方法来过滤出符合条件的元素，并将这些元素返回一个新的数组，这是一个更高级的用法。 从JavaScript Array 尾部移除元素可以通过设置数组的 length 属性来打到移除末端元素的效果，当新设置的 length 属性的值，小于当前数组长度时，索引值大于新的 length 属性的元素都会自动被删除。 123var ar = [1, 2, 3, 4, 5, 6];ar.length = 4; // set length to remove elementsconsole.log( ar ); // [1, 2, 3, 4] pop 方法移除数组末端的最后一个元素，返回这个元素，更新 length 属性。 123var ar = [1, 2, 3, 4, 5, 6];ar.pop(); // returns 6console.log( ar ); // [1, 2, 3, 4, 5] 从JavaScript Array 头部移除元素shift 方法会删除数组索引为 0 的元素，返回被删除的元素，删除后，剩余元素会向下移动。 123var ar = ['zero', 'one', 'two', 'three'];ar.shift(); // returns "zero"console.log( ar ); // ["one", "two", "three"] 当数组中元素为空，或者 length 为0时，方法返回 undefined 用 splice 方法移除 JavaScript Array 元素splice 方法用于删除数组元素，也可以新增元素。第一个参数指定增加或者删除的起始位置，第二个参数指定要移除的元素个数。第三个参数以及后续的参数都是可选参数；他们指定了要被加入到数组中的元素。 下面的例子将从数组的第三个元素开始删除两个元素（数组从0开始） 1234567var array = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0];var removed = array.splice(2,2);/*removed === [3, 4]array === [1, 2, 5, 6, 7, 8, 9, 0]*/ splice 方法返回一个由被删除元素组成的数组 用 splice 方法删除 JavaScript Array 中的特定值的元素如果知道想要从数组中删除的值，也可以用 splice 方法。但是也要先获取目标元素的索引，然后用根据索引来删除该元素 123456789var array = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0];for( var i = 0; i &lt; array.length-1; i++)&#123; if ( array[i] === 5) &#123; arr.splice(i, 1); &#125;&#125;//=&gt; [1, 2, 3, 4, 6, 7, 8, 9, 0] 这是一个简单的例子，元素都是整数。如果数组元素是 object 类型，那么方法就会复杂的多了。 用 filter 方法移除 JavaScript Array 中的特定值的元素不同于 splice 方法，filter 会创建一个新的数组，即不会改变调用 filter 方法的数组，不会产生副作用。 filter 方法只接收一个 callback 方法作为参数。当fulter 方法遍历数组元素时触发 callback 方法。callback 接收三个参数：当前元素的值，当前元素的索引，整个数组。 callback 方法返回 true 或者 false ，元素返回 true 还是 false 由你决定，返回为true 的元素将被加入到 filter 方法的返回数组中。 1234567var array = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0];var filtered = array.filter(function(value, index, arr)&#123; return value &gt; 5;&#125;);//filtered =&gt; [6, 7, 8, 9]//array =&gt; [1, 2, 3, 4, 5, 6, 7, 8, 9, 0] Lodash Array 删除方法有时候使用现成的工具库来解决复杂问题是最佳的实践。Lodash 提供了一套丰富的数组操作方法，其中一个就是 remove 。Lodash 的 remove 方法与 JavaScript Array 的 filter 方法非常相似，但是它不会保存原始数组，即会产生副作用，它会删除匹配元素，并将删除的元素作为一个新的数组返回 12345678var array = [1, 2, 3, 4];var evens = _.remove(array, function(n) &#123; return n % 2 === 0;&#125;);console.log(array);// =&gt; [1, 3]console.log(evens);// =&gt; [2, 4] 手写一个 Remove 方法原生 JS 没有提供 Array.remove方法。Lodash 的 remove 方法的确可以解决问题，但是并不是总想要去引用 Lodash 的类库的。我们可以手写一个 remove 方法出来，这篇文章 model to follow 给出了一个例子，但是它是通过扩展 Array 对象的原型来实现的，这不是一个好主意。 下面是我实现的一个简单的例子： 1234567891011function arrayRemove(arr, value) &#123; return arr.filter(function(ele)&#123; return ele != value; &#125;);&#125;var result = arrayRemove(array, 6);// result = [1, 2, 3, 4, 5, 7, 8, 9, 0] 使用 Delete 操作符显示地删除数组元素你也可以使用 delete 运算符来删除数组元素 1234var ar = [1, 2, 3, 4, 5, 6];delete ar[4]; // delete element with index 4console.log( ar ); // [1, 2, 3, 4, undefined, 6]alert( ar ); // 1,2,3,4,,6 使用 delete 操作符不会影响数组的 length 属性，也不会影响后续元素的索引值。会将数组变成稀疏数组。 delete 操作符是被设计用于删除 JavaScript object 类型属性的，数组也是一种特殊的 object 类型。 元素没有真正被从数组中删除的原因是 delete 操作符的作用更多的是释放内存，而不是删除元素。当不再有对这个值的引用时，内存就会自动释放。]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用排序算法]]></title>
    <url>%2F2018%2F11%2F08%2F%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法的学习和记录 更新中。。。 冒泡排序12345678910111213141516function bubble = (arr) =&gt; &#123; let n = arr.length,i,j,tmp,flag = true; let result = arr.slice(0); for(i = 0;i&lt;n &amp;&amp; flag;i++)&#123; flag = false; for(j=0;j&lt;n-i;j++)&#123; if(result[j]&gt;result[j+1])&#123; tmp = result[j]; result[j] = result[j+1]; result[j+1] = tmp; flag=true; &#125; &#125; &#125; return result;&#125; 选择排序123456789101112131415161718function Selector = (arr) =&gt; &#123; let n = arr.length,i,j,min,tmp; let result = arr.slice(0); for(i=0;i&lt;n;i++)&#123; min = i; for(j=i+1;j&lt;n;j++)&#123; if(result[j] &lt; result[min])&#123; min = j; &#125; &#125; if(min !=i)&#123; tmp = result[i]; result[i] = result[min]; result[min] = tmp; &#125; &#125; return result;&#125; 计数排序12345678910111213141516const CountingSort = (arr)=&gt;&#123; let n = arr.length,i,tmp = []; for(i=0;i&lt;n;i++)&#123; var a = arr[i]; var b = tmp[a]; tmp[a] = b?++b:1; &#125; let result = []; for(i=0;i&lt;tmp.length;i++)&#123; while(tmp[i]&gt;0)&#123; result.push(i); tmp[i]--; &#125; &#125; return result;&#125; 桶排序1234567891011121314151617181920// 堆排序const BucketSort = (arr) =&gt; &#123; let n = arr.length,i,j,tmp,result,D=[]; for(i = 0;i&lt;n;i++)&#123; tmp = arr[i]; j = Math.floor(tmp/10); if(!D[j])&#123; D[j] = []; &#125; D[j].push(tmp); &#125; result = []; for(i=0;i&lt;D.length;i++)&#123; if(!D[i])&#123; continue; &#125; result.push(...CountingSort(D[i])) &#125; return result;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[CSS Layout]]></title>
    <url>%2F2018%2F11%2F05%2FCSS-Layout%2F</url>
    <content type="text"><![CDATA[水平居中水平居中布局需要看子元素是 block 元素还是 inline 元素，width 是否固定。因此形成下面四个例子。 demo1 是子元素为 inline ，对父元素设置 text-align:center。 demo2 中子元素为 block ，宽度固定，则对子元素设置 margin:0 auto,左右宽度固定 demo3 中子元素为 block ，宽度不定，则子元素 display:inline ,父元素 text-align:center demo4 中采用了 flex 布局，是一种通用的方案，对 inline 和 block 两种元素均有效，display:flex 主轴居中对齐 justify-content:center; See the Pen 水平居中布局 by RedCorss (@redcorss) on CodePen. 垂直居中垂直居中布局则因子元素是单行内联文本，多行内联文本以及块级元素而异 demo1 父元素高度固定，子元素为单行内联文本，设置父元素行高为子元素的 line-height demo2 父元素高度固定，子元素为多行内联文本，这时用上面的方法会导致子元素只有第一行在父元素内部，其他行飘出去了，于是要换一种思路，父元素设置 CSS display:table-cell; vertical-align:middle ，如果不成功，注意检查外部CSS污染。 demo3 子元素是块级元素的时候，使用定位+位移的方式，父元素设置为 static 以外的值，子元素 position:absolute; top:50%;transform:translateY(-50%); demo4 通用方案，使用 Flex 布局， display:flex; ,交叉轴居中对齐 align-items:center; See the Pen 垂直居中布局 by RedCorss (@redcorss) on CodePen. 左中右布局position + margin使用绝对定位，让元素脱离原始的文档流，然后使用 top ，left，right将左右边栏分别固定在左上，右上，中间自适应上浮。注意，中间主面板要使用左右margin，值为左右面板的宽度。 优点是，这种写法不限制 div 的书写顺序，可以先写主面板，让重要内容优先渲染。 See the Pen position+margin-布局 by RedCorss (@redcorss) on CodePen. float + 负margin下面是传统的使用 float + 负margin的方式来实现的圣杯布局，这几种方式的 HTML 中，都没有考虑主页栏（class=“main”）写在侧边栏前面的问题，这样能让浏览器中主页内容在侧边栏之前加载。 第4个 demo 使用的 父元素左右 margin 替代的父元素左右 padding 第5个 demo 使用子元素 浮动，主页元素左右margin 自动上浮，缺点是需要将 主页元素写在侧边栏之后，导致页面加载时会先加载侧边栏，后加载主页 See the Pen float +父padding+ 负margin 圣杯布局 by RedCorss (@redcorss) on CodePen. 传统圣杯布局关于圣杯布局的出处可以看 这里 创建HTML，要把中间的div写在左右边栏的前面，让它首先渲染 12345&lt;div class="container"&gt; &lt;div class="center"&gt;&lt;/div&gt; &lt;div class="left"&gt;&lt;/div&gt; &lt;div class="right"&gt;&lt;/div&gt;&lt;/div&gt; 左右定宽 width:200px ，中间100%宽度，三栏同时左浮 float:left left 元素 margin-left:-100% , 上浮到 center 元素的左侧；right 元素 margin-left:-200px ，上浮到center元素的右侧，此时center元素的左右两边与 left ，right 元素是发生重叠的 父元素container padding:0 200px;, left元素 position:relative;left:200px; ，right 元素 position:relative;right:200px，至此圣杯布局完成 See the Pen 传统圣杯布局 by RedCorss (@redcorss) on CodePen. Flex 弹性盒子布局 See the Pen Responsive Holy Grail Layout using FlexBox by RedCorss (@redcorss) on CodePen.]]></content>
      <categories>
        <category>FE</category>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>Layout</tag>
        <tag>CSS布局</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS line-height]]></title>
    <url>%2F2018%2F11%2F02%2FCSS-line-height%2F</url>
    <content type="text"><![CDATA[​ 认识 line-height 之前，我们需要先了解一些 CSS 中与排版有关的概念。 ​ leading ，这个概念，对应中文的意思应该是“行距”，即排版中相邻两行之间的距离。lead有铅块的意思，在过去手工排版的时代，人们会向模板中插入细铅条来增加类型线之间的距离。现代排版中，leading 的确切定义已经混淆，大致分为两种：1.其一是指相邻两行 baseline （基线）之间的距离；2.其二是指上面一行的底部至下面一行的顶部的距离；其实两种表示的结果一致，但一般使用前者居多。 baseline， 基线，在一开始学习英语的时候，我们会在四线格子中练习英文字母的书写。一般把英文字母纵向等分四线三格，第三条线称为基线，如下图： 在CSS中，leading 指内容高度与 line-height 属性值的差异。 leading 的一半叫作 half- leading 。用户代理通过向 inline box 的顶部和底部各添加一个 half-leading 来让字体垂直居中。例如，如果一个字体是 “12pt” 高，line-height 是 “14pt” ，那么多出来的 2pt 就会被加上：1pt 加到字体顶部，1pt 加到字体底部。（这个特性也适用于空盒子，就像这个空盒子包含了一个高度为零的字听） In CSS, leading refers to the difference between the content height and the value of the line-height property. Half the leading is called the half-leading. User agents center glyphs vertically in an inline box, which adds half-leading on the top and bottom. For example, if a piece of text is “12pt” high and the line-height value is “14pt”, 2pt of extra space should be added: 1pt above and 1pt below the text (this applies to empty boxes as well, as if the empty box contained zero-height text). ——维基百科 MDN 中对 line-height 的解释如下： line-height CSS 属性用于设置多行元素的空间量，比如文本。对于块级元素，它指定元素行盒（line boxes）的最小高度。对于非替代的inline元素，它用于计算行盒（line box）的高度。 ​ line-height 属性定义了内联元素的顶部和底部的空间量。也就是那些属性为 display:inline 或 dispaly:inline-block 的元素。它可以接收关键词 normal ，none 作为属性值，当然也可以接收 数字，长度以及百分比。 ​ 根据规范，normal 的值并不是直接应用于元素的一个具体的值，而是根据元素设置（或继承） 的字体大小计算出的 合理的 值，取决于客户端代理中元素应用的font-family ，桌面浏览器（包括Firefox）默认值大约为1.2。 ​ 在 Chrome 调试工具中查看元素的行号的计算值，只能看到我们设置的 normal ，并不能直接看出实际行高，我们可以在 Firefox 浏览器下使用同样的方式查看，Firefox 浏览器会显示出计算出的实际行高的像素值。 ​ 长度可以是任何有效的 CSS 长度单位（px，em，rem等）。 ​ 百分比是指，用字体大小乘以这个百分比值，例如： See the Pen JejRVW by RedCorss (@redcorss) on CodePen. ​ 在上面的例子中，四段文字的 line-height 分别设置为 150%，200%，250%，normal。字体大小都是 20px。最终计算出来的行高就分别是 30px，40px，50px，normal最终的计算行高与 font-family，font-size，浏览器甚至操作系统有关，而不是一个确切的数值。 ​ 规范推荐用无单位数字作为 line-height 的值。无单位数字可以是任意数字，包括 decimal 类型。 ​ 推荐无单位数字行高，是因为子元素会继承无单位数字行高，而不是行高的计算值，这样子元素可以根据自己计算出的字体大小来计算出适合自己的行高，而不是直接从父元素继承一个固定的行高。]]></content>
      <categories>
        <category>FE</category>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS border-radius]]></title>
    <url>%2F2018%2F10%2F31%2FCSS-border-radius%2F</url>
    <content type="text"><![CDATA[​ 今天遇到了一个 border-radius:50% 和 100% 有什么不同 的问题，查资料时在 YouTube找到了这个视频，关于 border-radius 的运用，里面有很多精彩的内容，我将字幕翻译成了中文。视频中的演讲者 @LeaVerou 曾经在 W3C 工作，这是她在2014年做过的一个演讲，那时应该正在 W3C 就职。 YouTube 视频和字幕下载 视频和字幕下载使用 Chrome 浏览器 + Tampermonkey 扩展 + YouTube Download + Youtube Subtitle Downloader v20 脚本 字幕默认下载为 srt 格式，要在 HTML5 的 Video标签内使用 track 标签嵌入字幕，需要将 srt 转换为 vtt 格式，使用 在线转换工具 翻译字幕，因为非专业也不是经常干这个，就用 notepad++ 打开后逐行翻译，保存。 上传视频字幕到CDN视频这类比较大的静态资源文件如果直接上传到站点服务器上，一方面可能会加载比较慢，另一方面也会增加反向代理服务器的流量开销，所以利用了 七牛云 每天10G流量的免费 CDN，将视频和字幕都上传后拷贝外链 Markdown 嵌入视频Markdown中嵌入复杂元素有多种方案，可以借助一些专门支持 video 的 Hexo 插件，我没有装这种插件，而是选择用 将 HTML 直接注入到 Markdown 文档中，这样 Hexo 在将 md 文档渲染成 html 时会将注入的 HTML 代码原样输出，从而达到 HTML 代码注入的目的，代码如下 123456789101112&#123;% raw %&#125;&lt;div style="width:1080px;margin:0 auto;"&gt;&lt;video controls mutedsrc="//phbiw9gl9.bkt.clouddn.com/video_sub.mp4"width="600"height="400"&gt;&lt;track label="English" kind="subtitles" srclang="en" src="//phbiw9gl9.bkt.clouddn.com/video.vtt" default&gt;&lt;/video&gt;&lt;/div&gt;&#123;% endraw %&#125; 这里有个地方需要注意，一开始 vtt 字幕文件会加载失败，浏览器控制台输出 blocked:origin 错误，猜测大概是同源策略导致的，可以在 Video 标签的属性中增加 一项crossorigin=&quot;anonymous&quot;， 这样就允许字幕文件不同源 允许跨域后发现字幕加载又失败了，出错为 blocked:mixed-content ，这个错误是因为我在 HTTPS 的网站中加载了不安全的 HTTP 资源，浏览器是不允许这种操作的，我的七牛云域名用的测试域名，正式域名还在备案，只能用 HTTP ，于是我只能将 .vtt 字幕文件上传到我的 Github pages 博客中，最终的配置就变成了 123456789101112&#123;% raw %&#125;&lt;div style="width:1080px;"&gt;&lt;video style="margin:0 auto;display:inherit" controls mutedsrc="http://phbiw9gl9.bkt.clouddn.com/video_sub.mp4"crossorigin="anonymous"width="600"height="400"&gt;&lt;track label="English" kind="subtitles" srclang="en" src="https://kinboyw.github.io/fedemo/resume/video/video.vtt" crossorigin="anonymous" default&gt;&lt;/video&gt;&lt;/div&gt;&#123;% endraw %&#125; :sushi: 夜深了，饿]]></content>
      <categories>
        <category>FE</category>
        <category>blog</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Absolute, Relative, Fixed ,几种CSS定位有何不同]]></title>
    <url>%2F2018%2F10%2F30%2FAbsolute-Relative-Fixed-%E5%87%A0%E7%A7%8DCSS%E5%AE%9A%E4%BD%8D%E6%9C%89%E4%BD%95%E4%B8%8D%E5%90%8C%2F</url>
    <content type="text"><![CDATA[​ ​ 首先要理解的一个非常重要的概念就是，页面上的每一个元素都是一个块（block）。字面意思是一个像素矩形。如果你将元素设置为 display:block; 或者这个元素本身默认的就是 display:block; ；这意味着你可以设置一个元素的宽高，这个元素也会遵循它。但是那些默认是 display:inline; 的元素，就像默认情况下的，也是矩形，他们只是用不同的方式流入页面，尽可能的横向排列。 ​ 既然你现在可以将每个页面元素都视作一个像素块了，我们就可以聊一聊如何使用元素定位来将这些像素块放置到页面上我们指定的位置。这里我们将不会对盒模型进行任何讨论，但是它在这里确实会有影响… Static ：这是每一个页面元素的默认设置。不同类型的元素的默认定位都是 static 。Static 没有别的意思，它就是说这个元素会流到页面上它本应该在的位置。你将元素设置为 position:static; 的唯一理由就是强制清除元素上在其他地方应用的定位设置。这种情况极少，因为定位属性不会继承。 Relative ：这种定位类型可能是最容易混淆和用错的。它真正的意思是“相对自身”。如果你在一个元素上设置了 position:relative; 但是没有设置其他定位属性（top，left，bottom，或者right），就完全不会影响这个元素的定位，它会保持在原地，就像设置为 position:absolute; 一样。但是如果你的确设置了一些其他的定位属性，假如说， top:10px; ,它会从自己当前的位置向下移动 10 像素。我确定你能想象，能够基于常规位置移动一个元素非常有用。我自己经常用这中方式来排列那些没有按照我希望的方式排列的表单元素。 当你在一个元素上设置 position:relative; 的时候需要注意另外两件事。一个是相对定位引入了在这个元素上使用 z-index 的能力，即元素使用相对定位，且 z-index 的值不等于 auto 的时候 会创建一个新的 层叠上下文（stacking context） ，这在绝对定位的元素上是并不真正起作用的。甚至如果你没有设置一个 z-index 的值，这个元素也会出现在其他决定对位元素的顶层。另一件事是 相对定位限制了绝对定位子元素的作用范围 。任何相对定位元素的子元素都可以绝对定位在该块的内部。这带来了一些强大的功能，我在这里说过。 See the Pen Relative positioning by RedCorss (@redcorss) on CodePen. Absolute：这是一种非常强大的定位类型，允许你直白地将任何页面元素放置到你想要的位置。使用 top，left，bottom，和 right 来设定位置。记住，这些值是相对于最近的一个具有相对（或者绝对）定位的父元素。如果没有这样的父元素，它就会默认的找到最外层的 &lt;html&gt; 元素，就是说相对于整个网页移动。 使用绝对定位需要权衡（也是需要记住的最重要的）的地方是这些元素会从页面的文档流中被移除，于是后续元素会自然地尽可能向上浮动。一个具有绝对定位的元素不受其他元素影响，也不会影响其他元素。这是一个你每次使用绝对定位时都要认真思考的问题。滥用和错误地使用绝对定位都会限制你的网站的灵活性 See the Pen Absolute positioning by RedCorss (@redcorss) on CodePen. Fixed：这种定位非常少见，但是也有它的作用。固定定位元素是相对于视口（viewport） ，或者浏览器窗口的。当窗口滚动时视口不会改变，所以当页面滚动时固定定位元素会保持在原位置，制造出一种过去老套的 “帧” 一样的效果。这种定位的优点是，可以用它来实现导航栏，页面滚动时，导航栏固定定位，始终停留在当前视口中，不会移出视线。缺点是，这种效果对设备的兼容性较差，在小屏幕的笔记本，平板或者手机上，侧边导航栏的内容可能会被截断，影响使用。总而言之，这是一个很酷的效果，有它的用处，但是使用时需要充分测试。 See the Pen Fixed positioning by RedCorss (@redcorss) on CodePen. Sticky：目前是实验属性，粘性定位可以被认为是 Relative 定位与 Fixed 定位的混合体。粘性定位在给定的阈值范围内都是被当成一个相对定位元素对待，直到移动出了父元素边界就变成一个固定定位元素了。 See the Pen Sticky positioning by RedCorss (@redcorss) on CodePen.]]></content>
      <categories>
        <category>FE</category>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>CS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS Positioning]]></title>
    <url>%2F2018%2F10%2F30%2FCSS%20Positioning%2F</url>
    <content type="text"><![CDATA[1. position:staticposition:static 是所有元素的默认定位，就是说元素没有定位，出现在文档中通常的位置。 一般情况下你不用去指定它，除非你需要用它来覆盖前面的定位设置。 123#div-1 &#123; position:static;&#125; 如果指定了 position:relative，你就可以使用 top 或者 bottom , left 或者 right 来将元素移动到一个相对于它原来在文档中位置的新的位置。 我们来将 div-1 向下移动 20 像素，向左移动 40 像素： 12345#div-1 &#123; position:relative; top:20px; left:-40px;&#125; 注意 div-1 移动前应该在的位置，现在是空的了。当我们移动 div-1 时， 紧挨着的元素（div-after）并没有随之移动。那是因为 div-1 即使我们移动了 div-1 ，它实际上仍然占据着文档中原来的位置。 看上去似乎 position:relative 不是很有用，但是在后面的教程中，它会扮演一个重要的角色。 3. position:absolute当你指定了 position:absolute, 元素会从当前文档（流）中移除，并且重新被放置到你指定的位置。 让我们移动 div-1 到页面的右上角： 123456#div-1a &#123; position:absolute; top:0; right:0; width:200px;&#125; 这次要注意，因为 idv-1a 从当前文档（流）中被移除了，所以页面上其他元素的定位也因此发生了变化：div-1b，div-1c，和 div-after 都向上移动了，因为 div-1a 已经不在那里了。 也要注意 div-1a 定位到了页面的右上角。虽然能够直接在页面上定位元素很不错，但是这样做的用处也很有限。 我真正需要的是让 div-1a 相对于 div-1 定位。这里就需要相对定位的加入了。 备注： 在Windows 的 IE 浏览器中有一个 bug ：如果你指定一个相对宽度（例如，”width:50%”），那么这个宽度将会是基于父元素的，而不是发生定位的元素。 4. position:relative + position:absolute如果我们在 div-1 上面设置了 relative 定位，那么 div-1 内部的任何元素的定位都将是相对与 div-1 的。如果我们在 div-1a 上设置了绝对定位，那么我们就可以将 div-1a 移动到 div-1 的右上角去了。 123456789#div-1 &#123; position:relative;&#125;#div-1a &#123; position:absolute; top:0; right:0; width:200px;&#125; 5. two column absolute现在我们可以用相对定位和绝对定位来制作两栏布局（两列布局）了！ 123456789101112131415#div-1 &#123; position:relative;&#125;#div-1a &#123; position:absolute; top:0; right:0; width:200px;&#125;#div-1b &#123; position:absolute; top:0; left:0; width:200px;&#125; 使用绝对定位的一个优点就是，我们可以将元素以任意顺序定位在页面上，不用管他们出现在 HTML 中的顺序。所以我将 div-1b 放在了 div-1a 的前面了。 不过等等 - 其他元素都到哪里去了？他们被绝对定位的元素遮住了。 6. two column absolute height一个解决办法是给被遮盖的元素一个固定的高度。 但是在多数设计中这种方案是不可行的，因为我们通常并不知道被隐藏的元素中将会有多少文字，也不知道这些文字确切的字体大小。 12345678910111213141516#div-1 &#123; position:relative; height:250px;&#125;#div-1a &#123; position:absolute; top:0; right:0; width:200px;&#125;#div-1b &#123; position:absolute; top:0; left:0; width:200px;&#125; 7. float对于可变高度的列，绝对定位不起作用，所以我们来尝试另一种解决办法。 我们可以让元素 “浮动” ，将它推到尽可能左或者右的位置，并允许文字环绕它。这种浮动通常是用于图片元素的，但是我们将它用于更加复杂的布局任务（因为这是我们唯一可用的工具）。 1234#div-1a &#123; float:left; width:200px;&#125; 8. float columns如果浮动一列到左侧，另一列也浮动到左侧，他们会尽可能并排浮动到顶端。 12345678#div-1a &#123; float:left; width:150px;&#125;#div-1b &#123; float:left; width:150px;&#125; 9. float columns with clear然后在浮动元素的后面，我们可以 “清除” 浮动效果，来将余下的内容按住，不让他们浮上来。 1234567891011#div-1a &#123; float:left; width:190px;&#125;#div-1b &#123; float:left; width:190px;&#125;#div-1c &#123; clear:both;&#125; 10. 免责声明这些示例都及其简单，旨在简单实现效果以介绍几个定位的功能，并不会触发一些 Windows IE 浏览器中的 CSS bug（实际上有很多）。]]></content>
      <categories>
        <category>FE</category>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>CSS</tag>
        <tag>Element-Position</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何阅读W3C规范]]></title>
    <url>%2F2018%2F10%2F29%2F%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BBW3C%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[如何阅读W3C规范？ ​ 看到这样一篇文章，作者是 J. David Eisenberg ，于 2001年9月28日发表于 CSS, HTML。 ​ J. David Eisenberg 是一位程序员兼教师，和他的猫, Marco Polo 和 Big Tony一起生活在 San Jose, CA 。写过一本关于 Scalable Vector Graphics（SVG）的书。对 OpenDocument Format 和 学外语感兴趣。 ​ 我将主题内容及要点翻译并罗列如下，原文请看 How to Read W3C Specs。 ​ World Wide Web Consoritium（W3C）是所有网络技术规范的守护者。作为 web 设计者，你应该访问过他们的网站(w3.org) 来寻找关于 XHTML 的问题的答案，或者关于一些更新的技术，例如 XSL Formatting Objects 或者 Scalable Vector Graphics。（文章发表时间较早，HTML5 还没诞生） ​ 你跑去看规范，然后立刻陷入混乱，说：“这根本没法看！”。实际上，它是可读的，只要你理解了一点关键信息 规范不是用户手册 The Bible was not meant to be read, but interpreted. ——attribution unknown ​ 当你寻找答案的时候，你其实需要的是用户手册或者指南，你想使用这项技术。而这并不是 W3C 规范的目的。“spec” 的目的是告诉那些要实现这个规范的程序员，必须要有哪些特性，以及如何实现这些特性。 ​ 当你在使用最新的技术时，可能没有任何用户参考手册；唯一可用的文档就是技术规范。在这样的情况下，学习阅读规范就是很有必要的，而不是一个奢侈的事情了。 规范的结构​ 大部分规范都有一个描述文档自身的章节。例如 HTML 和 CSS 规范的第一节就是告诉你规范的各个部分是如何组织的，以及如何正确阅读规范。 基本概念 I hate definitions. ——Benjamin Disraeli W3C 规范是用日本歌舞伎剧中的仪式化形式编写的，当你阅读规范时，你将会遇到这些词语 normative “this section is normative” 意味着你将阅读的内容是实现者应该遵循的细节，这部分一般会包含示例和解释。 user agent 一般是指用户用于访问该技术的程序的代名词。对于 HTML 来说，user agent 就是指浏览器；对 Scalable Vector Graphics（SVG）来说，它可能是像 Batik 这样的程序 或者 Adobe’s SVG viewer 这样的插件。 RFC Request For Comment, 一个代表了互联网标准的文档。 helping verbs 如果一个规范说它遵循了 RFC2119 ，则某些助动词就具有正式的含义。must 表示定义是绝对的要求，must not 表示定义是绝对的禁止，should 表示一项特性可以实现也可以不实现，但是如果你不实现它，最好要有充分的理由， should not 意味着如果你要加入一个特性，最好要有充分的理由。 略读 Dear Aunt Martha: Thank you for the book on elephants. It told me more about elephants than I wanted to know. ——A child’s thank-you letter ​ 不必仔细阅读规范的每一个单词，如果你发现自己处于一个完全没有任何术语索引标签的区域，又看起来像法律文书或者计算机科学文章一样，那么就简单瞥一眼就够了。 ​ 比如像下面的 XLS:FO 规范这些部分就完全是可以跳过的。（实际上，作为一个用户来说，这个规范真正需要仔细阅读的部分在第六章之前都不会到来。） 4.2.5 Stacking Constraints: This section defines the notion of block-stacking constraints and inline-stacking constraints involving areas. These are defined as ordered relations, i.e., if A and B have a stacking constraint it does not necessarily mean that… Hey! Are you ready to skim yet?! ​ 另一方面，有些地方你应该慢下来认真看。如果你看到插图，要看一下标签或者标注。他们通常会提到重要的信息，如果看到带有示例的部分，也要放慢节奏仔细阅读。 命名空间​ 在 XML 术语中，命名空间 使用来将不同标记语言混合在文档中的机制。例如我想在 HTML 文档中引入 数学标记语言（Math Markup Language），我就必须在文档的顶部元素中放入额外的声明，然后在数学元素前面添加 ml: 前缀 Here is Einstein’s famous equation, E = MC2, with which we all are familiar. ​ 最好遵循你在示例中看到的任何命名空间前缀。大部分情况下，如果你遇到了一个关于某项 XML 技术是 “命名空间感知” 的大篇幅讨论，你可以安全地跳过了。 学会阅读 BNF​ BNF 代表 Backus Naur Form, 或者 Backus Normal Form。它是一种表达计算机语言语法的紧凑方式，一直存在，并将永远存在。不同的声明使用不同风格的 BNF, 但是他们都会将冗长的英语描述翻译成符号格式。以三明治的构成为例： A sandwich consists of a lower slice of bread, mustard or mayonnaise; optional lettuce, an optional slice of tomato; two to four slices of either bologna, salami, or ham (in any combination); one or more slices of cheese, and a top slice of bread. sandwich ::= lower_slice [ mustard | mayonnaise ] lettuce? tomato? [ bologna | salami | ham ] {2,4} cheese+ top_slice ​ 定义的的组成部分都是顺序排列，空格分隔的。方括号表示分组，分组内的选项用竖线分隔。 ​ 如果一个项目后面跟着一个问号（？），表示“一个或者没有”；如果后面跟着加号（+），表示“一个或者多个”；如果后面是星号（*），表示“零个或者多个”；如果后面跟着大括号内的数字，它就给出了这个项目可以出现的最少和最多的次数限制。 ​ 括弧或者多组方括号用来将更加复杂的定义中的项目分组。有时候通用项目（例如“color”）包含在 &lt; 和 &gt; 中，或者固定项目将包含在引号中。 学会阅读文档类型定义 The Grolier Encyclopedia® is the source authority for all answers and questions asked on Jeopardy®. ——Credit on TV game show ​ 我们一般会在文档中添加 &lt;!DOCTYPE …&gt; 标签声明来告诉浏览器你用的是 HTML 或者 XHTML 的哪个版本。这些声明就是文档类型声明（Document Type Definition），或者 DTD，定义了文档中合法的元素组合。 ​ 阅读 DTD 是比较难的，但也不是不可能。并且它是值得一读的，因为 DTD 是判断在特定的标记语言中语法正确性的最高权威。 ​ 关于如何阅读 DTD 文档的完整解释不在本文范围内，但是可以在Elizabeth Castro 的 XML for the World Wide Web 视觉快速入门指南，或者 Erik Ray的 Learning XML 中读到。这里有一些你可能在 DTD 中看到的简短示例： 1234&lt;!ENTITY %fontstyle &quot;(tt | i | b)&quot;&gt; &lt;!ENTITY %inline &quot;(#PCDATA | %fontstyle;)&quot;&gt; &lt;!ELEMENT div (p | %inline;)+&gt; &lt;!ATTLIST div align (left | right | center) #IMPLIED&gt; 这里是他们的英文解释： The font style elements are &lt;code&gt;, &lt;i&gt;, and &lt;b&gt;. Inline elements consist of text or font style elements. A &lt;div&gt; can contain one or more &lt;p&gt; or inline elements in any order. A &lt;div&gt; has an optional align attribute with values of left, right, or center. IDLE PAST IDL, BE BOUND BY BINDINGS​ 一些 XML 技术，例如 SVN 和 SMIL ，允许用户编写程序来动态控制文档，就像 JavaScript 让你可以控制 HTML 文档一样。他们的规范中会有一些章节描述脚本是如何与 Document Object Model 工作的。这部分用 IDL 来描述接口，Interface Definition Language。 ​ IDL 是一类通用符号，用于描述用户代理用来访问编程环境的信息，即描述软件编程接口（API）的语言。IDL 不是一种编程语言；它是用一种紧凑的方式来描述接口的符号系统。IDL 接口定义很可能不是你要找的东西。 ​ 你需要的东西，决定于你选择的编程语言，是 Java binding 还是 ECMAScript bindings 。 ​ Bindings 是脚本中可用的对象，属性，和方法列表的奇特的术语。ECMAScript 是 European Computer Manufacturer’s Association standard version of JavaScript。 ​ 如果你使用的是一些其他的像 Perl 或者 Python 这样的语言，你就要去其他地方看看相关的资料，例如 Comprehensive Perl Archive Network 或者 Python XML Special Interest Group. 总结 理解 W3C 规范是写给实现者的，而不是用户。 许多规范都有一个章节会告诉你规范是如何组织的，以及你应该如何阅读 了解规范使用的词汇表 记住你不必读懂每一个单词，跳过那些读不通的部分 避开关于命名空间的讨论 学会阅读 BNF——它在许多地方用到 学会阅读 DTD来解答语法问题 如果技术是可以编写脚本的，则信息在 binding 中。 只要耐心和坚持，你就会惊讶与你可以从 W3C 规范中获得的信息量。 作者的其他文章 Using XML Get Ready for HTML 5 “Forgiving” Browsers Considered Harmful DOM Design Tricks]]></content>
      <categories>
        <category>FE</category>
        <category>W3C</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>W3C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SEO中的几个重要的 META tag]]></title>
    <url>%2F2018%2F10%2F29%2FSEO%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E7%9A%84-META-tag%2F</url>
    <content type="text"><![CDATA[​ Meta tags 作为描述网页内容的文本片段，它不会在页面上显示，只会存在与页面代码中。不同网站的 Meta tags 或多或少都有点相似，一些内容描述符，告诉搜索引擎网页的内容。Meta tags 只会出现在页面 “head” 标签内，只对搜索引擎可见。然而，它是 SEO 的重要手段。 ​ 我们介绍一下 SEO 中的 8 个重要的 Meta tag： Title tag, Meta description, Canonical Tag, Alternative text (Alt) Tag, Robots meta tag, Social Media Meta Tags (Open Graph and Twitter Cards), Header tags, Responsive Design Meta Tag TITLE TAG​ 不论对访问者还是搜索引擎来说，Title tag 都是第一个出现的对网页作出声明的 HTML 元素。 所有浏览器都支持传这个标签，包括 Chrome, Firefox, Safari 等. ​ 始终要在网站页面的 &lt;head&gt; 区域添加 Title tag。 123&lt;head&gt; &lt;title&gt;This is Title Sample&lt;/title&gt;&lt;/head&gt; ​ Title tag 优化的长度: Google 通常显示 55–64 个字符 (保持 60 字符以内). ​ Title tags 对 SEO 和来访者都很重要，它会显示在 SERP （Search Engine Result Page）和 浏览器标题栏中。 浏览器标题栏显示如下: SERP 标题显示如下: Title tags 是 SEO 中仅次于内容的最重要的的页面因素。— Source: MOZ 你不能在你的页面上添加多于一个的 &lt;title&gt; 元素。 — Source: w3schools 好的 Title tags 的几个要点: 在 title tag 中添加修饰词 (How to |The current year | Review |Best | Tips | Top |Find | Buy | Easy) 在 title tag 中迁入长尾关键词 在标题中添加数字 (例如：9 个重要的 HTML 标签帮助你的网站优化 SEO) title tag 中按重要性排序，重要关键词前置 不要不在乎关键词 每个页面使用唯一的 title tag META DESCRIPTION​ Meta Description 是综述网页的 HTML 元素。搜索引擎通常在搜索结果的标题下方显示 Meta description。 代码示例 123&lt;head&gt;&lt;meta name=”description” content=”This is a meta description sample. We can add up to 160 characters.”&gt;&lt;/head&gt; ​ Google does not use the Meta description as a ranking signal; still, it has a massive effect on your page CTR because it shows up in search results. ​ Google 不使用 Meta description 作为搜索排名的指标；但是，它对你的网页 CTR（ClickThrough Rate ）有重要影响，因为它会显示在搜索结果中。 ​ 在2017年12月, Google 增加了搜索结果片段的长度。现在 Google 确认了在去年12月扩大长度后再次 缩短了搜索结果片段。 ​ Meta description 的较优长度是多少? “这些片段没有固定的长度，长度因我们的系统认为认为的最优而不同” 他补充说, “Google 不会给出片段的最大长度，因为这些片段都是动态生成的” Source, Danny Sullivan ​ 在桌面端浏览器中描述片段的平均长度大约从原来的 300+ 字符 减少到大约 160 字符。 ​ 移动端搜索结果现在下降到平均 130 字符。 Goolge 生成的搜索结果描述 优质 Description tag 的几项要点 Don’t put emphasis on the number of characters, as Google might pull Meta description text from your content based on a user’s query. 不要过分强调字数，因为 Google 可能会在用户请求下，从你的网页上拉取 Meta 描述信息的文本。 Do not add duplicate Meta Descriptions Add clear Call-to-action (CTA) in your descriptions like Apply today, Check-out, Contact us today etc. See these CTA keywords for marketing campaigns Add your targeted keywords in descriptions Strategically provide solutions to a problem Write for your users and encourage them to click with specific and relevant content Add any discounts or offers you’ve going on Show empathy while writing your Meta Descriptions CANONICAL TAG The Canonical tag is an HTML link tag with “rel=canonical” attribute that is used if you have a single page URL that has the same content with other multiple page URLs. By implementing the Canonical tag in the code, we are telling search engines that this URL is the main page and avoid indexing other duplicate page URLs. A canonical tag Syntax: &lt;link rel=”canonical” href=”http://example.com/” /&gt; Where should we choose a canonical URL? Multiple URLs: http://www.example.com https://www.example.com http://example.com http://example.com/index.php Google sees all the above URLs as duplicate versions of the Homepage. And to fix this problem, the canonical tag (rel=canonical) was invented. Session ID URLs: These are the automatic system-generated URLs and commonly generated due to the tracking URLs, breadcrumb links and permalinks in CMS http://example.com/properties/villa-331-luxury-rental?partnerID=18 http://example.com/target.php?session_id=rj3ids98dhpa0mcf3jc89mq1t0 Mobile URL: When using a special URL (m. example.com) for the mobile version of your website. SEMrush itself has 2 versions — one is a mobile version and the other is a desktop version. For the mobile and desktop version, SEMrush is using the following canonical tag: &lt;link rel=”canonical” href=”https://www.semrush.com/” /&gt; ALTERNATIVE TEXT (ALT) TAGThe Alt tag is important for any images, as search engines cannot read them, so you need to add proper Alt text to the images so the search engine can consider them. Syntax for Alt Text: &lt;img src=”http://example.com/xyz.jpg” alt=”xyz” /&gt; Key points to consider while creating alt-tags for images: All images should have informative filenames Alt text needs to be short clear and to the point Always use the original, right type of image, as this is an essential step towards success Create an image sitemap Use 50–55 characters (up to 16 words) in the alt text Use an optimal file size without degrading its quality for faster page loading speed “Adding an alt tag is very easy to do and you should pretty much do it on all of your images. It helps your accessibility and it can help us understand what’s going on in your image.” Source ROBOTS META TAGThe Robots Meta tag is an HTML tag that provides instructions to web crawlers on whether to index or noindex a web page. The Robots Meta tag has four main values for search engine crawlers: FOLLOW –The search engine crawler will follow all the links in that web page INDEX –The search engine crawler will index the whole web page NOFOLLOW — The search engine crawler will NOT follow the page and any links in that web page NOINDEX — The search engine crawler will NOT index that web page The Robots Meta tag syntax: — Means not to index or not to follow this web page. — Means index and follow this web page. Note: The robots Meta tag should be placed in the section of your web page. SOCIAL MEDIA META TAGS (OPEN GRAPH AND TWITTER CARDS)Open Graph Tags: Open Graph Meta tags are designed to promote integration between Facebook, LinkedIn, Google and the website URLs that you shared on these platforms. Here is a sample of how Open Graph tags look like in standard HTML: Twitter Cards: Twitter cards work in a similar way to Open Graph, except you add these special Meta tags only for Twitter. Twitter will use these tags to enhance the display of your page when shared on their platform. Here is a sample of how a Twitter card looks like in standard HTML: How both Social Media Meta Tags look like: Head over to this post if you want to know everything about these tags. HEADER TAGSA Header tag is used for headings creations, i.e. by using these we can apply font changes. The heading elements are H1, H2, H3, H4, H5, and H6 with H1 being the highest (or most important) level and H6 the least. Here is an example of how we can use header tags taken from SEMrush: 9 Tips for Boosting the Speed of your Shopify Website Paragraph of content another paragraph of content Performance Analysis Paragraph of content Analyzes the Mobile and Desktop Performance with PageSpeed Insights Important Point to consider: Use as Many H1 Tags as You Want Source: Search Engine Roundtable RESPONSIVE DESIGN META TAGThe final important Meta tag is the Responsive Design Meta tag, which we call “Viewport Meta Element”. By using the viewport meta tag we can control layout for web pages on mobile browsers. This viewport element is included in the head section of your web page. Syntax: If you want to learn more about this responsive design Meta tags, head over to this nicely written post. Note: Do not use this responsive Meta tag if your website pages are not responsive, as it will make the user experience worse. Meta Tags to ignoreFinally, there are a few tags — we can call them bad Meta tags and we should simply ignore them: Keywords tag– Google does not use the keywords Meta tag in web ranking. — Source Revisit after — This HTML tag is a command to robots to return to a page after a specific period. This tag is not followed by any major search engine and has no value in SEO. It is better to avoid this tag and leave it to the search engines to decide how to crawl your website. Syntax: Expiration/date — This tag defines the expiration date of your page. Personally I would not recommend this, just remove this if you are using it. Syntax: Site verification– Just ignore this. You can verify your site using Google Search Console and Bing Webmaster tool. Copyright– Every site puts their copyright in the footer, so you don’t need a separate tag. A big NO for this tag. Distribution — The “distribution” value is supposedly used to control who can access the document, typically set to “global”. It’s inherently implied that if the page is open (not password-protected, like on an intranet) that it’s meant for the world. Go with it, and leave the tag off the page. — Source Generator — Useless tag. Cache control –This tag allows web publishers to define how often a page is cached. Generally, these are not required; we can simply use the HTTP header instead of this HTML tag. The ODP Robots Meta Tag — Google no longer follows this Meta tag. –Source Geo Meta Tag — Google does not use Geo Meta tags to rank pages. — Source So these are the few HTML tags which we should consider or simply ignore. Now you can easily use the relevant HTML Meta tags intelligently. Don’t forget to comment below and share your views on HTML Tags. Thanks for reading! Originally published at advancedwebranking.com SEO Meta Tags In 2018 Meta Tags Searchengineoptimization]]></content>
      <categories>
        <category>FE</category>
        <category>SEO</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>SEO</tag>
        <tag>META tags</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT 开启 emoji]]></title>
    <url>%2F2018%2F10%2F29%2FHexo-NexT-%E5%BC%80%E5%90%AF-emoji%2F</url>
    <content type="text"><![CDATA[Hexo 开启欢乐的 emoji 之旅 💛 Hexo 默认的 markdown 渲染引擎不支持将 Github emoji 渲染到静态的 html 页面中，我们换一个支持 emoji 的引擎，再增加一个 emoji 插件即可. 安装命令行如下： 123npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --savenpm install markdown-it-emoji --save Tips：据说 hexo-renderer-markdown-it 的速度要比 Hexo 原装插件要快，而且功能更多 配置完成插件安装后还需要修改 Hexo 站点配置文件 _config.yml（不是主题配置哦） 123456789101112131415161718192021## markdown 渲染引擎配置，默认是hexo-renderer-marked，这个插件渲染速度更快，且有新特性markdown: render: html: true xhtmlOut: false breaks: true linkify: true typographer: true quotes: '“”‘’' plugins: - markdown-it-footnote - markdown-it-sup - markdown-it-sub - markdown-it-abbr - markdown-it-emoji anchors: level: 2 collisionSuffix: 'v' permalink: true permalinkClass: header-anchor permalinkSymbol: ¶ 这里需要注意 render: 下的 html: 配置项，它的作用是控制 Markdown 渲染引擎是否转义文档中出现的 html 标签，默认为 false ，这里要设置为 true，否则回导致 &lt;!--more--&gt; 渲染失败。 123html: true # 不转义 HTML 内容，即允许 HTML ## ORhtml: false # 转义 HTML，&lt; &gt; 尖括号会被转义成 &amp;lt; &amp;gt;等 plugins: 中的最后一项 - markdown-it-emoji是手动添加的，官方 Github Wiki 中给出的配置不包含这一项，其他配置参照的 Github Wiki 中的默认配置，hexo-renderer-markdown-it 提供的其他新特性还没有一一尝试，暂时只想用它的 emoji 功能。:v: 使用方法 在 Emoji 中找到你想要的表情，然后点击复制粘贴。 常用的emoji可以记下它的编码，直接输入，例如直接输入笑脸对应的 emoji 编码 :smile: 就可以得到 😄 。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Emmet Cheat Sheet]]></title>
    <url>%2F2018%2F10%2F28%2FEmmet-Cheat-Sheet%2F</url>
    <content type="text"><![CDATA[​ 之前一直手敲HTML标签😅，最近知道了 Emmet 这个神奇的东西，可以用短短一行代码生成复杂的树结构，同时绑定属性，还具有自动编号等强大功能。于是上官网把 Cheat Sheet 都手敲了一遍，然后记录一下，添加了一些注解，方便自己记忆查阅，原文。 Child: &gt;nav&gt;ul&gt;li 12345&lt;nav&gt; &lt;ul&gt; &lt;li&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/nav&gt; Sibling: +div+p+bq 123&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;/blockquote&gt; Climb-up: ^div+div&gt;p&gt;span+em^bq 12345&lt;div&gt;&lt;/div&gt;&lt;div&gt; &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt; &lt;blockquote&gt;&lt;/blockquote&gt;&lt;/div&gt; div+div&gt;p&gt;span+em^^bq 12345&lt;div&gt;&lt;/div&gt;&lt;div&gt; &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;/blockquote&gt; Grouping: ()div&gt;(header&gt;ul&gt;li*2&gt;a)+footer&gt;p 1234567891011&lt;div&gt; &lt;header&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=""&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=""&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/header&gt; &lt;footer&gt; &lt;p&gt;&lt;/p&gt; &lt;/footer&gt;&lt;/div&gt; (div&gt;dl&gt;(dt+dd)*3)+footer&gt;p 12345678910111213&lt;div&gt; &lt;dl&gt; &lt;dt&gt;&lt;/dt&gt; &lt;dd&gt;&lt;/dd&gt; &lt;dt&gt;&lt;/dt&gt; &lt;dd&gt;&lt;/dd&gt; &lt;dt&gt;&lt;/dt&gt; &lt;dd&gt;&lt;/dd&gt; &lt;/dl&gt;&lt;/div&gt;&lt;footer&gt; &lt;p&gt;&lt;/p&gt;&lt;/footer&gt; Multiplication: *ul&gt;li*5 1234567&lt;ul&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt;&lt;/ul&gt; li*2 会使 同一分组下 之后的元素分别 *2 ，例如 li*2&gt;a+span 生成的html是这样的 12&lt;li&gt;&lt;a href=""&gt;&lt;/a&gt;&lt;span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=""&gt;&lt;/a&gt;&lt;span&gt;&lt;/span&gt;&lt;/li&gt; Item numbering: $ul&gt;li.item$*5 编号 1234567&lt;ul&gt; &lt;li class="item1"&gt;&lt;/li&gt; &lt;li class="item2"&gt;&lt;/li&gt; &lt;li class="item3"&gt;&lt;/li&gt; &lt;li class="item4"&gt;&lt;/li&gt; &lt;li class="item5"&gt;&lt;/li&gt;&lt;/ul&gt; h$[title=item$]{Header $}*3 任意位置都可以写 123&lt;h1 title="item1"&gt;Header 1&lt;/h1&gt;&lt;h2 title="item2"&gt;Header 2&lt;/h2&gt;&lt;h3 title="item3"&gt;Header 3&lt;/h3&gt; ul&gt;li.item$$$*5 多位数编号 1234567&lt;ul&gt; &lt;li class="item001"&gt;&lt;/li&gt; &lt;li class="item002"&gt;&lt;/li&gt; &lt;li class="item003"&gt;&lt;/li&gt; &lt;li class="item004"&gt;&lt;/li&gt; &lt;li class="item005"&gt;&lt;/li&gt;&lt;/ul&gt; ul&gt;li.item$@-*5 倒序 1234567&lt;ul&gt; &lt;li class="item5"&gt;&lt;/li&gt; &lt;li class="item4"&gt;&lt;/li&gt; &lt;li class="item3"&gt;&lt;/li&gt; &lt;li class="item2"&gt;&lt;/li&gt; &lt;li class="item1"&gt;&lt;/li&gt;&lt;/ul&gt; ul&gt;li.item$@3*5 从指定数值开始编号 12345678&lt;ul&gt; &lt;li class="item3"&gt;&lt;/li&gt; &lt;li class="item4"&gt;&lt;/li&gt; &lt;li class="item5"&gt;&lt;/li&gt; &lt;li class="item6"&gt;&lt;/li&gt; &lt;li class="item7"&gt;&lt;/li&gt;&lt;/ul&gt;ID and CL ID and CLASS attributes#header 1&lt;div id="header"&gt;&lt;/div&gt; .title 1&lt;div class="title"&gt;&lt;/div&gt; form#search.wide 1&lt;form id="search" class="wide"&gt;&lt;/form&gt; p.class1.class2.class3 1&lt;p class="class1 class2 class3"&gt;&lt;/p&gt; Custom attributes 自定义属性p[title=”Hello World”] 属性值可以不加引号，但是如果包含空格，则要加上，否则，World 会被当作另一个属性名称 1&lt;p title="Hello world"&gt;&lt;/p&gt; td[rowspan=2 colspan=3 title] 1&lt;td rowspan="2" colspan="3" title=""&gt;&lt;/td&gt; [a=’value1’ b=’value2’] 自定义属性，属性值可以不加引号 1&lt;div a="value1" b="value2"&gt;&lt;/div&gt; Text: {} 插入文本内容a{Click me} 1&lt;a href=""&gt;Click me&lt;/a&gt; p&gt;{Click }+a{here}+{ to continue} 等效于 p{Click}&gt;a{here}+{to continue} 1&lt;p&gt;Click &lt;a href=""&gt;here&lt;/a&gt; to continue&lt;/p&gt; Implicit tag names 隐式标签声明一个带class的div 可以不用输入div；.header+.footer 则生成: 12&lt;div class="header"&gt;&lt;/div&gt;&lt;div class="footer"&gt;&lt;/div&gt; Emmet 还会根据父标签进行判定例如输入ul&gt;.item*3 则生成： 12345&lt;ul&gt; &lt;li class="item"&gt;&lt;/li&gt; &lt;li class="item"&gt;&lt;/li&gt; &lt;li class="item"&gt;&lt;/li&gt;&lt;/ul&gt; 下面是所有的隐式标签名称： li：用于 ul 和 ol 中 tr：用于 table、tbody、thead 和 tfoot 中 td：用于 tr 中 option：用于 select 和 optgroup 中]]></content>
      <categories>
        <category>FE</category>
        <category>Emmet</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>Emmet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS3选择器 Selector Level 3]]></title>
    <url>%2F2018%2F10%2F27%2FCSS3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[阅读 W3C 2018年9月11日发布的 Selectors Level 3 提议的一些翻译和记录，文档中说，这份提议还只是草稿，不属于规范的一部分。 概要​ 选择器（Selectors ）是一种用来匹配树节点元素的模式，因此一种可以用来选择XML文档节点的技术。选择器已经针对 HTML 和 XML 进行了优化，旨在用于性能苛刻的代码。 ​ CSS (Cascading Style Sheets) 是一种用于描述在显示器、纸张和语音等中渲染和呈现 HTML 和 XML 文 档的语言。CSS 用选择器将样式属性绑定到文档的元素。 ​ 在 CSS1 和 CSS2 中已经有了选择器，下面介绍 CSS3 以及其他语言可能需要用到的选择器。 ​ 选择器定义了下面的方法： 1expression * element -&gt; boolean ​ 就是说，给定一个元素和一个选择器，规范定义改元素是否与选择器匹配。 通过对一个子树中的所有元素进行表达式评估，这些表达式还可以被用于选择一些元素集合，或者从元素集合中选择一个元素。 介绍一级选择器（Selector Level 1）和二级选择器（Selector Level 2）已经分别被定义为 CSS1 和 CSS2.1规范中定义的选择器功能的子集。 相对 CSS2 的变化 一些基本的定义（selector，group of selector,simple selector等）发生了变化；尤其是，在 CSS2 中的简单选择器现在称为简单选择器序列（sequence of simple selectors）,术语“简单选择器” 现在被用于该序列的组件。 可选的命名空间组件现在可以被用于元素类型选择器，通用选择器和属性选择器。 引入了新的组合器——后续兄弟组合（Subsequent-sibling combinator） 新的简单选择器，包括子串匹配属性选择器（substring matching attribute）和新的伪类（pseudo-classes） 新的伪元素，以及伪元素的 “::” 约定的引入。 语法被重写 选择器现在是 CSS3 的模块，有独立的声明，其他选择器可以独立于 CSS 参考本选择器的文档。 选择器（Selector）下面是选择器语法的总结 Pattern Represents Description Level * any element Universal selector 2 E an element of type E Type selector 1 E[foo] an E element with a “foo” attribute Attribute selectors 2 E[foo=”bar”] an E element whose “foo” attribute value is exactly equal to “bar” Attribute selectors 2 E[foo~=”bar”] an E element whose “foo” attribute value is a list of whitespace-separated values, one of which is exactly equal to “bar” Attribute selectors 2 E[foo^=”bar”] an E element whose “foo” attribute value begins exactly with the string “bar” Attribute selectors 3 E[foo$=”bar”] an E element whose “foo” attribute value ends exactly with the string “bar” Attribute selectors 3 E[foo*=”bar”] an E element whose “foo” attribute value contains the substring “bar” Attribute selectors 3 E[foo\ =”en”] an E element whose “foo” attribute has a hyphen-separated list of values beginning (from the left) with “en” Attribute selectors 2 E:root an E element, root of the document Structural pseudo-classes 3 E:nth-child(n) an E element, the n-th child of its parent Structural pseudo-classes 3 E:nth-last-child(n) an E element, the n-th child of its parent, counting from the last one Structural pseudo-classes 3 E:nth-of-type(n) an E element, the n-th sibling of its type Structural pseudo-classes 3 E:nth-last-of-type(n) an E element, the n-th sibling of its type, counting from the last one Structural pseudo-classes 3 E:first-child an E element, first child of its parent Structural pseudo-classes 2 E:last-child an E element, last child of its parent Structural pseudo-classes 3 E:first-of-type an E element, first sibling of its type Structural pseudo-classes 3 E:last-of-type an E element, last sibling of its type Structural pseudo-classes 3 E:only-child an E element, only child of its parent Structural pseudo-classes 3 E:only-of-type an E element, only sibling of its type Structural pseudo-classes 3 E:empty an E element that has no children (including text nodes) Structural pseudo-classes 3 E:link E:visited an E element being the source anchor of a hyperlink of which the target is not yet visited (:link) or already visited (:visited) The link pseudo-classes 1 E:active E:hover E:focus an E element during certain user actions The user action pseudo-classes 1 and 2 E:target an E element being the target of the referring URI The target pseudo-class 3 E:lang(fr) an element of type E in language “fr” (the document language specifies how language is determined) The :lang() pseudo-class 2 E:enabled E:disabled a user interface element E which is enabled or disabled The UI element states pseudo-classes 3 E:checked a user interface element E which is checked (for instance a radio-button or checkbox) The UI element states pseudo-classes 3 E::first-line the first formatted line of an E element The ::first-line pseudo-element 1 E::first-letter the first formatted letter of an E element The ::first-letter pseudo-element 1 E::before generated content before an E element The ::before pseudo-element 2 E::after generated content after an E element The ::after pseudo-element 2 E.warning an E element whose class is “warning” (the document language specifies how class is determined). Class selectors 1 E#myid an E element with ID equal to “myid”. ID selectors 1 E:not(s) an E element that does not match simple selector s Negation pseudo-class 3 E F an F element descendant of an E element Descendant combinator 1 E &gt; F an F element child of an E element Child combinator 2 E + F an F element immediately preceded by an E element Next-sibling combinator 2 E ~ F an F element preceded by an E element Subsequent-sibling combinator 3 区分大小写所有的选择器语法都是在 ASCII 范围内且大小不写敏感的（例如 [a-z] 和 [A-Z]是等同的），除了不受选择器控制的部分。在选择器中的文档语言元素名称，属性名称和属性值的是否区分大小写要取决于文档语言本身。例如，在 HTML 中，元素名是大小写敏感的，但是 XML 中区分大小写。]]></content>
      <categories>
        <category>FE</category>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用HTML标签归纳]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%B8%B8%E7%94%A8HTML%E6%A0%87%E7%AD%BE%E5%BD%92%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[HTML常用标签divdiv标签用于组合其他HTML元素，本身无实在意义。常用于页面的布局，比如一个展开式的广告页面框架大致如下： 123456&lt;body&gt; &lt;div id=&quot;wrap-container&quot;&gt; &lt;div id=&quot;collapsed-container&quot;&gt;&lt;/div&gt; &lt;div id=&quot;expanded-container&quot;&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt; h1~h6, p, span, strong, em…此类标签用于设置文本，常见的使用方式是填充段落，比如弹出的legal框文字HTML结构如下: 12345&lt;div id=&quot;legal-window&quot;&gt; &lt;h4&gt;LEGAL&lt;/h4&gt; &lt;img id=&quot;legal-close&quot; src=&quot;img/embed/legal-close.png&quot; alt=&quot;close window&quot;&gt; &lt;p&gt;*Requires a system with Intel&lt;sup&gt;&amp;reg;&lt;/sup&gt; Turbo Boost Technology. Intel&lt;sup&gt;&amp;reg;&lt;/sup&gt; Turbo Boost Technology and Intel&lt;sup&gt;&amp;reg;&lt;/sup&gt; Turbo Boost Technology 2.0 are only available on select Intel&lt;sup&gt;&amp;reg;&lt;/sup&gt; processors. Consult your PC manufacturer. Performance varies depending on hardware, software, and system configuration. For more information, visit http://www.intel.com/go/turbo. Copyright &amp;copy; 2014 Intel Corporation. All rights reserved. Intel, the Intel logo, Intel Core, Look Inside, Intel Inside, and Pentium are trademarks of Intel Corporation in the U.S. and/or other countries. Other names and brands may be claimed as the property of others.&lt;/p&gt;&lt;/div&gt; ul, li, ol, dl, dt, dd此类标签用于设置带有列表内容的，比如导航栏的下拉菜单，多视频的缩略图等： 1234567891011121314151617181920212223242526&lt;ul class=&quot;nav-tools-list&quot;&gt; &lt;li&gt; &lt;div&gt; &lt;img src=&quot;shoppingtools-icon-1.png&quot; alt=&quot;&quot;&gt; &lt;span&gt;Build &amp; Price&lt;/span&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;div&gt; &lt;img src=&quot;shoppingtools-icon-2.png&quot; alt=&quot;&quot;&gt; &lt;span&gt;Incentives &amp; Offers&lt;/span&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;div&gt; &lt;img src=&quot;shoppingtools-icon-3.png&quot; alt=&quot;&quot;&gt; &lt;span&gt;Request a Local Quote&lt;/span&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;div&gt; &lt;img src=&quot;shoppingtools-icon-4.png&quot; alt=&quot;&quot;&gt; &lt;span&gt;Search Dealer Inventory&lt;/span&gt; &lt;/div&gt; &lt;/li&gt;&lt;/ul&gt; form表单相关页面中涉及到表单时候，需要使用到form相关标签： 1234567&lt;form name=&quot;frm-sample&quot; class=&quot;frm-sample&quot; action=&quot;try&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;Name&quot;&gt; &lt;div id=&quot;status-message&quot;&gt;&lt;/div&gt; &lt;div id=&quot;sample-captcha&quot;&gt;&lt;/div&gt; &lt;a id=&quot;check-is-filled&quot; class=&quot;info-btn&quot;&gt;Check if visualCaptcha is filled&lt;/a&gt; &lt;button type=&quot;submit&quot; name=&quot;submit-bt&quot; class=&quot;submit&quot;&gt;Submit form&lt;/button&gt;&lt;/form&gt; table表格相关页面中涉及到table结构，需要使用到table相关标签: 1&lt;talbe&gt;&lt;/talbe&gt; img, canvas用于图像显示。一般不直接操作img,canvas元素，而是在它的外层包裹一层父级元素（可以为span,div等)，对父级元素进行操作： 1234567&lt;div class=&quot;preload&quot; data-src=&quot;CheddarBacon.png&quot;&gt; &lt;img src=&quot;CheddarBacon.png&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;!-- or --&gt;&lt;div id=&quot;sprite-car&quot; class=&quot;cw-sprite sprite-car&quot; cw-interval=&quot;30&quot; cw-loops=&quot;1&quot; cw-auto-play=&quot;false&quot; cw-texture=&quot;images/sprites/expanded/car-texture.png&quot; cw-mapper=&quot;car&quot;&gt; &lt;canvas class=&quot;cw-renderer&quot; width=&quot;460&quot; height=&quot;130&quot;&gt;&lt;/canvas&gt;&lt;/div&gt; aa标签用于打开链接，发送邮件，段落跳转等功能。使用时需要注意阻止掉标签的默认事件。 链接跳转，常见的关于分享按钮的HTML结构如下： 12345678910111213141516171819202122232425&lt;div id=&quot;shareBox&quot;&gt; &lt;ul&gt; &lt;li id=&quot;facebook&quot;&gt; &lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; data-shareWay=&quot;facebook&quot;&gt; &lt;img alt=&quot;Post on Facebook&quot; src=&quot;img/embed/f4Icon3.png&quot; alt=&quot;Facebook&quot; /&gt; &lt;/a&gt; &lt;/li&gt; &lt;li id=&quot;twitter&quot;&gt; &lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; data-shareWay=&quot;twitter&quot;&gt; &lt;img alt=&quot;Tweet this&quot; src=&quot;img/embed/f4Icon4.png&quot; /&gt; &lt;/a&gt; &lt;/li&gt; &lt;li id=&quot;pinterest&quot;&gt; &lt;a data-pin-do=&quot;buttonPin&quot; data-pin-config=&quot;none&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot; data-shareWay=&quot;pinterest&quot;&gt; &lt;img alt=&quot;Pin it&quot; src=&quot;img/embed/f4Icon5.png&quot; /&gt; &lt;/a&gt; &lt;/li&gt; &lt;li id=&quot;email&quot;&gt; &lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; data-shareWay=&quot;email&quot;&gt; &lt;img src=&quot;img/embed/f4Icon6.png&quot; /&gt; &lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;/p&gt;&lt;/div&gt; 发送邮件的代码片段如下： 123&lt;div class=&quot;button&quot;&gt; &lt;a class=&quot;mail&quot; data-img=&quot;mail.png&quot; href=&quot;mailto:example@gmail.com?subject=xxx&amp;body=xxx&quot;&gt;&lt;/a&gt;&lt;/div&gt; 段落跳转代码片段如下： 12&lt;div id=&quot;html5&quot;&gt;&lt;/div&gt;&lt;a name=&quot;user-content-html5&quot; href=&quot;#html5&quot; class=&quot;headeranchor-link&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;headeranchor&quot;&gt;&lt;/span&gt;&lt;/a&gt; HTML5标签查询W3School: 点击查询]]></content>
      <categories>
        <category>FE</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HTTP的请求、响应以及 CURL 工具介绍]]></title>
    <url>%2F2018%2F10%2F23%2F%E5%85%B3%E4%BA%8EHTTP%E7%9A%84%E8%AF%B7%E6%B1%82%E3%80%81%E5%93%8D%E5%BA%94%E4%BB%A5%E5%8F%8A%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[在像 HTTP 这样的客户端 - 服务器协议中，会话一般包含三个部分： 客户端建立 TCP 连接（或者如果传输层不是 TCP 的话就是某种适当的连接）。 客户端发送请求，并等待服务器应答 服务器处理请求，回送应答，提供状态码和适当的数据。 对于 HTTP/1.1来说，在完成第三步以后，连接不再被关闭，客户端可以立刻发起进一步的请求：这意味着第二、三两步现在可以执行任意次。即连接的复用。 建立连接在客户端 - 服务器协议中 ，是客户端建立连接。打开一个 HTTP 连接意味着在底层传输层中启动连接，通常这层传输层是 TCP。 对于 TCP ，默认端口（对于计算机上的 HTTP 服务器）是端口80。其他的端口也可以 使用，像 8000 或者8080 这些。获取一个页面的 URL 包含了域名和端口号，如果后者是80端口则通常可以忽略。 注意：客户端 - 服务器模型不允许服务器在没有明确的请求的情况下发送数据给客户端。为了解决这个问题，Web 开发者们使用了一些技术：用 XMLHTTPRequest 轮询服务器，使用 Fetch API，使用 WebSockets API ，或者相似的协议。 发送客户端请求一旦请求建立，用户代理就可以发送请求（用户代理通常是浏览器，但是也可以是其他的东西，例如，爬虫）。客户端请求中包含了一些用 CRLF （回车换行）分隔开的文本指令，可划分三个块： 第一行包含了一个请求方法，后跟其参数： 文档路径，例如，一个不包含协议或者域名的绝对路径。 HTTP 协议版本 后续行代表请求头部，像服务器提供有关适合的数据类型的信息（例如，什么语言，MIME 类型），或者其他改变其行为的数据（例如，如果已经缓存就不发送应答）。这些 HTTP 头组成了一个区块，这个区块以一个空行结尾。 最后一个区块是一个可选的数据块，可能包含了一些主要被 POST 方法使用的数据。 示例请求获取 developer.mozilla.org的根页面，例如，http://developer.mozilla.org/ ，并告诉服务器，如果可能，客户端将更喜欢法语页面： 1234GET / HTTP/1.1Host: developer.mozilla.orgAccept-Language: fr&lt;!--empty line--&gt; 注意观察最后的 “empty line”，它将数据数块从头部区块分离开了。由于 HTTP 头部没有提供 Content-Length ，因此数据区块显示为空，标记了请求头部的末尾，允许服务器在接收到这个空行时处理该请求。 例如，发送一个表单的结果： 123456POST /contact_form.php HTTP/1.1Host: developer.mozilla.orgContent-Length: 64Content-Type: application/x-www-form-urlencodedname=Joe%20User&amp;request=Send%20me%20one%20of%20your%20catalogue 请求方法HTTP 定义了一组 请求方法 ，指示要对资源执行的操作。尽管它们也能是名词，这些请求方法有时被称作 HTTP 动词。最常见的请求是 GET 和 POST ： GET 方法请求一个代表指定资源的数据。使用 GET 方法的请求应该只检索数据。 POST 方法向服务器发送数据，所以它能改变服务器状态。这在 HTML 表单 中经常用到。 服务器响应的结构用户代理连接并发送数据后，服务器会处理请求和数据，最终返回一个响应。与 客户端请求 类似，服务器响应也是由一些以 CRLF 分隔的文本指令组成，可划分为三个区块： 第一行，状态行，包含了使用的 HTTP 版本，跟着是一个状态请求（及其人类可读的简要含义）。 接下来的几行代表了特定的 HTTP 头部，向客户端提供了关于返回数据的信息（例如，类型，数据大小，使用的压缩算法，关于缓存的提示）。与 客户端请求的 HTTP 头部区块一样，这些响应 HTTP 头部也是以空行结尾组成一个区块。 最后一个区块是数据块，包含了可选的数据。 示例响应成功的应用响应： 12345678910HTTP/1.1 200 OKDate: Sat, 09 Oct 2010 14:28:02 GMTServer: ApacheLast-Modified: Tue, 01 Dec 2009 20:18:22 GMTETag: "51142bc1-7449-479b075b2891b"Accept-Ranges: bytesContent-Length: 29769Content-Type: text/html&lt;!DOCTYPE html... (here comes the 29769 bytes of the requested web page) 请求的资源已被永久转移的通知： 12345678910111213141516171819202122HTTP/1.1 301 Moved PermanentlyServer: Apache/2.2.3 (Red Hat)Content-Type: text/html; charset=iso-8859-1Date: Sat, 09 Oct 2010 14:30:24 GMTLocation: https://developer.mozilla.org/ (this is the new link to the resource; it is expected that the user-agent will fetch it)Keep-Alive: timeout=15, max=98Accept-Ranges: bytesVia: Moz-Cache-zlb05Connection: Keep-AliveX-Cache-Info: cachingX-Cache-Info: cachingContent-Length: 325 (the content contains a default page to display if the user-agent is not able to follow the link)&lt;!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Moved Permanently&lt;/h1&gt;&lt;p&gt;The document has moved &lt;a href="https://developer.mozilla.org/"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;hr&gt;&lt;address&gt;Apache/2.2.3 (Red Hat) Server at developer.mozilla.org Port 80&lt;/address&gt;&lt;/body&gt;&lt;/html&gt; 请求的资源不存在的通知： 12345678910HTTP/1.1 404 Not FoundDate: Sat, 09 Oct 2010 14:33:02 GMTServer: ApacheLast-Modified: Tue, 01 May 2007 14:24:39 GMTETag: "499fd34e-29ec-42f695ca96761;48fe7523cfcc1"Accept-Ranges: bytesContent-Length: 10732Content-Type: text/html&lt;!DOCTYPE html... (contains a site-customized page helping the user to find the missing resource) 响应状态码HTTP 响应状态码 指示了一个 HTTP 请求是否成功执行。响应被分成了5类：通知类响应，成功响应，重定向，客户端错误，服务端错误。 200: OK。请求成功。 301: 永久转移。这个返回码意味着请求的资源的 URI 发生了改变。 404: 未找到。服务器没找到请求的资源。 curl 应用curl 是一个用于在客户端和服务器之间发送数据的工具，支持很多种协议（DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET and TFTP）。该工具提供的功能类似浏览器，可以作为用户代理向服务器发送请求，但是被设计用于无用户交互环境下使用。 curl 发起一个 GET 请求 1curl -s -v -H "Name: kinboy" -- "http://example.org" 参数选项的含义可以使用命令 man curl 查询，或者将命令直接粘贴到 https://explainshell.com/# 页面的搜索栏就可以清晰的看到每个选项的含义。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475* Rebuilt URL to: http://example.org/* Trying 93.184.216.34...* TCP_NODELAY set* Connected to example.org (93.184.216.34) port 80 (#0)&gt; GET / HTTP/1.1&gt; Host: example.org&gt; User-Agent: curl/7.58.0&gt; Accept: */*&gt; Name: kinboy&gt;* HTTP 1.0, assume close after body&lt; HTTP/1.0 200 OK&lt; Cache-Control: max-age=604800&lt; Content-Type: text/html; charset=UTF-8&lt; Date: Tue, 23 Oct 2018 17:18:21 GMT&lt; Etag: "1541025663+ident"&lt; Expires: Tue, 30 Oct 2018 17:18:21 GMT&lt; Last-Modified: Fri, 09 Aug 2013 23:54:35 GMT&lt; Server: ECS (sjc/4FC1)&lt; Vary: Accept-Encoding&lt; X-Cache: HIT&lt; Content-Lengti: 1270&lt; Connection: close&lt;&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Example Domain&lt;/title&gt; &lt;meta charset="utf-8" /&gt; &lt;meta http-equiv="Content-type" content="text/html; charset=utf-8" /&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1" /&gt; &lt;style type="text/css"&gt; body &#123; background-color: #f0f0f2; margin: 0; padding: 0; font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif; &#125; div &#123; width: 600px; margin: 5em auto; padding: 50px; background-color: #fff; border-radius: 1em; &#125; a:link, a:visited &#123; color: #38488f; text-decoration: none; &#125; @media (max-width: 700px) &#123; body &#123; background-color: #fff; &#125; div &#123; width: auto; margin: 0 auto; border-radius: 0; padding: 1em; &#125; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &lt;h1&gt;Example Domain&lt;/h1&gt; &lt;p&gt;This domain is established to be used for illustrative examples in documents. You may use this domain in examples without prior coordination or asking for permission.&lt;/p&gt; &lt;p&gt;&lt;a href="http://www.iana.org/domains/example"&gt;More information...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;* Closing connection 0 curl 发起一个 POST 请求 1curl -X POST -d "some data transfer to server" -s -v -H "name: kinboy" -- "http://example.org" 响应如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576* Rebuilt URL to: http://example.org/* Trying 93.184.216.34...* TCP_NODELAY set* Trying 2606:2800:220:1:248:1893:25c8:1946...* TCP_NODELAY set* connect to 2606:2800:220:1:248:1893:25c8:1946 port 80 failed: Connection refused* Connected to example.org (93.184.216.34) port 80 (#0)&gt; POST / HTTP/1.1&gt; Host: example.org&gt; User-Agent: curl/7.58.0&gt; Accept: */*&gt; name: kinboy&gt; Content-Length: 28&gt; Content-Type: application/x-www-form-urlencoded&gt;* upload completely sent off: 28 out of 28 bytes&lt; HTTP/1.1 200 OK&lt; Accept-Ranges: bytes&lt; Cache-Control: max-age=604800&lt; Content-Type: text/html; charset=UTF-8&lt; Date: Tue, 23 Oct 2018 17:23:42 GMT&lt; Etag: "1541025663"&lt; Expires: Tue, 30 Oct 2018 17:23:42 GMT&lt; Last-Modified: Fri, 09 Aug 2013 23:54:35 GMT&lt; Server: EOS (vny006/044F)&lt; Content-Length: 1270&lt;&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Example Domain&lt;/title&gt; &lt;meta charset="utf-8" /&gt; &lt;meta http-equiv="Content-type" content="text/html; charset=utf-8" /&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1" /&gt; &lt;style type="text/css"&gt; body &#123; background-color: #f0f0f2; margin: 0; padding: 0; font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif; &#125; div &#123; width: 600px; margin: 5em auto; padding: 50px; background-color: #fff; border-radius: 1em; &#125; a:link, a:visited &#123; color: #38488f; text-decoration: none; &#125; @media (max-width: 700px) &#123; body &#123; background-color: #fff; &#125; div &#123; width: auto; margin: 0 auto; border-radius: 0; padding: 1em; &#125; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &lt;h1&gt;Example Domain&lt;/h1&gt; &lt;p&gt;This domain is established to be used for illustrative examples in documents. You may use this domain in examples without prior coordination or asking for permission.&lt;/p&gt; &lt;p&gt;&lt;a href="http://www.iana.org/domains/example"&gt;More information...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/body&gt;]]></content>
      <categories>
        <category>FE</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP Request]]></title>
    <url>%2F2018%2F10%2F23%2FHTTP-Request%2F</url>
    <content type="text"><![CDATA[翻译原文：Request RequestA request message from a client to a server includes, within the first line of that message, the method to be applied to the resource, the identifier of the resource, and the protocol version in use. 一个从客户端发送到服务器的请求消息的行首（请求的第一行）中包括了，操作资源的method方法（GET/POST/PUT等），资源标识符（即URI），以及使用的协议版本（HTTP/1.1,HTTP/1.2等）。 完整的请求消息结构如下，包含了4个部分：行首，请求头，换行，消息体 123456Request = Request-Line ; 行首（1） *(( general-header ; 通用头部（2） | request-header ; 请求头部（2） | entity-header ) CRLF) ; 实体头部（2） CRLF ; 请求头与消息体之间有换行（3） [ message-body ] ; 消息体（4） 5.1 Request-LineThe Request-Line begins with a method token, followed by the Request-URI and the protocol version, and ending with CRLF. The elements are separated by SP characters. No CR or LF is allowed except in the final CRLF sequence. 请求的首行以方法名称（Method）开头，接着是请求地址（Request-URI），协议版本，以CRLF结尾。这些元素以空格分隔，末尾只能是CRLF，不可能是CR 或者 LF。 1Request-Line = Method SP Request-URI SP HTTP-Version CRLF 5.1.1 MethodThe Method token indicates the method to be performed on the resource identified by the Request-URI. The method is case-sensitive. 方法名称（Method）指定了当前请求对请求地址（Request-URI）所指向的服务器资源将要执行的操作方法。 12345678910Method = &quot;OPTIONS&quot; ; Section 9.2 | &quot;GET&quot; ; Section 9.3 | &quot;HEAD&quot; ; Section 9.4 | &quot;POST&quot; ; Section 9.5 | &quot;PUT&quot; ; Section 9.6 | &quot;DELETE&quot; ; Section 9.7 | &quot;TRACE&quot; ; Section 9.8 | &quot;CONNECT&quot; ; Section 9.9 | extension-methodextension-method = token The list of methods allowed by a resource can be specified in an Allow header field (section 14.7). The return code of the response always notifies the client whether a method is currently allowed on a resource, since the set of allowed methods can change dynamically. An origin server SHOULD return the status code 405 (Method Not Allowed) if the method is known by the origin server but not allowed for the requested resource, and 501 (Not Implemented) if the method is unrecognized or not implemented by the origin server. The methods GET and HEAD MUST be supported by all general-purpose servers. All other methods are OPTIONAL; however, if the above methods are implemented, they MUST be implemented with the same semantics as those specified in section 9. 可以在 Allow 头部字段中指定资源允许的方法列表。因为允许操作的方法集合可以动态修改，所以响应的返回码始终会通知客户端是否允许在资源上使用当前方法。如果服务器理解当前方法但是不允许在请求的资源上执行则源服务器应该返回状态码 405 （方法不被允许）。如果方法未源服务器识别或者不支持则返回 501 （不支持）。所有的服务器都 必须 支持 GET 和 POST 方法。所有其他方法都是可选的；但是，如果服务器要实现上面的方法，则必须用 section 9 中指定的语义相同的语义实现它们。 5.1.2 Request-URIThe Request-URI is a Uniform Resource Identifier (section 3.2) and identifies the resource upon which to apply the request. Request-URI 本质上就是一个 URI（Uniform Resource Identifier，section 3.2），用来标识请求所指向的资源。 1Request-URI = &quot;*&quot; | absoluteURI | abs_path | authority The four options for Request-URI are dependent on the nature of the request. The asterisk “*” means that the request does not apply to a particular resource, but to the server itself, and is only allowed when the method used does not necessarily apply to a resource. One example would be Request-URI 的四个选项取决于请求的性质。星号 ”*“ 表示请求不适用于特定资源，而是适用于服务器本身，并且仅在使用的方法不一定适用于资源的时候才允许。下面是一个例子： 1OPTIONS * HTTP/1.1 The absoluteURI form is REQUIRED when the request is being made to a proxy. The proxy is requested to forward the request or service it from a valid cache, and return the response. Note that the proxy MAY forward the request on to another proxy or directly to the server specified by the absoluteURI. In order to avoid request loops, a proxy MUST be able to recognize all of its server names, including any aliases, local variations, and the numeric IP address. An example Request-Line would be: 在向代理发出请求的时候，必须使用absoluteURI（绝对URI） 。代理会转发请求或者提供有效的缓存，然后返回响应。要知道代理可能转发请求给另一个代理或者直接转发给服务器，由 absoluteURI 指定。为了避免请求循环，代理 必须 能够识别所有的服务器名称，包括任何别名，本地变体，以及 IP 地址。一个 Request-URI 的示例如下： 1GET http://www.w3.org/pub/WWW/TheProject.html HTTP/1.1 To allow for transition to absoluteURIs in all requests in future versions of HTTP, all HTTP/1.1 servers MUST accept the absoluteURI form in requests, even though HTTP/1.1 clients will only generate them in requests to proxies. 为了在未来的版本的 HTTP 中允许将所有请求转换为 absoluteURI ，所有 HTTP/1.1 服务器必须在请求中接受 absoluteURI ，尽管 HTTP/1.1 客户端只能在向代理发出请求时生成这些 absoluteURI。 The authority form is only used by the CONNECT method (section 9.9). 权限（authority）仅由 CONNECT 方法使用 (section 9.9)。 The most common form of Request-URI is that used to identify a resource on an origin server or gateway. In this case the absolute path of the URI MUST be transmitted (see section 3.2.1, abs_path) as the Request-URI, and the network location of the URI (authority) MUST be transmitted in a Host header field. For example, a client wishing to retrieve the resource above directly from the origin server would create a TCP connection to port 80 of the host “www.w3.org&quot; and send the lines: 最常用的 Request-URI 格式是用于标识源服务器或者网关上的一个资源。这种情况下，URI的绝对路径必须作为 Request-URI 传送 (参见第 3.2.1节, abs_path)，并且 URI（权限）的网络位置必须在 Host 头部字段中传输。例如，一个想要直接从源服务器上检索上述资源的客户端将会创建一个到主机 “www.w3.org” 的端口 80 的 TCP 连接，并发送以下行： 12GET /pub/WWW/TheProject.html HTTP/1.1Host: www.w3.org followed by the remainder of the Request. Note that the absolute path cannot be empty; if none is present in the original URI, it MUST be given as “/“ (the server root). 然后是请求的其余部分。要注意绝对路径不能为空；如果源 URI 中不存在，则必须以 “/”（服务器根目录）给出。 The Request-URI is transmitted in the format specified in section 3.2.1. If the Request-URI is encoded using the “% HEX HEX” encoding [42], the origin server MUST decode the Request-URI in order to properly interpret the request. Servers SHOULD respond to invalid Request-URIs with an appropriate status code. Request-URI 以第 3.2.1 节中声明的格式传输。如果 Request-URI 使用 “% HEX HEX”编码 [42] 进行编码，则源服务器必须解码 Request-URI 以正确解释请求。对于无效 Request-URI 服务器应该返回合适的状态码。 A transparent proxy MUST NOT rewrite the “abs_path” part of the received Request-URI when forwarding it to the next inbound server, except as noted above to replace a null abs_path with “/“. 透明代理在将请求转发到下一个入站服务器时不得重写接受到的 Request-URI 的 “abs_path” 部分，除了上面提到的用 ”/“ 替换 null abs_path。 12345Note: The &quot;no rewrite&quot; rule prevents the proxy from changing themeaning of the request when the origin server is improperly usinga non-reserved URI character for a reserved purpose. Implementorsshould be aware that some pre-HTTP/1.1 proxies have been known torewrite the Request-URI. 5.2 The Resource Identified by a RequestThe exact resource identified by an Internet request is determined by examining both the Request-URI and the Host header field. 通过检查 Request-URI 和 Host 头部字段来确定网络请求指定的确切资源。 An origin server that does not allow resources to differ by the requested host MAY ignore the Host header field value when determining the resource identified by an HTTP/1.1 request. (But see section 19.6.1.1 for other requirements on Host support in HTTP/1.1.) 在确定由 HTTP/1.1 请求标识的资源时，不允许资源因服务器而不同的源服务器可能会忽略 Host 头部字段值。（但有关HTTP / 1.1中主机支持的其他要求，请参阅第 19.6.1.1 节。） An origin server that does differentiate resources based on the host requested (sometimes referred to as virtual hosts or vanity host names) MUST use the following rules for determining the requested resource on an HTTP/1.1 request: 根据请求的主机（有时也叫作 虚拟主机 或者 虚荣主机名）区分资源的源服务器必须用下面的规则来确定 HTTP/1.1 请求上请求的资源： \1. If Request-URI is an absoluteURI, the host is part of the Request-URI. Any Host header field value in the request MUST be ignored. 如果 Request-URI 是一个absoluteURI，主机是 Request-URI 的一部分。必须忽略请求中任何 Host 头部字段的值。 \2. If the Request-URI is not an absoluteURI, and the request includes a Host header field, the host is determined by the Host header field value. 如果 Request-URI 不是 absoluteURI，请求中包含一个 Host 请求头字段，主机有 Host 头部字段的值决定。 \3. If the host as determined by rule 1 or 2 is not a valid host on the server, the response MUST be a 400 (Bad Request) error message. 如果根据规则 1 或者 2 确定的主机不是服务器上的有效主机，响应必须是 400 （Bad Request）错误消息。 Recipients of an HTTP/1.0 request that lacks a Host header field MAY attempt to use heuristics (e.g., examination of the URI path for something unique to a particular host) in order to determine what exact resource is being requested. 缺少 Host 头字段的 HTTP/1.0 请求的接收者可以尝试启发算法（例如，检查 URI 路径以寻找特定主机特有的东西），以确定正在请求的资源。 5.3 Request Header FieldsThe request-header fields allow the client to pass additional information about the request, and about the client itself, to the server. These fields act as request modifiers, with semantics equivalent to the parameters on a programming language method invocation. 请求头字段允许客户端将有关请求以及客户端本身的其他信息传递给服务器。这些字段充当请求修饰符，其语义等同于编程语言调用方法的参数。 12345678910111213141516171819request-header = Accept ; Section 14.1 | Accept-Charset ; Section 14.2 | Accept-Encoding ; Section 14.3 | Accept-Language ; Section 14.4 | Authorization ; Section 14.8 | Expect ; Section 14.20 | From ; Section 14.22 | Host ; Section 14.23 | If-Match ; Section 14.24 | If-Modified-Since ; Section 14.25 | If-None-Match ; Section 14.26 | If-Range ; Section 14.27 | If-Unmodified-Since ; Section 14.28 | Max-Forwards ; Section 14.31 | Proxy-Authorization ; Section 14.34 | Range ; Section 14.35 | Referer ; Section 14.36 | TE ; Section 14.39 | User-Agent ; Section 14.43 Request-header field names can be extended reliably only in combination with a change in the protocol version. However, new or experimental header fields MAY be given the semantics of request- header fields if all parties in the communication recognize them to be request-header fields. Unrecognized header fields are treated as entity-header fields. 请求头字段的名称只能与协议版本的更改一起可靠地扩展。但是如果通信中的各方都能识别新增或者实验性的请求头字段，则可以为它们赋予请求头字段的语义。无法识别的头部字段被视为实体请求头字段。]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个 JavaScript 可选参数的安全隐患]]></title>
    <url>%2F2018%2F10%2F19%2F%E4%B8%80%E4%B8%AA-JavaScript-%E5%8F%AF%E9%80%89%E5%8F%82%E6%95%B0%E7%9A%84%E5%AE%89%E5%85%A8%E9%9A%90%E6%82%A3%2F</url>
    <content type="text"><![CDATA[​ 这显然是个棘手的问题，可能大多数程序员会认为这个表达式会返回一个类似 [1，2，3] 的数组，如果你在浏览器中输入上面的表达式回车后，就会看到实际返回的是 [1, NaN, NaN] 。 ​ 解释如下，parseInt 作为 JavaScript 的内置函数，试图将一个字符串转换为数值，并返回该数值。所以，一个这样的调用： 1const n = parseInt('123'); ​ 应该将数值 123 赋给变量 n。 ​ 你应该知道，当遇到字符串无法转换为数值的时候，parseInt 方法会返回 NaN ，NaN 是 Not a Number 的缩写，通常意味着出现了某种数值计算错误。所以，一个这样的表达式： 1const x = parseInt('xyz'); ​ 会将 NaN 赋值给变量 x。 ​ map 是 ECMAScript5 中的内置函数，许多浏览器中都已支持。map 以一个 function 对象作为参数，遍历整个数组，并对每一个数组元素调用该参数 function，将元素作为参数传入该 function。然后将这些 function 调用的返回值组成一个新的数组返回。参考下面的例子 1[1，2，3].map(function(value) &#123;return value + 1&#125;); ​ 这个表达式执行后会返回一个值为 [2，3，4] 的数组。最常见的是传递一个诸如此类的函数表达式或者 lambda 表达式给 map ，但是传递一个已有的函数对象 parseInt 也是有效的。 ​ 了解了 parseInt 和 map 的基本概念后，文章开头的表达式就很好理解了，它试图将一个数值字符串的数组转换为一个包含了每个字符串对应数值的数组。为什么不成功呢？为了找到答案，我们就要继续深入了解一下 parseInt 和 map 的定义了。 ​ 看看 parseInt 的定义 ，你会注意到它接收两个参数。第一个参数是要被转换的字符串，第二个参数是要被转换成的数值的基数，所以 parseInt(&#39;ffff&#39;,16)会返回 65535 ，然而 parseInt(&#39;ffff&#39;,8) 就会返回 NaN。因为 ffff 不能转换为一个八进制数。如果第二个参数缺失或者为 0 ，那么默认值将是 10 ，所以 parseInt(&#39;12&#39;,10) ，parseInt(&#39;12&#39;,0) 以及 parseInt(&#39;12&#39;) 都会返回数值 12。 ​ 现在仔细看看 map 方法的声明 。它指出 callbackfn 是第一个作为参数传入 map 的 function ，定义中说 “the callbackfn is called with three arguments: the value of the element, the index of the element, and the object that is being traversed.” （使用三个参数调用 callbackfn 函数：元素值，元素索引，和被遍历的对象）。仔细阅读这句话。它的意思是，并不是像下面这样调用了三次 parseInt： 123parseInt("1")parseInt("2")parseInt("3") ​ 我们实际上是有三次这样的调用： 123parseInt('1', 0, theArray);parseInt('2', 1, theArray);parseInt('3', 2, theArray); ​ 上面的 theArray 就是原始数组 [&#39;1&#39;,&#39;2&#39;,&#39;3&#39;] 。 ​ JavaScript 方法通常会忽略多余的参数，而 parseInt 函数只需要两个参数，所以我们不必担心上面这些调用中的 theArray 参数。但是第二个参数呢？第一个调用的第二个参数是 0 ，我们已知这里默认基数是 10，所以 parseInt(&#39;1&#39;,0) 会返回 1。第二次调用传入 1 作为基数参数。定义中非常清晰的说明了这种情况会发生什么。如果基数非零且小于2，则方法直接返回 NaN 甚至不用读取字符串。 ​ 第三次调用传入了 2 作为基数。这意味着带转换的字符串应该是仅由数字字符 &quot;0&quot; 和 &quot;1&quot; 组成的二进制数。 parseInt 的定义中（第11步）说，它只转换字符串中第一个不是传入基数的有效数字的字符左侧的子字符串。第三次调用中的第一个字符串是 &quot;3&quot; ，不是以数字 2 为基数的有效数字，所以要转换的子字符串是一个空字符串。步骤12说到，如果子字符串是空字符串，方法将返回 NaN 。所以三次调用的返回结果是 1，NaN 和 NaN。 ​ 使用原始表达式的程序员可能会在两个方面犯错。第一个可能的地方是他们可能忘记了或者从来不知道 parseInt 接收可选的第二个参数。第二个可能的地方是他们可能忘记或者从不知道 map 调用 callbackfn 有三个参数。最可能的是这两种情况都占了。 parseInt 最常见的用法只取第一个参数，而绝大多数情况下传给 map 的方法也只使用第一个参数，所以这两种情况下都很容易忘记可能存在可选参数。 ​ 有一个直接的方法是重写原始的表达式来避免错误： 1['1','2','3'].map(function(value) &#123;return parseInt(value)&#125;) ​ 而不是直接使用： 1['1','2','3'].map(parseInt) ​ 这样明确的定义了 callbackfn 只取一个参数，并且很清晰地只用一个参数调用 parseInt 函数。但是这样也使得代码更加冗长，少了些优雅。 ​ 我继续在推特上搜索了这个问题，有一些扩展 JavaScript 来避免此问题或者至少让代码更加简介的方法。 ​ Angus Croll (@angusTweets) 建议用 Number 构造函数而不是 parseInt 作为 callbackfn 能解决此问题。用这种方式调用 Number 也能将字符串转换为 decimal 数值，而且它只需要一个参数。 ​ @__DavidFlanagan 建议新增一个 mapValues 方法来解决此问题，这个方法只传一个参数给 callbackfn 。然而 ECMAScript 5 有 7 种不同的 Array 方法，其操作方式与 map 类似，所以我们就真的不得不新增 7 个这种方法。 ​ 我认为新增下面这样的方法也是一种解决的办法： 123456Function.prototype.only = function(numberOfArgs)&#123; var self = this; //原始方法 return function()&#123; return self.apply(this,[].slice.call(arguments,0,numerOfArgs)) &#125;&#125; ​ 这是一个高阶函数，以一个函数作为参数，返回一个新的函数，返回的新函数调用原始函数，并且只使用指定数量的参数。使用 only，原始表达式可以写成这样： 1['1','2','3'].map(parseInt.only(1)); ​ 这样只是略显冗长，并且保留了一定程度的优雅。 ​ 这个问题引发了关于 JavaScript curry function （柯里化函数，真正意义上的 partial function application ——部分函数应用，或偏函数应用，或散函数应用）的讨论。部分函数应用 取一个需要特定数量参数的函数，产生一个新的需要更少参数的函数。我的 only 函数就是一个实现了 部分函数应用 的函数示例。ES5中新增的 Function.prototype.bind 方法也是。JavaScript 需要这样的方法吗？例如，一个 固定最右侧参数而不是最左侧参数的bindRight 方法。也许可以，但是参数数量允许可变时，最右究竟有什么意义呢？可能一个取参数位置的 bindRight 方法可能更适合 JavaScript。 ​ 然而，所有这些关于扩展的讨论已经偏离了原始问题的关键问题。为了使用他们任意一个，你必须首先知道 map 和 parseInt 的可选参数不匹配。如果你知道了这个问题，那么有很多中方式来解决问题。如果你还不知道，那么上面推荐的任何一种解决方案都没有帮助。这似乎主要是一个 API 设计问题，并提出了一些关于在 JavaScript 中适当使用可选参数的基本问题。 ​ 一个用例是从调用这的角度来看可选参数，另一个用例是从被调用者的角度来看。在 parseInt 的情况下，它的设计假设调用者知道它正在调用 parseInt 并且已经适当的选择了实际的参数值。从调用者的角度来看，第二个参数是可选的。如果它想要使用默认的基数，就可以换略第二个参数。但是 parseInt 的实际规范中详细定义了使用一个或两个参数以及各种参数值调用时，被调用者将执行的操作。 ​ 另一个用例更多来自不同类型的函数调用者。一个调用者，它不知道它实际调用了什么函数，并且总是传递一个固定大小的参数。map 的规范中明确定义了它将总是传递三个参数给它提供的任何 callbackfn 。因为调用者并不真正知道被调用者的身份，以及被调用者需要什么信息，map 将所有可用的信息作为参数传递。假设实际的被调用者将忽略任何它不需要的参数。在这个用例中，从被调用者的角度来看，第二个和第三个参数是可选的。 ​ 这两个都是有效的可选参数用例，但是当我们将两者结合起来的时候，我们就得到一个软件 “impedance mismatch”（阻抗失配）。被调用者的可选参数很少与调用者的可选参数匹配。bind 或者 only 这样的高阶函数可以被用来解决这样的失配，但是前提是程序员意识到了失配的存在。 JavaScript API 的设计者需要记住这一点，每个 JavaScript 程序员都要格外小心，了解究竟什么值被传递给了回调函数。]]></content>
      <categories>
        <category>FE</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>FE</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGINX: Proxy folders to different root]]></title>
    <url>%2F2018%2F10%2F17%2FNGINX-Proxy-folders-to-different-root%2F</url>
    <content type="text"><![CDATA[原文: NGINX: Proxy folders to different root 这篇教程教你在 Nginx 中将站点的不同目录设置成不同的反向代理站点的根目录。 默认情况下，假设有一个设置了 proxy_pass 的 location 区块，这个 location 区块匹配的是一个目录，例如 /nagios ，访问这个目录将跳转到代理服务器： 12345678location /nagios/ &#123; proxy_pass http://10.0.21.8:80/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_redirect off;&#125; 当在浏览器中访问的时候，上面的配置会将你的请求发送到 http://10.0.21.8/nagios/ ，因为这就是 Nginx location 的默认行为。然而如果你想要浏览器转发请求到 http://10.0.21.8/ ，你要么 rewrite URL 要么就使用 / location。 下面是正确的重写规则的示例： 123456789location /nagios/ &#123; rewrite ^/nagios(/.*)$ $1 break; proxy_pass http://10.0.21.8:80/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_redirect off;&#125; 可以这一行配置： 1rewrite ^/collectd(/.*)$ $1 break; 它解决了问题, 将你的请求发送到 http://10.0.21.8/ 而不是 http://10.0.21.8/nagios.]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>NGINX</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx-Windows版开启支持TLSv1.2]]></title>
    <url>%2F2018%2F10%2F17%2FNginx-Windows%E7%89%88%E5%BC%80%E5%90%AF%E6%94%AF%E6%8C%81TLSv1-2%2F</url>
    <content type="text"><![CDATA[微信小程序要求使用 https 发送请求，并且 TLS（传输层安全协议）的版本至少为 1.2，在配置好 https之后，如果 TLS 的版本较低，就涉及到升级问题 从申请免费证书到配置 Nginx HTTPS 配置，有一篇比较完整的教程：微信小程序Server端环境配置 Linux 下配置的教程有很多，这里记录一下 Windows 中的配置过程，公司的 Nginx 跑在 Windows Server 上。 操作系统：Windows Server 2008 R2 Nginx版本：ngixn/1.12.2 for Windows 证书：腾讯云管理后台用 TrustAsia 签发的免费证书，有效期一年 当前 Nginx 配置中，Https 有关的配置： 12345678ssl_certificate 1_gis.wohitech.com_bundle.crt;ssl_certificate_key 2_gis.wohitech.com.key;ssl on;ssl_protocols SSLv2 SSLv3 TLSv1;ssl_ciphers HIGH:!aNULL:!MD5;ssl_prefer_server_ciphers on; 腾讯云提供了工具可以监测域名是否支持 HTTPS TLS1.2，当前检测可以看到不通过。 在火狐浏览器中打开网址，点击地址栏左侧的锁图标，可以查看当前域名的 HTTPS 加密协议版本，当前为 TLS 1.0 找到了 Nginx 官网文档提供的 HTTPS 配置文档，Configuring HTTPSS servers 对比示例，我发现在 ssl_protocols 这一行的配置中，官方示例包含了 TLSv1.2 123456789server &#123; listen 443 ssl; server_name www.example.com; ssl_certificate www.example.com.crt; ssl_certificate_key www.example.com.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ...&#125; 我用官方示例的配置替换了生产环境 Nginx 的配置，成功！ 注意，在服务端修改 Nginx 配置后，浏览器再次访问前需要先清一下浏览器缓存，否则火狐中看到的是缓存的之前的证书信息。 FireFox 中查看域名的 TLS 版本 腾讯云检测结果]]></content>
      <categories>
        <category>FE</category>
        <category>NGINX</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迁移Jenkins作业到新的Jenkins服务器]]></title>
    <url>%2F2018%2F10%2F15%2F%E8%BF%81%E7%A7%BBJenkins%E4%BB%BB%E5%8A%A1%E5%88%B0%E6%96%B0%E7%9A%84Jenkins%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[最近在公司搭建 Jenkins 持续集成环境，要将测试环境中配置的 Jenkins 作业导入到正式环境中，上网找了下资料，大概有三种可行的方案: 拷贝作业文件夹 用Jenkins插件 用Jenkins cli 命令 有更好的办法欢迎交流。 选项1：拷贝 jobs 目录One option (and seems to be the recommended one) is to just copy the jobs directory from the old server to the new one. 一个方案是直接拷贝旧的 Jenkins 服务安装目录下的 jobs 文件夹到新服务同级目录下，这也是较为推荐的方案。 引自这篇文件 Moving/copying/renaming jobs: You can: 你可以 Move a job from one installation of Jenkins to another by simply copying the corresponding job directory. 通过简单的拷贝对应的 job 目录将一个作业从一个 Jenkins 安装实例移动到另一个中。 Make a copy of an existing job by making a clone of a job directory by a different name. 可以通过克隆和重命名一个 job 文件夹来制作一个已有作业的副本。 Rename an existing job by renaming a directory. Note that the if you change a job name you will need to change any other job that tries to call the renamed job. 通过重命名文件夹来重命名一个已有的作业。注意如果你改变了一个作业的名称，你需要改变所有依赖这个作业的其他作业。 Those operations can be done even when Jenkins is running. For changes like these to take effect, you have to click “reload config” to force Jenkins to reload configuration from the disk. 这些选项可以在 Jenkins 正在运行的情况下操作。为了让改变生效，你必须点击 “重新加载配置”来强制 Jenkins 从硬盘重新加载配置。 选项2：尝试下面这两个插件有一些 Jenkins 插件提供了作业导出的选项，下面推荐了两个： Job Exporter Plugin 这个插件并没有真正导出作业，而是改变了作业运行时的环境变量。 Job Importer Plugin 选项3：使用 Jenkins CLI我使用了这种方案，它比较适合作业数量较少的情况下使用。如果你有非常多的 Jenkins 作业，你可以考虑下第一种方案。 第一步，下载 Jenkins CLI 的 jar 包文件。 你可以在你的 Jenkins 安装实例的 Jenkins CLI 页面上下载。 接着我们可以用下面的命令（指向旧服务器）来列出作业。 1java -jar jenkins-cli.jar -s http://&lt;YourBuildServer&gt;:&lt;YourBuildServerPort&gt;/ list-jobs 使用上面列表中的一个作业，将作业的 xml 复制到剪贴板。（下面以Mac 为例，剪贴板用 pbcopy 和 pbpaste ） 1java -jar jenkins-cli.jar -s http://&lt;YourBuildServer&gt;:&lt;YourBuildServerPort&gt;/ get-job "NAME_OF_JOB" | pbcopy 这里使用 cli 的 get-job “NAME_OF_JOB” 命令将这个 作业的 xml 打印到 stdout 标准输出，接着用管道符 输出到 Mac 的 pbcopy 以将配置加载到剪贴板。你当然也可以管道输出到一个文件中，像这样 ... &gt; config.xml。 如果用上面的命令将作业的 XML 放到了剪贴板中，你可以用下面的命令来将作业添加到新服务器上。 1pbpaste | java -jar jenkins-cli.jar -s http://&lt;YourBuildServer&gt;:&lt;YourBuildServerPort&gt; create-job &quot;NAME_OF_JOB&quot; This uses pbpaste to take what is in the clipboard, send it to stdin and pipe it to the Jenkins cli’s create-job &quot;NAME_OF_JOB&quot;command. 这一步使用了 pbpaste 来获取剪贴板中的内容，发送到 stdin 标准输入，然后管道传递给 Jenkins cli create-job &quot;NAME_OF_JOB&quot; 命令。 希望能帮到你]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 CORS （跨域资源共享）]]></title>
    <url>%2F2018%2F10%2F14%2Fusing-cors%2F</url>
    <content type="text"><![CDATA[原文：Using CORS Introduction | 介绍 APIs are the threads that let you stitch together a rich web experience. But this experience has a hard time translating to the browser, where the options for cross-domain requests are limited to techniques like JSON-P(which has limited use due to security concerns) or setting up a custom proxy (which can be a pain to set up and maintain). API 是让你将丰富的 web 体验拼接在一起的纽带。但是在过去，跨域请求被限制只能在一些技术上使用的时候，例如 JSON-P(出于安全考虑，使用上有诸多限制)或者设置自定义代理(难于设置和维护)，这些体验是很难在浏览器中实现的。 Cross-Origin Resource Sharing (CORS) is a W3C spec that allows cross-domain communication from the browser. By building on top of the XMLHttpRequest object, CORS allows developers to work with the same idioms as same-domain requests. 跨源资源共享 (CORS)是一个 W3C 规范，允许浏览器跨域通信。建立在 XMLHttpRequest 对象之上，CORS 允许开发者使用与同域请求相同的语法。 The use-case for CORS is simple. Imagine the site alice.com has some data that the site bob.com wants to access. This type of request traditionally wouldn’t be allowed under the browser’s same origin policy. However, by supporting CORS requests, alice.com can add a few special response headers that allows bob.com to access the data. CORS 的用例非常简单。想象一下网站 alice.com 上有一些网站 bob.com 想要获取的数据。这种类型的请求在浏览器的同源策略下通常不会被允许的。然而，通过支持 CORS 请求，alice.com 可以增加一些特殊的响应头来允许 bob.com 获取数据。 As you can see from this example, CORS support requires coordination between both the server and client. Luckily, if you are a client-side developer you are shielded from most of these details. The rest of this article shows how clients can make cross-origin requests, and how servers can configure themselves to support CORS. 正如你在上面的例子中看到的，支持 CORS 需要服务端与客户端之间的协作。幸运的是，如果你是以为客户端开发者，你已经被屏蔽了大部分细节。本文其他部分将会阐述如何让客户端发起跨域请求，以及如何配置服务器来支持 CORS。 Making a CORS Request | 发起一个 CORS 请求 This section shows how to make a cross-domain request in JavaScript. 本节展示如何用 JavaScript 发起跨域请求 Creating the XMLHttpRequest object | 创建一个XMLHttpRequest 对象 CORS is supported in the following browsers: 下面这些浏览器支持了 CORS： Chrome 3+ Firefox 3.5+ Opera 12+ Safari 4+ Internet Explorer 8+ (see the complete list of supported browsers at http://caniuse.com/#search=cors ) (查看浏览器支持的完整列表: http://caniuse.com/#search=cors ) Chrome, Firefox, Opera and Safari all use the XMLHttpRequest2 object. Internet Explorer uses the similar XDomainRequest object, which works in much the same way as its XMLHttpRequest counterpart, but adds additional security precautions. Chrome, Firefox, Opera and Safari 全部使用 XMLHttpRequest2 对象。Internet Explorer 使用的是类似的 XDomainRequest 对象，它与 XMLHttpRequest 对应部分的工作方式大致相当，但是增加了额外的安全防范措施。 To get started, you will first need to create the appropriate request object. Nicholas Zakas wrote a simple helper method to help sort out the browser differences: 首先，你需要创建适当的请求对象。Nicholas Zakas 写了一个简单的 helper 方法来帮助检查理清浏览器间的差异。 12345678910111213141516171819202122232425262728function createCORSRequest(method, url) &#123; var xhr = new XMLHttpRequest(); if ("withCredentials" in xhr) &#123; // Check if the XMLHttpRequest object has a "withCredentials" property. // "withCredentials" only exists on XMLHTTPRequest2 objects. xhr.open(method, url, true); &#125; else if (typeof XDomainRequest != "undefined") &#123; // Otherwise, check if XDomainRequest. // XDomainRequest only exists in IE, and is IE's way of making CORS requests. xhr = new XDomainRequest(); xhr.open(method, url); &#125; else &#123; // Otherwise, CORS is not supported by the browser. xhr = null; &#125; return xhr;&#125;var xhr = createCORSRequest('GET', url);if (!xhr) &#123; throw new Error('CORS not supported');&#125; Event handlers | 事件处理程序 The original XMLHttpRequest object had only one event handler, onreadystatechange, which handled all responses. Although onreadystatechange is still available, XMLHttpRequest2 introduces a bunch of new event handlers. Here is a complete list: 原始的 XMLHttpRequest 对象只有一个事件处理程序，onreadystatechange ，这个处理程序处理了所有的返回。但是 onreadystatechange 仍然可用，XMLHttpRequest2 引入了一堆新的事件处理程序。这里是一个完整列表： Event Handler Description onloadstart* When the request starts. 当请求开始的时候 onprogress While loading and sending data. 当加载和发送数据的时候 onabort* When the request has been aborted. For instance, by invoking the abort() method. 当请求被中止的时候。例如通过调用 abort() 方法。 onerror When the request has failed. 当请求失败的时候 onload When the request has successfully completed. 当请求成功完成的时候。 ontimeout When the author specified timeout has passed before the request could complete. 当请求完成之前达到了作者设定的超时时间的时候。 onloadend* When the request has completed (either in success or failure). 当请求完成（不论成功或者失败）的时候 * starred items are not supported by IE’s XDomainRequest * 星号标记的项目是不被 IE 浏览器的 XDomainRequest 对象支持的。 source: http://www.w3.org/TR/XMLHttpRequest2/#events For most cases, you will at the very least want to handle the onload and onerror events: 多数情况下，你至少要处理 onload 和 onerror 事件： 123456789xhr.onload = function() &#123; var responseText = xhr.responseText; console.log(responseText); // process the response.&#125;;xhr.onerror = function() &#123; console.log('There was an error!');&#125;; Browers don’t do a good job of reporting what went wrong when there is an error. For example, Firefox reports a status of 0 and an empty statusText for all errors. Browsers also report an error message to the console log, but this message cannot be accessed from JavaScript. When handling onerror, you will know that an error occurred, but not much else. 浏览器在出现错误时不能很好地定位错误来源。例如，Firefox 对所有错误都报告一个状态 0 和空的 statusText。浏览器也会在控制台日志中报告错误，但是这种错误信息不能被 JavaScript 获取。当处理 onerror 的时候，你只知道发生了错误，但是除此之外没有更多信息了。 withCredentials Standard CORS requests do not send or set any cookies by default. In order to include cookies as part of the request, you need to set the XMLHttpRequest’s .withCredentials property to true: 标准的 OCRS 请求默认不发送也不设置任何cookie缓存。为了将 cookie 缓存作为请求的一部分，你需要设置 XMLHttpRequest的 .withCredentials 属性为 true： 1xhr.withCredentials = true; In order for this to work, the server must also enable credentials by setting the Access-Control-Allow-Credentials response header to “true”. See the server section for details. 为了使之生效，服务端也必须通过设置 Access-Control-Allow-Credentials 响应头为 ”true” 来允许证书（credentials）。更多细节看这里 server section 。 1Access-Control-Allow-Credentials: true The .withCredentials property will include any cookies from the remote domain in the request, and it will also set any cookies from the remote domain. Note that these cookies still honor same-origin policies, so your JavaScript code can’t access the cookies from document.cookie or the response headers. They can only be controlled by the remote domain. .withCredentials 属性将包含来自请求中远程域的任何 cookie 缓存，并且还将设置来自远程域的任何 cookie 缓存。注意这些缓存仍然遵循同源策略，所以你的 JavaScript 代码访问 document.cookie 中的 cookie 缓存，或者响应头（response headers）。它们只能被远程域名控制。 Making the request | 发起请求 Now that your CORS request is configured, you are ready to make the request. This is done by calling the send() method: CORS 请求配置完成后，你就可以发起请求了。这是通过调用 send() 方法来完成的。 1xhr.send(); If the request has a body, it can be specified as an argument to send(). 如何请求有一个请求体，请求体可以被声明为 send() 方法的一个参数。 And thats it! Assuming the server is properly configured to respond to CORS requests, your onload handler will fire with the response, just like the standard same-domain XHR you are so familiar with. 这就是 CORS 请求了！假定服务器合理的配置了响应 CORS 请求，你的 onload 事件处理程序将会触发响应，就像你熟悉的标准的同域 XHR 一样。 End-to-End Example | 端对端示例 Here is a full working sample of a CORS request. Run the sample and watch the network requests in the browser’s debugger to see the actual request being made. 这里有一个 CORS 请求的完整工作示例。运行示例然后在浏览器的调试器中查看网络请求，来看看实际上产生的请求。 Run Sample 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Create the XHR object.function createCORSRequest(method, url) &#123; var xhr = new XMLHttpRequest(); if ("withCredentials" in xhr) &#123; // XHR for Chrome/Firefox/Opera/Safari. xhr.open(method, url, true); &#125; else if (typeof XDomainRequest != "undefined") &#123; // XDomainRequest for IE. xhr = new XDomainRequest(); xhr.open(method, url); &#125; else &#123; // CORS not supported. xhr = null; &#125; return xhr;&#125;// Helper method to parse the title tag from the response.function getTitle(text) &#123; return text.match('&lt;title&gt;(.*)?&lt;/title&gt;')[1];&#125;// Make the actual CORS request.function makeCorsRequest() &#123; // This is a sample server that supports CORS. var url = 'http://html5rocks-cors.s3-website-us-east-1.amazonaws.com/index.html'; var xhr = createCORSRequest('GET', url); if (!xhr) &#123; alert('CORS not supported'); return; &#125; // Response handlers. xhr.onload = function() &#123; var text = xhr.responseText; var title = getTitle(text); alert('Response from CORS request to ' + url + ': ' + title); &#125;; xhr.onerror = function() &#123; alert('Woops, there was an error making the request.'); &#125;; xhr.send();&#125; Adding CORS support to the server | 在服务器上增加 CORS 支持 Most of the heavy lifting for CORS is handled between the browser and the server. The browser adds some additional headers, and sometimes makes additional requests, during a CORS request on behalf of the client. These additions are hidden from the client (but can be discovered using a packet analyzer such as Wireshark). CORS 的大部分繁重工作都是在浏览器和服务器之间进行的。浏览器在代表客户端的 CORS 请求期间添加了一些额外的请求头，有时候 发起额外的请求。这些添加对客户端是隐藏的（但是可以使用诸如 Wireshark 之类的抓包分析工具来发现）。 CORS flow Browser manufacturers are responsible for the browser-side implementation. This section explains how a server can configure its headers to support CORS. 浏览器制造商负责浏览器端的实现。这一节阐述服务器如何配置请求头来支持 CORS。 Types of CORS requests | CORS 请求的类型 Cross-origin requests come in two flavors: 跨源请求主要有2种： simple requests 简单请求 “not-so-simple requests” (a term I just made up) 非简单的请求 Simple requests are requests that meet the following criteria: 简单请求必须满足以下准则： HTTP Method matches (case-sensitive) one of: HTTP 方法匹配（大小写敏感）下面一种 HEAD GET POST HTTP Headers matches (case-insensitive): HTTP 请求头匹配（大小写敏感）： Accept Accept-Language Content-Language Last-Event-ID Content-Type, but only if the value is one of: application/x-www-form-urlencoded multipart/form-data text/plain Simple requests are characterized as such because they can already be made from a browser without using CORS. For example, a JSON-P request can issue a cross-domain GET request. Or HTML could be used to do a form POST. 简单请求具有这样的特点是因为他们已经可以在不使用 CORS 的情况下浏览器中生成。例如，JSON-P 请求可以发出跨域 GET 请求。或者 HTML 可以用于执行表单 POST。 Any request that does not meet the criteria above is a not-so-simple request, and requires a little extra communication between the browser and the server (called a preflight request), which we’ll get into below. 任何不满足以上准则的请求都是 非简单的 请求，需要在浏览器和服务器之间进行一点点额外的通信（称为 预检请求），我们会在下面介绍。 Handling a simple request | 处理一个简单请求 Lets start by examining a simple request from the client. The table below shows the JavaScript code for a simple GET request on the left, along with the actual HTTP request that the browser emits; CORS specific headers are in bold. 让我们从检查客户端的简单请求开始。下表展示了左侧简单请求的 JavaScript 代码，以及浏览器发出的实际 HTTP 请求；CORS 特定请求头用粗体显示。 JavaScript: 123var url = 'http://api.alice.com/cors';var xhr = createCORSRequest('GET', url);xhr.send(); HTTP Request: 123456GET /cors HTTP/1.1Origin: http://api.bob.comHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... The first thing to note is that a valid CORS request always contains an Origin header. This Origin header is added by the browser, and can not be controlled by the user. The value of this header is the scheme (e.g. http), domain (e.g. bob.com) and port (included only if it is not a default port, e.g. 81) from which the request originates; for example: http://api.alice.com. 第一个要注意的地方是，一个可用的 CORS 请求 始终 包含一个 Origin 请求头。这个 Origin 请求头是浏览器添加的，不能被用户控制。这个请求头的值是请求源自的方案（例如：http），域（例如：bob.com），和端口（仅在它不是默认端口时才需要声明 例如：81）；例如：http://api.alice.com。 The presence of the Origin header does not necessarily mean that the request is a cross-origin request. While all cross-origin requests will contain an Origin header, some same-origin requests might have one as well. For example, Firefox doesn’t include an Origin header on same-origin requests. But Chrome and Safari include an Origin header on same-origin POST/PUT/DELETE requests (same-origin GET requests will not have an Origin header). Here is an example of a same-origin request with an Origin header: Origin请求头的出现并不一定意味着这个请求就是跨源请求。所有的跨源请求都要包含 Origin 请求头，一些同源请求也可能会有一个 Origin 请求头。例如，Firefox 在同源请求下不包含 Origin 请求头。但是 Chrome 和 Safari在同源的 POST/PUT/DELETE（同源的 GET 请求不包含 Origin 请求头）请求中会包含一个 Origin 请求头。这是一个有 Origin 请求头的同源请求。 HTTP Request: 123POST /cors HTTP/1.1Origin: http://api.bob.comHost: api.bob.com The good news is that browsers don’t expect CORS response headers on same-origin requests. The response to a same-origin request is sent to user, regardless of whether it has CORS headers or not. However, if your server code returns an error if the Origin doesn’t match a list of allowed domains, be sure to include the origin the request comes from. 好消息是浏览器不希望同源请求上使用 CORS 响应头。同源请求的响应被发送给用户，不考虑它是否包含 CORS 响应头。但是，如果你的服务器代码在 Origin 与允许的域名列表不匹配时返回错误，请确认包含请求来源。 Here’s a valid server response; the CORS-specific headers are bolded 这里是一个有效的服务器响应；CORS 特定的请求头加黑显示了。 HTTP Response: 1234Access-Control-Allow-Origin: http://api.bob.comAccess-Control-Allow-Credentials: trueAccess-Control-Expose-Headers: FooBarContent-Type: text/html; charset=utf-8 All CORS related headers are prefixed with “Access-Control-“. Here’s some more details about each header. 所有 CORS 有关的请求头都是以 “Access-Control-” 为前缀的。下面有一些关于每个请求头的详细描述。 Access-Control-Allow-Origin (required) - This header must be included in all valid CORS responses; omitting the header will cause the CORS request to fail. The value of the header can either echo the Origin request header (as in the example above), or be a ‘‘ to allow requests from any origin. If you’d like any site to be able to access your data, using ‘‘ is fine. But if you’d like finer control over who can access your data, use an actual value in the header. Access-Control-Allow-Origin （必须的）- 这个请求头必须包含在所有有效的 CORS 响应中；忽略这个请求头会导致 CORS 请求失败。这个请求头的值要么回显 Origin 请求头（如上面的例子所示），要么为 &#39;&#39; (空字符)表示允许来自任何来源的请求。如果你想要任何网站都能够获取你的数据，使用 &#39;&#39; 就可以了。但是如果你希望更好地控制谁可以访问你的数据，就要在请求头设置实际的值。 Access-Control-Allow-Credentials (optional) - By default, cookies are not included in CORS requests. Use this header to indicate that cookies should be included in CORS requests. The only valid value for this header is true (all lowercase). If you don’t need cookies, don’t include this header (rather than setting its value to false). Access-Control-Allow-Credentials (可选) - 默认情况下，cookie 缓存不被包含在 CORS 请求中。用这个请求头来指示 cookie 缓存要被添加在 CORS 请求中。这个请求头唯一的有效值就是 true （允许小写）。如果你不需要 cookie 缓存，就不要包含这个请求头（而不是将请求头的值设置为 false）。 The Access-Control-Allow-Credentials header works in conjunction with the withCredentials property on the XMLHttpRequest 2 object. Both these properties must be set to true in order for the CORS request to succeed. If .withCredentials is true, but there is no Access-Control-Allow-Credentialsheader, the request will fail (and vice versa). Access-Control-Allow-Credentials 请求头在 XMLHtmlRequest2 对象上的 withCredentials 属性 一起使用。这两个属性都要被设置为 ture 才能让 CORS 请求成功执行。如果 .withCredentials 为 true 而没有 Access-Control-Allow-Credentials 请求头，请求将会失败（反之亦然）。 Its recommended that you don’t set this header unless you are sure you want cookies to be included in CORS requests. 除非你确定需要在 CORS 请求中包含 cookie 缓存，否则不建议设置这个请求头。 Access-Control-Expose-Headers (optional) - The XMLHttpRequest 2 object has a getResponseHeader() method that returns the value of a particular response header. During a CORS request, the getResponseHeader() method can only access simple response headers. Simple response headers are defined as follows: Access-Control-Expose-Headers (可选) - XMLHttpRequest2 对象有一个 getResponseHeader() 方法，返回一个特定的响应头的值。在 CORS 请求期间 ，getResponseHeader() 方法只能访问简单的响应头。简单的响应头定义如下： Cache-Control Content-Language Content-Type Expires Last-Modified Pragma If you want clients to be able to access other headers, you have to use the Access-Control-Expose-Headers header. The value of this header is a comma-delimited list of response headers you want to expose to the client. 如果想要客户端访问其他请求头，必须使用 Access-Control-Expose-Headers 请求头。这个请求头的值是你想要向客户端公开的响应头部的逗号分隔列表。 Handling a not-so-simple request | 处理一个 非简单的 请求 So that takes care of a simple GET request, but what if you want to do something more? Maybe you want to support other HTTP verbs like PUT or DELETE, or you want to support JSON using Content-Type: application/json. Then you need to handle what we’re calling a not-so-simple request. 这样就可以处理一个简单请求了，但是如果你想要做更多事情呢？可能你想支持其他诸如 PUT 或者 DELETE 之类的 HTTP 谓词，或者你想用 Content-Type:application/json 来支持 JSON 格式的响应。那么你就需要处理我们所谓的 非简单的 请求了 A not-so-simple request looks like a single request to the client, but it actually consists of two requests under the hood. The browser first issues a preflight request, which is like asking the server for permission to make the actual request. Once permissions have been granted, the browser makes the actual request. The browser handles the details of these two requests transparently. The preflight response can also be cached so that it is not issued on every request. 一个 非简单的 请求在客户端看来就像一个单个请求，但是它实际上包含两个请求。浏览器首先发起一个预检请求，看起来像是向服务器申请发起实际请求的权限。一旦权限被赋予，浏览器就会发起真正的请求了。浏览器处理这两个请求的详细过程是透明的。预检请求的响应也可以被缓存起来，这样就不用在每次请求的时候都发起预检请求了。 Here’s an example of a not-so-simple request: 这里有一个 非简单的 请求的示例： JavaScript: 12345var url = 'http://api.alice.com/cors';var xhr = createCORSRequest('PUT', url);xhr.setRequestHeader( 'X-Custom-Header', 'value');xhr.send(); Preflight Request: 12345678OPTIONS /cors HTTP/1.1Origin: http://api.bob.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: X-Custom-HeaderHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... Like the simple request, the browser adds the Origin header to every request, including the preflight. The preflight request is made as an HTTP OPTIONS request (so be sure your server is able to respond to this method). It also contains a few additional headers: 和简单请求类似，浏览器会向每一个请求添加 Origin 请求头，包括预检请求。这个预检请求是作为 HTTP OPTIONS 请求生成的（因此要确保你的服务器能够响应这种方式）。它也会包含额外一些请求头： Access-Control-Request-Method - The HTTP method of the actual request. This request header is always included, even if the HTTP method is a simple HTTP method as defined earlier (GET, POST, HEAD). Access-Control-Request-Method - 实际请求的 HTTP 方法。即使 HTTP 方法是前面定义过的简单 HTTP 方法（GET,POST,HEAD）,也始终包含这个请求头。 Access-Control-Request-Headers - A comma-delimited list of non-simple headers that are included in the request. Access-Control-Request-Headers - 包含在请求中的一个非简单请求头逗号分隔列表。 The preflight request is a way of asking permissions for the actual request, before making the actual request. The server should inspect the two headers above to verify that both the HTTP method and the requested headers are valid and accepted. 在进行实际请求之前，预检请求是一种询问实际请求权限的方法。 服务器应该检查上面两个请求头以验证 HTTP 方法和请求头有效并接受。 If the HTTP method and headers are valid, the server should respond with the following: 如果 HTTP 方法和请求头有效，服务器应该返回如下响应： Preflight Request: 预检请求： 12345678OPTIONS /cors HTTP/1.1Origin: http://api.bob.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: X-Custom-HeaderHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... Preflight Response: 1234Access-Control-Allow-Origin: http://api.bob.comAccess-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderContent-Type: text/html; charset=utf-8 Access-Control-Allow-Origin (required) - Like the simple response, the preflight response must include this header. Access-Control-Allow-Origin（必须）- 像简单响应，预检响应也必须包含这个响应头部。 Access-Control-Allow-Methods (required) - Comma-delimited list of the supported HTTP methods. Note that although the preflight request only asks permisions for a single HTTP method, this reponse header can include the list of all supported HTTP methods. This is helpful because the preflight response may be cached, so a single preflight response can contain details about multiple request types. Access-Control-Allow-Methods （必须） - 受支持的 HTTP方法的逗号分隔列表。要注意虽然预检请求只会询问单个简单 HTTP 请求的权限，但是这个响应头可以包含所有支持的 HTTP 方法。这很有用，因为可以缓存预检 请求响应，所以一个单个预检响应可以包含多种请求类型的详细信息。 Access-Control-Allow-Headers (required if the request has an Access-Control-Request-Headers header) - Comma-delimited list of the supported request headers. Like the Access-Control-Allow-Methods header above, this can list all the headers supported by the server (not only the headers requested in the preflight request). Access-Control-Allow-Headers （在请求包含一个 Access-Control-Request-Headers 的情况下是必须的） - 受支持的请求头的逗号分隔列表。像上面的 Access-Control-Allow-Methods ，这可以列出所有被服务器支持的请求头（不仅是预检请求中请求的标头）。 Access-Control-Allow-Credentials (optional) - Same as simple request. Access-Control-Allow-Credentials （可选） - 与简单请求相同。 Access-Control-Max-Age (optional) - Making a preflight request on every request becomes expensive, since the browser is making two requests for every client request. The value of this header allows the preflight response to be cached for a specified number of seconds. Access-Control-Max-Age（可选） - 对每个请求都进行预检请求是开销很大的，因为浏览器要为每次客户端请求发起两次请求。这个请求头的值允许预检请求的响应被缓存指定秒数的时间。 Once the preflight request gives permissions, the browser makes the actual request. The actual request looks like the simple request, and the response should be processed in the same way: 一点预检请求提供了权限，浏览器就会发起实际请求。实际请求看上去就像简单请求，请求的响应也是用相同的方式处理： Actual Request: 1234567PUT /cors HTTP/1.1Origin: http://api.bob.comHost: api.alice.comX-Custom-Header: valueAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... Actual Response: 12Access-Control-Allow-Origin: http://api.bob.comContent-Type: text/html; charset=utf-8 If the server wants to deny the CORS request, it can just return a generic response (like HTTP 200), without any CORS header. The server may want to deny the request if the HTTP method or headers requested in the preflight are not valid. Since there are no CORS-specific headers in the response, the browser assumes the request is invalid, and doesn’t make the actual request: 如果服务器想要拒绝 CORS 请求，它只能返回通用响应（如 HTTP 200），而不需要任何 CORS 头。如果 HTTP 方法或者预检请求的请求头无效，服务器可能会拒绝请求。因为返回中没有 CORS 特定的响应头，浏览器会假定请求不可用，就不会发起实际请求了。 Preflight Request: 预检请求 12345678OPTIONS /cors HTTP/1.1Origin: http://api.bob.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: X-Custom-HeaderHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... Preflight Response: 预检响应 12// ERROR - No CORS headers, this is an invalid request!Content-Type: text/html; charset=utf-8 If there is an error in the CORS request, the browser will fire the client’s onerror event handler. It will also print the following error to the console log: 如果 CORS 请求发生了错误，浏览器会触发客户端的 onerror 事件处理程序。也会在控制台日志中打印如下错误： 1XMLHttpRequest cannot load http://api.alice.com. Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin. The browser doesn’t give you a lot of details on why the error occurred, it only tells you that something went wrong. 浏览器不会给出为什么出错的详细信息，它只会告诉你出错了。 A word about security | 谈一点安全 While CORS lays the groundwork for making cross-domain requests, the CORS headers are not a substitute for sound security practices. You shouldn’t rely on the CORS header for securing resources on your site. Use the CORS headers to give the browser directions on cross-domain access, but use some other security mechanism, such as cookies or OAuth2, if you need additional security restrictions on your content. 虽然 CORS 为跨域请求奠定了基础，但是 CORS 请求头不能代替健全的安全措施。你不能依赖 CORS 头来保障网站资源的安全。使用 CORS 头来给浏览器执行跨域访问的指导，但是如果想要你的内容更加安全，使用其他的安全机制，例如 cookies 或者 OAuth2 。 CORS from JQuery | 用 JQuery CORS JQuery’s $.ajax() method can be used to make both regular XHR and CORS requests. A few notes about JQuery’s implementation: JQuery 的 $.ajax() 方法可以用来发起常规 XHR 和 CORS 请求。JQuery 实现的一些注意事项： JQuery’s CORS implementation doesn’t support IE’s XDomainRequest object. But there are JQuery plugins that enable this. See http://bugs.jquery.com/ticket/8283 for details. JQuery 的 CORS 实现不支持 IE 浏览器的 XDomainRequest 对象。但是有 JQuery 的插件使它支持。这里查看详情。 The $.support.cors boolean will be set to true if the browser supports CORS (This returns false in IE, see bullet above). This can be a quick way to check for CORS support. 如果浏览器支持 CORS ,布尔值 $.support.cors 将被设置为 true （在 IE 浏览器下返回 false，看上面的说明）。这是检查 CORS 支持的一个快捷方法。 Here’s sample code for making a CORS request with JQuery. The comments give more details on how certain properties interact with CORS. 这里有一份用 JQuery 发起 CORS 请求的示例代码。注释部分详细的描述了具体每个属性是如何与 CORS 交互的。 12345678910111213141516171819202122232425262728293031323334353637383940414243$.ajax(&#123; // The 'type' property sets the HTTP method. // A value of 'PUT' or 'DELETE' will trigger a preflight request. type: 'GET', // The URL to make the request to. url: 'http://html5rocks-cors.s3-website-us-east-1.amazonaws.com/index.html', // The 'contentType' property sets the 'Content-Type' header. // The JQuery default for this property is // 'application/x-www-form-urlencoded; charset=UTF-8', which does not trigger // a preflight. If you set this value to anything other than // application/x-www-form-urlencoded, multipart/form-data, or text/plain, // you will trigger a preflight request. contentType: 'text/plain', xhrFields: &#123; // The 'xhrFields' property sets additional fields on the XMLHttpRequest. // This can be used to set the 'withCredentials' property. // Set the value to 'true' if you'd like to pass cookies to the server. // If this is enabled, your server must respond with the header // 'Access-Control-Allow-Credentials: true'. withCredentials: false &#125;, headers: &#123; // Set any custom headers here. // If you set any non-simple headers, your server must include these // headers in the 'Access-Control-Allow-Headers' response header. &#125;, success: function() &#123; // Here's where you handle a successful response. &#125;, error: function() &#123; // Here's where you handle an error response. // Note that if the error was due to a CORS issue, // this function will still fire, but there won't be any additional // information about the error. &#125;&#125;); Cross-Domain from Chrome Extensions | 用Chrome扩展跨域 Chrome extensions support cross-domain requests in a two different ways: Chrome 浏览器扩展通过下面两种方式支持跨域请求： Include domain in manifest.json - Chrome extensions can make cross-domain requests to any domain if the domain is included in the “permissions” section of the manifest.json file: 在 manifest.json 中包含域名 - 如果域名包含在 manifest.json 文件中的 “permission” 区域中，Chrome 浏览器扩展可以生成跨域请求到任意域名。 1"permissions": [ "http://*.html5rocks.com"] The server doesn’t need to include any additional CORS headers or do any more work in order for the request to succeed. 服务器不需要包含任何额外的 CORS 头，也不需要做其他更多事情来让请求成功。 CORS request - If the domain is not in the manifest.json file, then the Chrome extension makes a standard CORS request. The value of the Origin header is “chrome-extension://[CHROME EXTENSION ID]”. This means requests from Chrome extensions are subject to the same CORS rules described in this article. CORS 请求 - 如果域名不在 manifest.json 文件中，Chrome 浏览器扩展就会发起一个标准的 CORS 请求。Origin 头的值为 “chrome-extension://[CHROME EXTENSION ID]”。这意味着 Chrome 浏览器扩展发出的请求必须遵循本文叙述的相同的 CORS 规则。 Known Issues | 已知问题 CORS support is still being actively developed in all browsers; here’s a list of known issues (as of 10/2/2013): CORS 支持仍然在所有浏览器中活跃的开发；这里有一个已知问题列表（截至 10/2/2013） FIXED XMLHttpRequests’ getAllResponseHeaders() doesn’t honor Access-Control-Expose-Headers - Firefox doesn’t return response headers when calling getAllResponseHeaders(). (Firefox bug). A similar bug in WebKit has been fixed. 以解决：XMLHttpRequest 的 getAllResponsHeader() 不支持 Access-Control-Expose_Headers - 当调用getAllResponseHeaders() 时Firefox浏览器不返回响应头。（Firefox bug）。WebKit 中同样的问题已经被解决了。 No error information provided to onerror handler - When the onerror handler is fired, the status code is 0, and there is no statusText. This may be by design, but it can be confusing when trying to debug why CORS requests are failing. onerror 事件处理程序不提供错误信息。当 onerror 处理程序被触发的时候，状态码为0，没有 statusText。这可能是故意的，但是这在调试 CORS 请求错误时会让人非常迷惑。 CORS Server Flowchart | CORS 服务器流程图 The flowchart below shows how a server should make the decisions as to which headers to add to a CORS response. Click the image to see a larger version. 下面的流程图展示了服务器应该如何决定将哪些响应头添加到 CORS 响应中。点击查看大图。 CORS Server Flowchart CORS w/ Images In Canvas and WebGL contexts, cross origin images can pose big problems. You can use the crossOrigin attribute on the image element to address much of them. Read Chromium Blog: Using Cross-domain images in WebGLand Mozilla Hacks: Using CORS to load WebGL textures from cross-domain images for the details. Implementation specifics can be found at the MDN page for CORS-enabled Image. 在 Canvas 和 WebGL 环境中，跨源图像可能导致大问题。你可以用图片元素的 crossOrigin 属性来解决大部分的问题。阅读 Chromium Blog: Using Cross-domain images in WebGL 和 Mozilla Hacks: Using CORS to load WebGL textures from cross-domain images 详细了解。在 MDN 页面上可以找到 支持 CORS 图像 的实现细节。 Resources Here are some resources if you’d like to learn more about CORS: The CORS Spec A good intro to CORS from Nicholas Zakas enable-cors.org - More details on how to enable CORS on your server.]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>CORS</category>
      </categories>
      <tags>
        <tag>CORS</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从Linux系统中恢复最近误删的文件]]></title>
    <url>%2F2018%2F10%2F13%2F%E4%BB%8ELinux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E6%81%A2%E5%A4%8D%E6%9C%80%E8%BF%91%E8%AF%AF%E5%88%A0%E7%9A%84%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[​ 谁都会有手抖的时候，晚上远程公司的ArchLinux时不小心 sudo rm -rf Desktop 了一下，然后开始尝试恢复误删文件。 google了一篇恢复的教程：PhotoRec – Recover Deleted or Lost Files in Linux ​ 当我们不小心用 shift + delete ，删除选项，或者清空回收站的方式删除了文件的时候，文件的内容实际上并没有被从硬盘上擦除。系统只是简单的将这些文件从目录结构中移除了，所以在被删的文件夹下看不到删除的文件了，但是他们实际上仍然保存在硬盘上被删除的位置上。 ​ 只要具备了正确的工具和知识，你就可以将他们从电脑上恢复出来。但是如果你从硬盘上恢复更多文件时，最近被删除的文件可能会被覆盖，导致你可能拿不到最近删除的文件。 ​ 我们将使用 Testdisk 这个工具来完成本次Linux下的文件恢复操作，Testdisk 是一款非常出色的恢复工具套件，附带一个名为 PhotoRec 的免费工具。 在Linux上安装 Testdisk(PhotoRec)1234567891011121314------- On Debian/Ubuntu/Linux Mint ------- $ sudo apt-get install testdisk------- On CentOS/RHEL/Fedora ------- $ sudo yum install testdisk------- On Fedora 22+ ------- $ sudo dnf install testdisk ------- On Arch Linux ------- $ pacman -S testdisk ------- On Gentoo ------- $ emerge testdisk 也可以去管网下载二进制安装包来手动安装，地址 恢复文件工具安装完成后，需要在 shell 中用 root 权限启动 PhotoRec，指定被删除文件所在的分区，我这次是在 /dev/sda2 : 1sudo photorec /dev/sda2 然后可以看到这样的界面 使用左右键选择菜单按钮，回车确定。这里选 Proceed，然后敲回车。 出现这样的界面： 选择 Options 查看有哪些恢复操作选项： 键盘按 Q 返回，在下面的界面中，你可以指定你想搜索和恢复的文件扩展名。选择 File Opt 然后回车。 按 s 来启用/禁用选择所有的文件扩展，如果你已经禁用了所有文件扩展名，则只需要使用右键（或者左键取消选择）选择要恢复的文件扩展类型。 这里我选择恢复 jpg 和一些其他类型。 然后按 b 来保存设置，应该能看到下图的消息。按回车键返回（也可以按 Q），然后再按 Q 返回到主菜单。 现在选择 Search 选项来开始恢复操作，在下面的界面中，选择被删文件所在的文件系统类型，然后按回车。 接下来，选择是只有空余空间还是整个分区都要分析。注意，选择全分区可能会使分区变慢，耗时更长。一旦你选择了合适的分区选项，按回车继续。 选择一个目录存放将要恢复出来的文件，如果目标正确，按 C 继续。 选择不同分区上的一个文件夹，避免被删文件被这个分区上恢复出来的其他文件覆盖。 要选择 root 分区，用 左键。 这里，我在根目录下创建了一个 recover 文件夹用来存放恢复文件 1sudo mkdir /recover 下面的截图展示了恢复出来的指定类型的被删文件。你可以按回车来停止操作。 注意：你的系统可能会变慢，某些时候还可能卡顿，需要耐心等待知道整个过程完成。 ​ 在整个过程的最后，PhotoRec 会告诉你恢复的文件数量和存放的位置。 ​ 被恢复出来的文件默认是用 root 权限存储的，所以也要用提升的权限打开文件管理器以访问文件。 ​ 操作有疑问的可以去 PhotoRec 官网上去看看文档：http://www.cgsecurity.org/wiki/PhotoRec. 注意事项​ 恢复出来的文件名会被恢复工具重命名，文件存放目录也不是按照删除之前的样子，要从恢复出来的文件中找到自己需要的那几个，还是要费点功夫的。 ​ 如果你像我一样，也是在远程 shell 中执行恢复过程，为了避免远程 shell 因为网络问题终端而导致 PhotoRec 的恢复进程被中止，建议在 screen 中执行恢复操作，这样及时远程 shell 断开，恢复进程也会在后台继续执行，再次远程登录时还可以恢复到之前的界面。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NPM package.json 中的 tilde (~) 和 caret (^)]]></title>
    <url>%2F2018%2F10%2F12%2Fdifference-between-tilde-and-caret-in-npm-packagefile%2F</url>
    <content type="text"><![CDATA[原文：What’s the difference between a tilde (~) and a caret (^) in a npm package.json file? 如果你用 npm 来管理 JavaScript 应用程序的 package ，那你应该熟悉 package.json 文件了。 12345&#123; "devDependencies": &#123; "ember-cli": "~2.14.0" &#125;&#125; 语法是 JSON 格式，key 是 package 的名称，value 是要使用的这个 package 的版本号。 npm 就是用 package.json 文件来声明你的 app 依赖的 package 的版本的。 版本号以 semver 语法 表示，它指定每个部分具有不同的含义。semver 被点号划分成 3 各部分。 123major.minor.patch1.0.2 Major，minor 和 patch 代表包的不同发行版本。 Npm 用波浪线（~）和插入符（^）来分别指定要使用的 patch（补丁）和 minor（小）版本。 所以如果你看到了 ~1.0.2 就表示要安装 1.0.2 或以上的 patch 版本，例如 1.0.4 。如果你看到 ^1.0.2 就表示要安装 1.0.2 或者最新的 minor 版本或者 patch 版本，例如 1.1.0 。]]></content>
      <categories>
        <category>FE</category>
        <category>工程化</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Archlinux安装Realtek-8812AU无线网卡驱动]]></title>
    <url>%2F2018%2F10%2F12%2FArchlinux%E5%AE%89%E8%A3%85Realtek-8812AU%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[​ 在公司台式机上装了Arch Linux，自己的笔记本用Windows，用Synergy共享键鼠，由于网口有限，台式机接有线，笔记本连wifi，不在一个网段内，公司网络不稳定，Synergy时不时会断开连接，于是就想把手里的Realtek-8812AU（后面简称无线网卡）用在台式机上，这样台式机和笔记本都连wifi，出问题的概率应该会小一点。 ​ 于是开始找驱动，买无线网卡时附带了一个刻有驱动的光盘，我把驱动拷贝后光盘就丢掉了，里面有Linux驱动。 123456789101112131415161718[kinboy@kinboyarchlinux Linux]$ ltotal 104K4.0K -rw-r--r-- 1 kinboy kinboy 183 Aug 1 2014 'Last Drivers Download.url' 0 -rw-r--r-- 1 kinboy kinboy 0 Feb 19 2014 RTL8812AU_linux_v4.2.4_9390.20131023 40K -rw-r--r-- 1 kinboy kinboy 37K Oct 23 2013 ReleaseNotes.pdf4.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 WiFi_Direct_User_Interface4.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 android_ref_codes_JB_4.14.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 android_ref_codes_JB_4.24.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 android_ref_codes_JB_4.34.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 android_reference_codes4.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 android_reference_codes_ICS_nl802114.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 document4.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 driver4.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 hardware_wps_pbc4.0K -rw-r--r-- 1 kinboy kinboy 3.1K Aug 21 2013 install.sh 12K -rw-r--r-- 1 kinboy kinboy 8.1K Oct 23 2013 readme.txt4.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 wireless_tools4.0K drwxr-xr-x 2 kinboy kinboy 4.0K Sep 12 2016 wpa_supplicant_hostapd 执行 install.sh 编译时出错 123456789101112131415161718192021222324252627282930313233343536373839make ARCH=x86_64 CROSS_COMPILE= -C /lib/modules/4.18.12-arch1-1-ARCH/build M=/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023 modulesmake[1]: Entering directory '/usr/lib/modules/4.18.12-arch1-1-ARCH/build' CC [M] /home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/core/rtw_cmd.oIn file included from /home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service.h:41, from /home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/drv_types.h:32, from /home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/core/rtw_cmd.c:22:/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service_linux.h: In function '_init_timer':/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service_linux.h:253:8: error: '_timer' &#123;aka 'struct timer_list'&#125; has no member named 'data' ptimer-&gt;data = (unsigned long)cntx; ^~/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service_linux.h:254:2: error: implicit declaration of function 'init_timer'; did you mean '_init_timer'? [-Werror=implicit-function-declaration] init_timer(ptimer); ^~~~~~~~~~ _init_timerIn file included from /home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/drv_types.h:32, from /home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/core/rtw_cmd.c:22:/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service.h: In function 'thread_enter':/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service.h:342:2: error: implicit declaration of function 'allow_signal'; did you mean 'do_signal'? [-Werror=implicit-function-declaration] allow_signal(SIGTERM); ^~~~~~~~~~~~ do_signal/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service.h: In function 'flush_signals_thread':/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service.h:352:6: error: implicit declaration of function 'signal_pending'; did you mean 'timer_pending'? [-Werror=implicit-function-declaration] if (signal_pending (current)) ^~~~~~~~~~~~~~ timer_pending/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/include/osdep_service.h:354:3: error: implicit declaration of function 'flush_signals'; did you mean 'do_signal'? [-Werror=implicit-function-declaration] flush_signals(current); ^~~~~~~~~~~~~ do_signalcc1: some warnings being treated as errorsmake[2]: *** [scripts/Makefile.build:318: /home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023/core/rtw_cmd.o] Error 1make[1]: *** [Makefile:1517: _module_/home/kinboy/Linux/driver/rtl8812AU_linux_v4.2.4_9390.20131023] Error 2make[1]: Leaving directory '/usr/lib/modules/4.18.12-arch1-1-ARCH/build'make: *** [Makefile:1161: modules] Error 2##################################################Compile make driver error: 2Please check error Mesg################################################## google implicit declaration of function ‘allow_signal’ 找到了这篇文章，大概讲了错误的原因和解决办法 Wsky 1200Mbps Wireless USB Wifi Adapter 我在操作过程中没有得到同样的结果，后来又在GitHub中找到了匹配版本的驱动的源码，地址 12345git clone https://github.com/abperiasamy/rtl8812AU_8821AU_linux.gitcd rtl8812AU_8821AU_linuxmakesudo make installsudo modprobe -a rtl8812au 插上USB无线网卡，灯亮！ 更新：内核升级至 4.19 后，无线网卡驱动失效，之前的驱动源码在 4.19 内核下无法编译成功，找到可以成功编译的驱动源码。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>archlinux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用vimdiff作为git mergetool]]></title>
    <url>%2F2018%2F10%2F09%2FUse-Vimdiff-As-Git-Mergetool%2F</url>
    <content type="text"><![CDATA[译自：Use vimdiff as git mergetool 使用vimdiff作为 git mergetool 可能有点难以理解，因为它会打开多个窗口，只有极少的说明。本篇是一个简单的练习，介绍 vimdiff 的基本使用方法以及什么是 LOCAL , BASE ,和 REMOTE 。这篇教程默认你至少具备了一点基础的 vim 知识（如何移动光标，保存，窗口切换）。如果你还不具备这些知识，这里有一篇短文可以帮助到你： Using vim for writing code。显然，对git和分支的基本理解也是必须的。 Git 配置开始之前，你需要知道如何将vimdiff设置为git mergetool。如下： 123git config merge.tool vimdiffgit config merge.conflictstyle diff3git config mergetool.prompt false 这些设置会使用git作为默认的合并工具，合并时会显示出冲突分支的共同祖先，会禁用打开vimdiff的提示命令。 创造合并冲突我们来创建一个测试环境。你可以自由选择跳过这部分或者跟着教程来做。 1234mkdir zoocd zoogit initvi animals.txt 添加一些动物 1234catdogoctopusoctocat 保存文件 123456789101112git add animals.txtgit commit -m &quot;Initial commit&quot;git branch octodoggit checkout octodogvi animals.txt # let&apos;s change octopus to octodoggit add animals.txtgit commit -m &quot;Replace octopus with an octodog&quot;git checkout mastervi animals.txt # let&apos;s change octopus to octomangit add animals.txtgit commit -m &quot;Replace octopus with an octoman&quot;git merge octodog # merge octodog into master 这里我们就会得到一个合并错误： 123Auto-merging animals.txtCONFLICT (content): Merge conflict in animals.txtAutomatic merge failed; fix conflicts and then commit the result. 用vimdiff解决合并冲突让我们来解决冲突： 1git mergetool 这一开始看起来会很恐怖，我们来解释一下发生了什么。 从左至右，从上到下： LOCAL - 这个文件来自当前分支；BASE - 两个分支的共同祖先，在两个分支上的文件改变之前的样子；REMOTE - 要合并到你当前分支的外部分支上的文件；MERGED - 合并结果，将会保存到本地repo中。 假设我们希望保留octodog 的变化（来自REMOTE）。为此，移动到MERGED文件上（Ctrl + w, j）,移动光标到一个合并冲突的区域，然后： 1:diffget RE 这一步从REMOTE上获得相应的更改并将其放入到MERGED文件中，你也可以： 123:diffg RE &quot; get from REMOTE:diffg BA &quot; get from BASE:diffg LO &quot; get from LOCAL 保存文件，然后退出（快速保存写入并退出的方法是:wap ） 执行git commit，你就完成了！]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单页面应用与服务器]]></title>
    <url>%2F2018%2F09%2F28%2FSimple-Page%20Applications%20And%20Server%2F</url>
    <content type="text"><![CDATA[原文：Single-Page Applications and the Server SPAs minimize server requests, but they aren’t server-lessSingle-page applications (SPAs) are distinguished from regular applications because they do not need to make server requests when the user navigates. However, the application still needs a server to provide the initial files for the application to render. Demystifying Single-Page Applications covers the client-side aspect of how this works and here we will cover how different types of servers can support single-page applications. Server TypesWebsites are backed by two types of servers: web and application. NGINX, a web server, provides a good explanation of the two. The most general way to differentiate the two is to say that a web server serves static content (i.e. files that already exist on the server) while an application server can generate new content. With single-page applications, there are three main scenarios for serving the application’s content: Purely static Configurable static Dynamic Purely StaticA purely static web server can only successfully respond to requests if a resource at the requested location exists. This will typically be the case when you are using a static host, such as GitHub Pages or Amazon S3. With a purely static server, a request for /horses.html only succeeds (returns a response with status 200) if the server’s root directory contains a horses.html file. If the resource does not exist, the server will return a 404 response. Configurable StaticA web server can be configured to respond with an alternative file if the requested resource doesn’t actually exist on the disk. If a request for /bears comes in and the server has no bears file, the configuration can tell it to respond with an index.html file instead. DynamicAn application server will have a web framework running on top of it. For example, a Node application server might be running Express and a Unicorn application server may be used to run Ruby on Rails. The framework is able to match requests and dynamically generate responses. Like a configurable static setup, requests don’t have to map directly to files on the server, but a dynamic setup gives you even more leeway. An application server is most likely run as a proxy of a web server, but the web server would typically just pass non-static requests to the application server. Generally speaking, a dynamic/configurable static server is preferable for running a single-page application. If you are using a static file host, you can still run a single-page application, but there are some limitations that you will need to know. Serving Single-Page Applications From Static File HostsIf you are running a single-page application through a static file host, you have two options. The first, and more practical, is to have a single HTML file. With this system, the URL’s hash will be used to store location data. This would be the home page: 1https://example.com/#/ and this is the contact page: 1https://example.com/#/contact Because the location is stored in the URL’s hash, and the server only uses the location’s pathname to map resources, all requests to the server for pages in the application will be for the root index.html file. Most single-page application routers should provide you with a way to encode locations in the hash. With the Curi router, this is done using the Hickory hash history. 1234567import Hash from &quot;@hickory/hash&quot;;// ...const history = Hash();const router = curi(history, routes);// current URL: &quot;example.com/#/&quot;history.push(&quot;/contact&quot;);// push() changes the URL to &quot;example.com/#/contact&quot; The popular history package also has a hash option. 12import &#123; createHashHistory &#125; from &quot;history&quot;;const history = createHashHistory(); A visual drawback of using hash URLs is that they are a bit ugly. However, they are your best bet and I would recommend just dealing with it. If you really want “pretty” URLs, you could generate an HTML file for every single possible URL in your application. That would allow your server to be able to respond with an HTML file for every (valid) request. This is technically feasible for applications with a small number of routes, and some static site generators will do this for you. However, this breaks down for sites that generate URLs for dynamic content, like profile pages for users. Serving Single-Page Applications from Configurable Static ServersIf you can configure your web server, creating a single-page application with “pretty” URLs is much easier. The basic gist of how to configure a web server for single-page applications is that you have a single HTML file that your application serves for almost every request. 123456789&lt;!-- index.html --&gt;&lt;!doctype html&gt;&lt;html&gt; &lt;head&gt;...&lt;/head&gt; &lt;body&gt; &lt;div id=&quot;root&quot;&gt;&lt;/div&gt; &lt;script src=&quot;/static/js/index.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; Request for/camels? Respond with index.html. Request for /badgers? Respond with index.html. Request for /static/js/index.js? That is where the “almost” comes in. The server needs to distinguish between requests for HTML content for requests for other files so that it can serve the correct files, and not the index.html file, for those requests. With the Apache web server, you can use mod_rewrite to try to respond with the requested file, but fall back to responding with a default HTML file when the resource does not exist. 1234567891011RewriteEngine On# set the base URL prefixRewriteBase /# for requests for index.html, just respond with the fileRewriteRule ^index\.html$ - [L]# if requested path is not a valid filename, continue rewriteRewriteCond %&#123;REQUEST_FILENAME&#125; !-f# if requested path is not a valid directory, continue rewriteRewriteCond %&#123;REQUEST_FILENAME&#125; !-d# if you have continue to here, respond with index.htmlRewriteRule . /index.html [L] With Nginx, you can use try_files to serve the HTML file. This will attempt to serve the file at the provided $uri, but if that does not exist, it will fall back to the index.html file. 123456server &#123; ... location / &#123; try_files $uri /index.html; &#125;&#125; Note: These configurations are gleaned from an old React Router documentation. If you have issues getting these Apache/NGINX setups to work, I would recommend either checking their respective documentation or StackOverflow. Dynamically Serving Single-Page Applications with Application ServersThe setup for application servers is similar to configurable static servers. In some cases, they may even overlap by having Apache/NGINX/etc. serve static files and pass other requests to a proxy, the application server. There are so many different application servers out there, that it is impractical to cover the setup for each of them here, but the gist is always the same: process the request, determine how to respond, and respond with some HTML. The example code below will use the Express framework. An application server needs to identify static resource requests and respond with the correct file. If you configure your web server to handle these, then you can skip this on the application server. Additionally, a dynamic server needs to identify API requests so that they can be handled properly. Some single-page applications will also employ server-side rendering. Instead of using a common HTML file, server-side rendering will respond with the fully structured HTML for the requested page. Some people swear by this, while others consider it unnecessary. At the very least, there are some caveats to it, but we will come back to this in a little bit. Your framework should provide a way to identify static resource requests. This basically entails specifying a static file directory so that any request whose pathname begins with the static directory will just serve the requested file (or fail with a 404 response if the requested file does not exist). To do this with Express, you would use its static() method and your Express app’s use() method. static() receives the local directory where the static files exist. You can either pass this as the only argument to use(), in which case it will respond to requests for the same local directory, or you can pass it a first argument path if static file requests don’t refer to the literal location. 1234567const express = require(&quot;express&quot;);const app = new express();// requests for /public/js/index.js will return public/js/index.jsapp.use(express.static(&quot;public&quot;));// requests for /static/js/index.js will return public/js/index.jsapp.use(&quot;/static&quot;, express.static(&quot;public&quot;));app.listen(&quot;8000&quot;); Frameworks also need to know how to map requests to to how they should respond, similar to how routes work in a single-page application. When the framework gets a request, it will iterate over these handlers and use the first one that matches the request to respond. In order for the framework to respond to any possible location, we need to give it a catch-all route handler that responds with the common HTML file. 1234const path = require(&quot;path&quot;);app.use(&quot;*&quot;, function(req, resp) &#123; resp.sendFile(&quot;/public/index.html&quot;);&#125;); The order of operations is important here. A catch-all route will match every location, so anything that shouldn’t be matched by it (i.e. static file and API requests) needs to be defined prior to the wildcard route. 12345678// 1. match static filesapp.use(&quot;/static&quot;, express.static(&quot;public&quot;));// 2. match API requestsapp.use(&quot;/graphql&quot;, ...);// 3. finally, match everything elseapp.use(&quot;*&quot;, function(req, resp) &#123; resp.sendFile(&quot;/public/index.html&quot;);&#125;); Server-Side RenderingThe technique outlines above sends a minimal HTML file, which will be “filled in” on the client-side to render the application. Server-side rendering (SSR) allows you to render each route’s HTML content on the server. The response will then be an HTML file that is already “filled in”. Server-side rendering also only really makes sense to attempt if you are running a Node server because you can re-use client-side code on the server. Technically speaking, if you aren’t using Node, you could create the same UI for whatever framework your server uses, but that would require you to duplicate your render logic. The advantages of using SSR is that your application will have a faster initial render for users and that it is easier for search engines to crawl your content. Whether an application really benefits has a variety of factors. For example, if you are using server-side rendering for search engine optimization, only public pages need to be server-side rendered. A private page page (one that is only visible to authorized users) would not benefit from server-side rendering since no search engines should attempt to index it. Instead of returning an HTML file from the disk, server-side rendering will generate an HTML string when a request comes in. There are two parts to this HTML string: the base HTML and the route specific HTML. The base HTML is a template that will be used for all requests. This should include any &lt;script&gt; tags that will be necessary for running the application on the client. The route specific HTML will be inserted into the template. Most of this should be inserted into a container element in the &lt;body&gt; of the template, but you may also want to insert elements into the &lt;head&gt;, such as a &lt;title&gt;. The technique for rendering on the server will depend entirely on how you are rendering on the client. If you are using React, the react-dom package provides server methods for generating an HTML string. Note: If you do server-side rendering using React, on the client you will want to use ReactDOM.hydrate() instead of ReactDOM.render(). 12345678910function responseHTML(content) &#123; return `&lt;!doctype html&gt; &lt;html&gt; &lt;head&gt;&lt;/head&gt; &lt;body&gt; &lt;div id=&quot;root&quot;&gt;$&#123;content&#125;&lt;/div&gt; &lt;script src=&quot;/static/js/bundle.js&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt;`;&#125; Important! Any static resource references in the template should be absolute. If you use a relative path (static/js/bundle.js) in the template, then requests for nested URLs (/parent/child) would attempt to load non-existent resource URLs (/parent/static/js/bundle.js). When the application just sends the same HTML file for every request, it doesn’t matter what the requested path is, but with server-side rendering it is important to render based on the request URL. Note: With Express, the request object can be referenced to get the requested path. req.path, which is just the requested URL’s pathname, can be used to determine the route that matches. However, if the app renders content using the search/hash, req.url should be used. To demo the actual rendering, we will use React and the Curi router, which makes server-side rendering very easy. 1234567891011121314151617181920212223242526272829import React from &quot;react&quot;;import renderToString from &quot;react-dom/server&quot;;import curi from &quot;@curi/core&quot;;import InMemory from &quot;@hickory/in-memory&quot;;import &#123; CuriProvider &#125; from &quot;@curi/react&quot;;import routes from &quot;../client/routes&quot;;app.use(&quot;*&quot;, function(req, resp) &#123; // 1. Use the request&apos;s URL to create the router. // Curi will use the provided location to generate a response // object const history = InMemory(&#123; locations: [req.url] &#125;); const router = curi(history, routes); // 2. Render the application using React. // The exact implementation here will vary, but Curi uses // a render-invoked prop to render a &quot;body&quot; component // from the response object provided by the router. const content = renderToString( &lt;CuriProvider&gt; &#123;(&#123; response &#125;) =&gt; &lt;response.body response=&#123;response&#125; /&gt;&#125; &lt;/CuriProvider&gt; ); // 3. Insert the content into the template. // We want to return the entire page&apos;s HTML, not just // the content rendered by React const html = responseHTML(content); // 4. Send the response HTML. resp.send(html);&#125;); That is the general gist of server-side rendering. Actual implementations vary by framework and router, but the idea is always the same. RecapIf you are using a static file host, you will either need to use hash routing and a shared HTML file or generate an HTML file for every possible route in your application. Web servers can be made more amenable to single-page applications if you can configure them. This allows you to respond with an HTML file for requests that don’t have a matching resource on the server. Application servers make serving single-page applications easy by using catch-all routes to respond to requests for any location. It is important that these match any other possible URLs, such as static resource and API requests, first so that the catch-all doesn’t catch those. If your application server is running Node, you can take advantage of server-side rendering to pre-generate the page’s HTML content, but this isn’t always necessary. React]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>单页应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器的history]]></title>
    <url>%2F2018%2F09%2F25%2Fa-little-bit-of-history%2F</url>
    <content type="text"><![CDATA[原文: A little bit of history If you wish to understand React Router, you must first study history. More specifically, the history package, which provides the core functionality for React Router. It enables projects to easily add location based navigation on the client-side, which is essential for single page applications. 如果你想要理解 React Router，那你必须先学习 history。具体来说，是 history 包，它提供了 React Router 的核心功能。它允许项目轻松的在客户端添加基于位置(location)的导航，这对但页面应用来说是至关重要的。 1npm install --save history There are three types of history: browser, hash, and memory. The history package exports methods to create each type. 共有3种类型的history：browser，hash，和memory。history包导出了用于创建每种类型的方法。 12345import &#123; createBrowserHistory, createHashHistory, createMemoryHistory&#125; from &apos;history&apos; If you are using React Router, it can automatically create history objects for you, so you may never have to actually interact with history directly. Still, it is important to understand the differences between each type of history so that you can determine which one is right for your project. 如果你使用 React Router，它能自动创建history对象，所以你可能永远不必与history直接交互。然而，理解history的几种类型之间的差异还是很重要的，这样你才能决定哪一种能适用于你的项目。 What is history? 什么是history？No matter which type of history you create, you will end up with an object that has nearly the same properties and methods. 不论你创建了哪种类型的history，你都将得到一个具有几乎相同属性和方法的对象。 Location 位置The most important property of a history object is the location. The location object reflects “where” your application currently is. It contains a number of properties that are derived from a URL. These are pathname , search [1], and hash. history 对象最重要的属性是location。location对象反映了你的应用程序当前所在的位置。它包含了从URL派生过来的若干属性。即 pathname , search[1] ,和 hash。 Additionally, each location has a unique key property associated with it. This key can be used to identify and store data specific to a location. 另外，每个location都有一个唯一的 key 属性关联与之关联。这个 key 可以被用于标识和存储与特定location相关的数据 Finally, a location can have state associated with it. This provides a means of attaching data to a location that is not present in the URL. 最后，一个location还能有一个 state 与之关联。它提供了一种将数据附加到URL中没有出现的位置的方法。 1234567&#123; pathname: &apos;/here&apos;, search: &apos;?key=value&apos;, hash: &apos;#extra-information&apos;, state: &#123; modal: true &#125;, key: &apos;abc123&apos;&#125; When a history object is created, it will need an initial location. How this is determined is different for each type of history. For example, the browser history will parse the current URL. 当一个 history 对象被创建，它就会需要一个初始的 location。在各种类型的 history 中，如何确定这个初始位置是不同的。例如，browser history会将当前的URL转换为当前 location。 One location to rule them all?While there is only one current location that we can access, the history object keeps track of an array of locations. The ability to add locations and move throughout the location array is what makes history “history”. If history only knew about the current location, it would be more aptly named “present”. 虽然我们只能访问一个当前位置，但是 history 对象会跟踪一组 location 。能在 location 数组中完成添加和移动的能力让 history 成为真正的 “history”。如果 history 只知道当前的 location，那么它被叫成 “present” 可能会更合适一点。 In addition to an array of locations, the history also maintains an index value, which refers to the position of current location in the array. 除了一组 location ，history 还维护了一个 index 索引值，它指向了 location 数组中当前 location 的位置。 For the memory history, these are explicitly defined. For both the browser and hash histories, the array and index is controlled by the browser and cannot be directly accessed [2]. 对与 memory history ，这些是明确定义的额。对于 browser 和 hash history，location 数组和 index 索引值都是被浏览器控制并且不可直接访问的[2]。 Navigation 导航An object with a location property isn’t particularly exciting. Where a history object starts to become interesting is with the navigation methods. Navigation methods allow you to change the current location. 一个具有 location 属性的对象没什么值得令人兴奋的。history 对象有趣的地方在于 导航（navigation） 方法。导航方法允许你改变当前的 location。 PushThe push method allows you to go to a new location. This will add a new location to the array after the current location. When this happens, any “future” locations (ones that exist in the array after the current location because of use of the back button) will be dropped. push方法让你能跳转到一个新的location。它会在 location 数组中的当前 location 的后面添加一个新的 location。当这种情况发生时，任何 “future” location（那些由于使用了后退按钮在数组中位于 current location 之后的 location） 将被删除。 By default, when you click on a &lt;Link&gt; from React Router, it will use history.push to navigate. 默认情况下，当你从 React Router 点击一个&lt;Link&gt;，它将使用 history.push来进行导航。 1history.push(&#123; pathname: &apos;/new-place&apos; &#125;) ReplaceThe replace method is similar to push, but instead of adding a new location, it will replace the location at the current index. “Future” locations will not be dropped. replace 方法与 push 相似，但是不同于添加一个新的 location ，它会替换当前 index 索引位置上的 location。“Future” location 将不会被删除。 Redirects are a good time to use replace. This is what React Router’s&lt;Redirect&gt; component uses. 重定向是使用 replace 的好时机。React Router的 &lt;Redirect&gt; 也使用它。 For example, if you are on one page and click a link that navigates to a second page, that second page might redirect to a third page. If the redirect uses push, clicking the back button from the third will bring you back to the second page (which potentially would redirect you back to the third page again). Instead, by using replace, going back from the third page will take you to the first. 例如，如果你在一个页面上点击了一个 link 导航到第二个页面上，第二个页面可能重定向到第三个页面。如果重定向使用了 push ，在第三个页面点击后退按钮将会带你回到第二个页面（第二个页面可能会再次将你重定向到第三个页面上）。相反，使用 replace 从第三页将带你回到第一页。 1history.replace(&#123; pathname: &apos;/go-here-instead&apos; &#125;) Go, go, goFinally, there are three related methods: goBack, goForward, and go. 最后，有三个相关的方法：goBack ，goForward ，and go。 goBack goes back one page. This essentially decrements the index in the locations array by one. goBack 回退一页。它实质上将 location 数组上的 index 减 1。 1history.goBack() goForward is the opposite of goBack, going forward one page. It will only work when there are “future” locations to go to, which happens when the user has clicked the back button. 与 goBack 相反，过Forward 前进一页。它仅在有 future location 时起作用，当用户点击了后退按钮时会出现这种情况。 1history.goForward() go is a more powerful combination of goBack and goForward . Negative numbers passed to the method will be used to go backwards in the array, and positive numbers will be used to go forward. go 是 goBack 与 goForward 的更强大的组合。传给这个方法的负数会被用于在数组中回退，整数会被用于前进。 1history.go(-3) Listen!History uses the observer pattern to allow outside code to be notified when the location changes. history 使用观察者模式（observer pattern） 来允许外部代码在 location 改变时接收通知。 Each history object has a listen method, which takes a function as its argument. That function will be added to an array of listener functions that the history stores. Any time the location changes (whether this is by your code calling one of the history methods or because a user clicked a browser button), the history object will call all of its listener functions. This allows you to setup code that will update whenever the location changes. 每种 history 对象都有一个 listen 方法，接收一个 function 作为参数。这个 function 将被添加到一个 history 存储的监听函数数组中。一旦 location 变动（不论是你的代码调用了一个 history 方法还是一个用户点击了浏览器按钮），history 对象将会调用所有的监听函数。这允许你编写一些在 location 变化时更新的代码。 1234const youAreHere = document.getElementById(&apos;youAreHere&apos;)history.listen(function(location) &#123; youAreHere.textContent = location.pathname&#125;) A React Router’s router component will subscribe to its history object so that it can re-render whenever the location changes. React Router 的路由组件会订阅他的 history 对象，这样无论合适 location 发生了变化，它都能重新渲染。 Linking things togetherEach history type also has a createHref method that can take a location object and output a URL. 每种类型的 history 都有一个 createHref方法，接收一个 location 对象，输出一个 URL。 Internally, history can navigate using location objects. However, any code that is unaware of the history package, such as anchor elements (&lt;a&gt;), does not know what location objects are. In order to generate HTML that will still properly navigate without knowledge of history, we must be able to generate real URLs. 在内部，history 可以用 location 对象导航。但是，任何不接触 history 包的代码，例如锚元素（&lt;a&gt;）,都不知道 location 对象是什么。为了生成在不了解 history 的情况下仍然能够正确导航的 HTML，我们必须生成真实的 URL。 123456789const location = &#123; pathname: &apos;/one-fish&apos;, search: &apos;?two=fish&apos;, hash: &apos;#red-fish-blue-fish&apos;&#125;const url = history.createHref(location)const link = document.createElement(&apos;a&apos;)a.href = url// &lt;a href=&apos;/one-fish?two=fish#red-fish-blue-fish&apos;&gt;&lt;/a&gt; That covers the essential history API. There are a couple more properties and methods, but the above should be enough to have a solid understanding of how to work with a history object. 这覆盖了必要的 history API。还有一些属性和方法，但是上面这些应该足够让你充分了解如何使用 history 对象。 With our powers combinedThere are some differences between the history types that you will need to consider when deciding which is best suited for your project. Between the three of them, any use case should be covered. 在决定哪种类型最适合你的项目时，有一些 history 类型之间的差异你需要考虑。这三种类型，应该能够覆盖任何用例。 In the BrowserBrowser and hash histories are both intended to be used in a browser. They interact with the history and location web APIs so that the current location is the same as the one displayed in your browser’s address bar. Browser 和 hash history 都是在浏览器中使用的。它们与 history 和 location web API交互，所以 current location 与浏览器地址栏中显示的是一样的。 12const browserHistory = createBrowserHistory()const hashHistory = createHashHistory() The biggest difference between the two is how they create a location from a URL. The browser history uses the full URL [3], while the hash history only uses the portion of the URL located after the first hash symbol. 这两者最大的不同是它们如何从一个 URL 创建 location。browser history 将会使用完整 URL[3]，然而 hash history 只会用 URL 中位于第一个 hash 符号（#）之后的部分。 1234567891011121314// Given the following URLurl = &apos;http://www.example.com/this/is/the/path?key=value#hash&apos;// a browser history creates the location object:&#123; pathname: &apos;/this/is/the/path&apos;, search: &apos;?key=value&apos;, hash: &apos;#hash&apos;&#125;// a hash history creates the location object:&#123; pathname: &apos;hash&apos;, search: &apos;&apos;, hash: &apos;&apos;&#125; Hashing things outWhy would you ever want to use a hash history? When you navigate to a URL, in theory there is a corresponding file on your server. 为什么你会想要使用 hash history？当你导航到一个 URL，理论上你的服务器上应该有一个相应的文件。 For servers that can respond to dynamic requests, the requested file does not actually have to exist. Instead, the server will examine the requested URL and decide what HTML to respond with. 对那些能够响应动态请求的服务器来说，被请求的文件不必实际存在。相反，服务器会检查请求的 URL ，然后决定返回什么 HTML。 However, a static file server can only return the files that exist on the disk. The most dynamic thing that a static server can do is to return the index.html file from a directory when the URL only specifies the directory. 然而一个静态文件服务器只能返回服务器上存在的文件。静态服务器能做到的最动态的事情就是当 URL只指定到一个目录的时候返回这个目录下的 index.html文件。 Update 4/25/18: I wrote a small article about Single-Page Applications and the Server that should help clarify the different ways a single-page application can be hosted. Update 4/25/18: 我写了一篇小文关于Single-Page Applications and the Server，应该能够帮助阐明单页面应用程序能够托管的不同方法。 Given the limitations imposed by a static file server, the simplest solution [4] for serving your application is to only have one “real” location on your server to fetch your HTML from. Of course, only having one location means only having one URL for your application, which would defeat the purpose of using history. To get around this limitation, the hash history uses the hash section of the URL to set and read locations. 考虑到静态文件服务器施加的限制，为你的应用程序提供服务的最简单的解决方案[4]就是在服务器上只有一个真实的 location 来获取 HTML。当然，只有一个位置意味着你的应用程序只有一个 URL，这破坏了 history 的目的。为了解决这个限制，hash history 使用 URL 的 hash 部分来设置和读取 location。 123456789// If example.com uses a static file server, these URLs would// both fetch html from /my-site/index.htmlhttp://www.example.com/my-site#/onehttp://www.example.com/my-site#/two// However, with a hash history, an application&apos;s location will be// different for each URL because the location is derived from// the hash section of the URL&#123; pathname: &apos;/one&apos; &#125;&#123; pathname: &apos;/two&apos; &#125; While the hash history works well, it can be considered a bit of a hack because of its reliance on the storing all of the path information in the hash of a URL. Therefore, it should only be considered when your website does not have a dynamic server to server your HTML. 虽然 hash history 工作得很好，但是由于它依赖与将所有 location 信息保存在 URL 的 hash 中，因此可以认为这种方法有一点点 hack。所以当你的网站没有动态服务器来服务你的 HTML 时可以考虑这种方法。 Memory: The Catch-all HistoryThe best thing about memory location is that you can use it anywhere that you can run JavaScript. 关于 memory history 的最好的事情是你能在任何可以运行 JavaScript 的地方使用它。 A simple example is that you can use it in unit tests run via Node. That allows you to test code that relies on a history object without having to actually test with a browser. 一个简单的例子是你可以在 Node 中运行的单元测试中使用它。这允许你测试一些依赖 history 对象的代码而不必真的用一个浏览器来测试。 More importantly, you can also use a memory history in mobile apps. A memory history is used by react-router-native to enable location based navigation in react-native apps. 更重要的是，你也可以在移动端 app 中使用它。memory history 被react-router-native 用于允许在react-nativeapp中使用基于 location 的导航。 If you really wanted, you could even use a memory history in the browser (although you would be losing the integration with the address bar). 如果你真的想，你甚至可以在浏览器中使用 memory history（但是你会失去与地址栏的集成）。 The biggest difference between the memory history and the browser and hash histories is that it maintains its own in-memory array of locations. When creating a memory history you can pass information to setup the initial state. This state would be an array of locations and the index of the “current” location in that array [5]. This is different from the browser and hash histories, which rely on the browser to already be storing the array of locations. memory history 与 browser 和 hash history最大的不同在于它在内存中维护了自己而 location 数组。当创建一个 memory history 的时候你可以传递来设置初始状态。这个状态将是一个 location 数组和这个数组中的 “current” location 的索引[5]。这与 browser 和 hash history不同，后两个依赖于浏览器已经存储了 location 数组。 1234const history = createMemoryHistory(&#123; initialEntries: [&apos;/&apos;, &apos;/next&apos;, &apos;/last&apos;], initialIndex: 0&#125;) While you can roll your own history equivalent code, there are a lot of little gotchas in how browsers handle navigation that can cause a headache. Instead, it is probably easier to rely on history to think about these things for you. 虽然你可以创造出自己的 history 等效的代码，但是又很多关于浏览器如何处理导航的小问题会让人头痛。相反，利用 history 对象来思考这些事情可能会更简单。 No matter which history type you end up choosing you will end up with a simple to implement, but powerful way to perform navigation and location-based rendering in your application. 不论你最后选用了哪一种 history 类型，你都将得到一个简单易用，但是在应用程序中处理导航和基于位置的渲染的强大方法。 Notes[1] The search property is a string instead of a parsed object. This is because there are different search string parsing packages that handle some cases slightly differently. Instead of imposing one way to parse search strings, history leaves it up to you to decide how to parse the string. If you are looking for a way to parse search strings, some popular options are qs, query-string, querystring, and the native URLSearchParams. [2] This restriction is out of security. The browser’s history’s location array contains more than just the locations that have been visited within your application. Allowing access to this list would leak information about a user’s browsing history that websites should not be allowed access to. [3] By default, the browser history creates location objects whose pathname is the URL’s full pathname. However, you can specify a basename for a history, in which case a portion of the full pathname will be effectively ignored. 1234const history = createBrowserHistory(&#123; basename: &apos;/path&apos; &#125;)// given the url: http://www.example.com/path/here// the history object will create the location&#123; pathname: &apos;/here&apos;, ... &#125; [4] Theoretically you could serve the same HTML file from every valid URL in your application. If all of your URLs are static, this could work, but it would create lots of redundant files. If any of your URLs use parameters to match a large number of possible values, this is infeasible. [5] If you do not provide a memory history with initial locations and index, it will fallback to default values: 12entries = [&#123; pathname: &apos;/&apos; &#125;]index = 0 This might be good enough for most applications, but being able to pre-populate the history can be very useful for things like session restoration. JavaScript React React Router]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>History</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>浏览器</tag>
        <tag>history</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7.4 配置路由网关服务器]]></title>
    <url>%2F2018%2F09%2F07%2FCentOS7.4%E9%85%8D%E7%BD%AE%E7%BD%91%E5%85%B3%E8%B7%AF%E7%94%B1%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Linux具有内核级的路由表，默认是没有启用转发功能的，添加网卡的IP转发功能 123sudo vim /etc/sysctl.conf#添加如下行net.ipv4.ip_forward = 1 重载网络配置，使生效 1sudo sysctl -p 开启public区域ip伪装 1sudo firewall-cmd --permanent --zone=public --add-masquerade 开启public区域ip端转发 1sudo firewall-cmd --permanent --zone=public --add-rich-rule='rule family=ipv4 source address=192.168.12.0/24 masquerade' 上面命令中192.168.12.0/24 IP段包含了路由器IP：192.168.12.252，这样设置会导致CentOS与路由器的通信被转发，VPN断开连接，这里只需要指定我们需要的一部分网段就可以了。 重新加载防火墙配置 1sudo firewall-cmd --reload]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7.4搭建L2TP/IPSec VPN Client]]></title>
    <url>%2F2018%2F09%2F07%2FCentOS7.4%E6%90%AD%E5%BB%BAL2TPIPSec%20VPN%2F</url>
    <content type="text"><![CDATA[安装ipsec和l2tp协议工具 1sudo yum install libreswan xl2tpd 配置文件 12345678910111213141516171819202122232425# /etc/ipsec.d/work.confconfig setup keep-alive=300conn Work authby=secret pfs=yes auto=add keyingtries=%forever dpddelay=30 dpdtimeout=120 dpdaction=restart rekey=yes rekeymargin=1h ikelifetime=8h keylife=1h type=transport left=%defaultroute leftprotoport=udp/l2tp right=civnet.vicp.net rightprotoport=udp/l2tp ike=aes_ctr,aes_cbc,camellia_cbc,serpent_cbc,twofish_cbc,3des,3DES-SHA1;MODP1024 phase2alg=aes-HMAC_SHA1,3DES-HMAC_SHA1 sha2-truncbug=yes 123# cat /etc/ipsec.d/Work.secrets%any civnet.vicp.net : PSK "civvpn.vicp.net" 123456789# cat /etc/xl2tpd/xl2tpd.conf[lac Work]lns = civnet.vicp.netppp debug = yespppoptfile=/etc/ppp/options.ppplength bit = yesredial = yesautodial = yes 12345678910111213141516# cat /etc/ppp/options.pppipcp-accept-localipcp-accept-remoterefuse-eaprequire-mschap-v2noccpnoauthidle 86400mtu 1400mru 1400nodefaultroutedebugconnect-delay 5000name gitlabserverpassword gitlabserver 查看日志 1sudo tail -f /var/log/messages | grep -v "journal" 启动ipsec服务 1sudo systemctl start ipsec 日志输出 12345Sep 7 20:05:55 gitlabserver systemd: Stopping Internet Key Exchange (IKE) Protocol Daemon for IPsec...Sep 7 20:05:55 gitlabserver whack: 002 shutting downSep 7 20:05:55 gitlabserver systemd: Starting Internet Key Exchange (IKE) Protocol Daemon for IPsec...Sep 7 20:05:55 gitlabserver ipsec: nflog ipsec capture disabledSep 7 20:05:55 gitlabserver systemd: Started Internet Key Exchange (IKE) Protocol Daemon for IPsec. 启动xl2tpd服务 1sudo systemctl start xl2tpd 日志输出 123456789101112131415161718Sep 7 20:08:38 gitlabserver pppd[8312]: Sent 714675 bytes, received 3429972 bytes.Sep 7 20:08:38 gitlabserver pppd[8312]: Overriding mtu 1500 to 1400Sep 7 20:08:38 gitlabserver pppd[8312]: Overriding mru 1500 to mtu value 1400Sep 7 20:08:38 gitlabserver pppd[8312]: Terminating on signal 15Sep 7 20:08:38 gitlabserver NetworkManager[898]: &lt;info&gt; [1536322118.7692] device (ppp0): state change: disconnected -&gt; unmanaged (reason 'connection-assumed', sys-iface-state: 'external')Sep 7 20:08:44 gitlabserver pppd[8312]: Connection terminated.Sep 7 20:08:44 gitlabserver avahi-daemon[830]: Withdrawing workstation service for ppp0.Sep 7 20:08:44 gitlabserver pppd[8312]: Modem hangupSep 7 20:08:44 gitlabserver pppd[8312]: Exit.Sep 7 20:08:44 gitlabserver systemd: Unit xl2tpd.service entered failed state.Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: Not looking for kernel SAref support.Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: Using l2tp kernel support.Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: xl2tpd version xl2tpd-1.3.8 started on gitlabserver.localdomain PID:31374Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: Written by Mark Spencer, Copyright (C) 1998, Adtran, Inc.Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: Forked by Scott Balmos and David Stipp, (C) 2001Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: Inherited by Jeff McAdams, (C) 2002Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: Forked again by Xelerance (www.xelerance.com) (C) 2006-2016Sep 7 20:08:44 gitlabserver xl2tpd: xl2tpd[31374]: Listening on IP address 0.0.0.0, port 1701 创建连接 12sudo ipsec auto --up worksudo xl2tpd-control connect work 日志输出 1234567891011121314151617Sep 7 20:12:24 gitlabserver xl2tpd: xl2tpd[20538]: Connecting to host civnet.vicp.net, port 1701Sep 7 20:12:24 gitlabserver xl2tpd: xl2tpd[20538]: Connection established to 171.113.154.63, 1701. Local: 45773, Remote: 36724 (ref=0/0).Sep 7 20:12:24 gitlabserver xl2tpd: xl2tpd[20538]: Calling on tunnel 45773Sep 7 20:12:24 gitlabserver xl2tpd: xl2tpd[20538]: Call established with 171.113.154.63, Local: 31692, Remote: 20120, Serial: 1 (ref=0/0)Sep 7 20:12:24 gitlabserver pppd[31767]: Plugin pppol2tp.so loaded.Sep 7 20:12:24 gitlabserver pppd[31767]: pppd 2.4.5 started by root, uid 0Sep 7 20:12:24 gitlabserver NetworkManager[898]: &lt;info&gt; [1536322344.5696] manager: (ppp0): new Ppp device (/org/freedesktop/NetworkManager/Devices/470)Sep 7 20:12:24 gitlabserver pppd[31767]: Using interface ppp0Sep 7 20:12:24 gitlabserver pppd[31767]: Connect: ppp0 &lt;--&gt;Sep 7 20:12:24 gitlabserver pppd[31767]: Overriding mtu 1500 to 1400Sep 7 20:12:24 gitlabserver pppd[31767]: Overriding mru 1500 to mtu value 1400Sep 7 20:12:27 gitlabserver pppd[31767]: CHAP authentication succeeded: Access grantedSep 7 20:12:27 gitlabserver pppd[31767]: CHAP authentication succeededSep 7 20:12:27 gitlabserver pppd[31767]: local IP address 10.1.0.2Sep 7 20:12:27 gitlabserver pppd[31767]: remote IP address 10.1.0.1Sep 7 20:12:27 gitlabserver NetworkManager[898]: &lt;info&gt; [1536322347.5741] device (ppp0): state change: unmanaged -&gt; unavailable (reason 'connection-assumed', sys-iface-state: 'external')Sep 7 20:12:27 gitlabserver NetworkManager[898]: &lt;info&gt; [1536322347.5746] device (ppp0): state change: unavailable -&gt; disconnected (reason 'none', sys-iface-state: 'external') 检查路由，连接成功后会在系统路由中增加一个ppp0的网络接口 12345678[gitlab@gitlabserver ~]$ route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.12.252 0.0.0.0 UG 100 0 0 enp2s010.1.0.1 0.0.0.0 255.255.255.255 UH 0 0 0 ppp0172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0192.168.12.0 0.0.0.0 255.255.255.0 U 100 0 0 enp2s0192.168.122.0 0.0.0.0 255.255.255.0 U 0 0 0 virbr0 成功后允许进程自动启动 1sudo systemctl enable xl2tpd 参考文档 Securing L2TP using IPsec Streisand How to Connect to L2TP/IPsec VPN on Linux SECURING VIRTUAL PRIVATE NETWORKS (VPNS) USING LIBRESWAN [strongSwan] L2TP over strongswan Linux VPN 客户端 VPN server for remote clients using IKEv1 with L2TP VPN Feature Guide for Security Devices]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器缓存策略交互——maxAge 与 maxStale]]></title>
    <url>%2F2018%2F08%2F18%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E2%80%94%E2%80%94maxAge%E4%B8%8EmaxStale%2F</url>
    <content type="text"><![CDATA[原文：Cache Policy Interaction—Maximum Age and Maximum Staleness To help ensure that the freshest content is returned to the client application, the interaction of client cache policy and server revalidation requirements always results in the most conservative cache policy. All the examples in this topic illustrate the cache policy for a resource that is cached on January 1 and expires on January 4. 为确保客户端应用程序能够被返回最新的内容，客户端缓存策略与服务端验证的交互总是产生最保守的缓存策略。这个话题中的所有示例都是说明一个1月1日被缓存，并在1月4日到期的资源的缓存策略。 In the following examples, the maximum staleness value (maxStale) is used in conjunction with a maximum age (maxAge): 下面的例子会将最大过期值（maxStale）与最大年龄（maxAge）结合使用： If the cache policy sets maxAge = 5 days and does not specify a maxStale value, according to the maxAgevalue, the content is usable until January 6. However, according to the server’s revalidation requirements, the content expires on January 4. Because the content expiration date is more conservative (sooner), it takes precedence over the maxAge policy. Therefore, the content expires on January 4 and must be revalidated even though its maximum age has not been reached. 如果缓存策略设置maxAge = 5 天并且没有指定一个maxStale 值，根据maxAge 值，该内容在1月6日之前可用。然而根据服务端验证要求，该内容在1月4日过期。因为内容过期日期更为保守（更快），它将优先于maxAge策略。因此，即使没有达到最大年龄，该内容也将在1月4日过期，必须被重新验证。 If the cache policy sets maxAge = 5 days and maxStale = 3 days, according to the maxAge value, the content is usable until January 6. According to the maxStale value, the content is usable until January 7. Therefore, the content gets revalidated on January 6. 如果缓存策略设置了maxAge = 5天，maxStale = 3天。根据 maxAge 值，该内容在1月6日前可用，根据maxStale 值，该内容在1月7日前可用。因此，该内容在1月6日重新验证。 If the cache policy sets maxAge = 5 days and maxStale = 1 day, according to the maxAge value, the content is usable until January 6. According to the maxStale value, the content is usable until January 5. Therefore, the content gets revalidated on January 5. 如果缓存策略设置maxAge值为5天，maxStale值为1天，根据maxAge 值，内容在1月6日前可用。根据maxStale值，内容在1月5日前可用，因此，内容在1月5日会被重新验证。 When the maximum age is less than the content expiration date, the more conservative caching behavior always prevails and the maximum staleness value has no effect. The following examples illustrate the effect of setting a maximum staleness (maxStale) value when the maximum age (maxAge) is reached before the content expires: 当最大 年龄小于内容过期日期时，总是存在更保守的缓存行为（即按照最大年龄缓存），并且最大过期值（maxStale）将不起作用。下面的例子证明了，当最大年龄（maxAge）在内容过期日期之前到来时，设置最大过期值（maxStale）的作用。 If the cache policy sets maxAge = 1 day and does not specify a value for maxStale value, the content is revalidated on January 2 even though it has not expired. 如果内容缓存策略设置maxAge = 1天并且没有指定maxStale值，内容在1月2日重新验证，即使还没过期。 If the cache policy sets maxAge = 1 day and maxStale = 3 days, the content is revalidated on January 2 to enforce the more conservative policy setting. 如果缓存策略设置了maxAge = 1天，maxStale = 3天，内容在1月2日重新验证来强制执行更保守的策略设置。 If the cache policy sets maxAge = 1 day and maxStale = 1 day, the content is revalidated on January 2. 如果缓存策略设置maxAge=1天，maxStale = 1天，内容在1月2日重新验证。]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>Cache Policy</category>
      </categories>
      <tags>
        <tag>浏览器</tag>
        <tag>缓存策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Symbolic Links|符号链接]]></title>
    <url>%2F2018%2F08%2F10%2F%E8%AE%A9Git%E6%94%AF%E6%8C%81Windows%20Symbolic%20link%2F</url>
    <content type="text"><![CDATA[原文：Symbolic links Short version: there is no exact equivalent for POSIX symlinks on Windows, and the closest thing is unavailable for non-admins by default. Therefore, symlink emulation support is switched off by default and needs to be configured by you, the user, via the core.symlinks=true config setting. 简介：Windows平台上没有与POSIX的symlinks完全对等的对象，最接近的一种类型（symbolic link）默认对非管理员用户是不可用的。所以，在安装Git-windows的时候默认关闭了支持 symlink 的选项，需要用户通过设置 core.symlinks=true 配置项来手动配置。 BackgroundStarting with Windows Vista, there is support for symbolic links. These are not your grandfather’s Unix symbolic links; They differ in quite a few ways: Windows从Vista开始支持symbolic links（符号链接）。这不是你爷爷的Unix上的symbolic links，他们非常不同： Symbolic links are only available on Windows Vista and later, most notably not on XP Symbolic links 只在Windows Vista 和更新的版本中可用，甚至XP中都不行。 You need the SeCreateSymbolicLinkPrivilege privilege, which is by default assigned only to Administrators and guarded by UAC, but can be assigned to other users or user groups (see below). 你需要SeCreateSymbolicLinkPrivilege 权限来创建Symbolic links，这个权限默认是只分配给Administrators，被UAC守护的，但是也可以分配给其他用户和用户组。 Symbolic links on remote filesystems are disabled by default (call fsutil behavior query SymlinkEvaluation to find out) 默认情况下禁用远程文件系统中的Symbolic links（调用 fsutil behavior query SymlinkEvaluation 可以看到） Symbolic links will only work on NTFS, not on FAT nor exFAT Symbolic links 只能作用在NTFS文件系统中，不能用于FAT和exFAT Windows’ symbolic links are typed: they need to know whether they point to a directory or to a file (for this reason, Git will update the type when it finds that it is wrong) Windows 的Symbolic links是有类型的：它们需要知道它们被指向的是目录还是文件（因此，Git在发现错误时会更新类型） Many programs do not understand symbolic links 许多程序不能识别symbolic links For those reasons, Git for Windows disables support for symbolic links by default (it will still read them when it encounters them). You can enable support via the core.symlinks config variable, e.g. when cloning: 因为这些原因，Git for Windows 默认禁用了对Symbolic links的支持（当遇到symbolic links时，Git仍然会读取它们）。你可以通过修改配置项core.symlinks的值来启用对Symbolic links的支持，例如在clone仓库的时候： 1git clone -c core.symlinks=true &lt;URL&gt; 创建 symbolic linksBy default, the ln -s command in Git Bash does not create symbolic links. Instead, it creates copies. 默认情况下，Git Bash中的 ln -s 命令不会创建symbolic links。相反，它会创建副本。 To create symbolic links (provided your account has permission to do so), use the built-in mklink command, like so: 要创建Symbolic links（如果你的账户有权限这样做），请使用Windows的cmd.exe内建的mklink 命令，像这样： 12mklink /d this-link-points-to c:\that-directory #创建目录类型的symbolic linkmklink this-link-points-to c:\that-file #创建文件类型的symbolic link 因为执行mklink需要管理员权限，所以在Windows命令行中执行mklink时需要用管理员权限启动命令行工具。]]></content>
      <categories>
        <category>翻译</category>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab Docker容器中SSH端口失效问题]]></title>
    <url>%2F2018%2F08%2F06%2FGitlab-docker-ssh-port-failure%2F</url>
    <content type="text"><![CDATA[在Gitlab配置文件/srv/gitlab/config/gitlab.rb中，将SSH协议的端口设置为8822了，但是在一些情况下会出现用SSH协议的Url执行网络同步操作时提示&quot;访问被拒，可能是权限问题&quot; 。 例如在我在服务器上sudo docker rm gitlab 之后再重新 sudo docker run之后就会重现以上问题。 排查过程如下： SSH连接远程连接到12.1服务器，查看SSH进程的运行状态 1sudo ps -aux | gerp sshd 得到如下图所示输出 可以看到12.1服务器上的sshd进程启动的配置文件是/assets/sshd_config ，而一般默认的配置路径是/etc/ssh/sshd_config，没找到是什么原因，不过有了这个线索就可以顺藤摸瓜了。 打开配置文件 1sudo vim /assets/sshd_config 发现是空的。 那就只能进到gitlab的docker container里面去看看了 12sudo docker exec -ti docker bashvim /assets/sshd_config 如图 发现这个配置文件里面设置的 ssh 端口号是 22。我们把它改成 8822 端口，:wq保存退出，service ssh restart 重启ssh服务，就解决问题了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>gitlab</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Docker 搭建私有NPM仓库]]></title>
    <url>%2F2018%2F08%2F03%2Fsinopia-private-npm-registry%2F</url>
    <content type="text"><![CDATA[关于 Docker 的使用不在本文之中，请自行参考其他文档。 经过测试， keyvanfatehi/sinopia 可用。 将 docker image 拉下来 1docker pull keyvanfatehi/sinopia 将 keyvanfatehi/sinopia 跑起来 1docker run --name sinopia -d -p 4873:4873 keyvanfatehi/sinopia docker运行在代码服务器上，此时通过 http://192.168.12.1:4873 可以访问私有NPM 仓库网页。 发布 JavaScript 类库添加示例类库项目 Hello 1234mkdir Hellocd Helloyarn init -y # npm init -ytouch index.js 在 index.js 内添加如下内容 12345let greeting = function(name) &#123; return &apos;Hello &apos; + name;&#125;module.exports = greeting; 这份代码导出了一个函数，已经可以发布和被依赖了。 npm adduser 初次使用这个私有仓库需要添加用户 1npm adduser --registry http://192.168.12.1:4873 npm publish 再把上面的代码发布上去 1npm publish . --registry http://192.168.12.1:4873 NPM 有自己的版本和发布策略，可以使用以下命令查看帮助文档 npm help version npm help publish 发布可能因为版本问题失败，追加谓词 –force 可强制发布但并非是常规操作。 发布后的管理页面图示 引用已发布的类库添加示例业务项目 myDemo 1234mkdir myDemocd myDemoyarn init -y # npm init -ytouch index.js 引用 Hello 1yarn add Hello --dev --registry http://192.168.12.1:4873 在 index.js 内添加如下内容 123456const Hello = require(&apos;Hello&apos;);(function() &#123; let greeting = Hello(&apos;Rattz&apos;); console.log(greeting);&#125;)(); 运行起来 12node index.jsHello Rattz 至此私有NPM仓库搭建、类库发布、依赖引用的部分已经完成。]]></content>
      <categories>
        <category>FE</category>
        <category>工程化</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>npm</tag>
        <tag>sinopia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用vim写代码]]></title>
    <url>%2F2018%2F07%2F26%2F%E7%94%A8vim%E5%86%99%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Vim is a great text editor which can be much more powerful then any GUI editor or IDE. It has its learning curve, but once you are used to it you’ll never want to switch to anything else. Here’s a quick tutorial on how to use and customize vim for working with code. BasicsFeel free to skip this first part if you are familiar with vim already. First, let’s get the hang of moving around. You can use arrow keys or h, j, k and l to move around. Holding Ctrl while moving will allow you to move between words (separated by spaces, tabulation, or line breaks), holding Shift allows you to do so with all punctuation characters including spaces and line breaks. Typing :147 will get you to the line 147, /foo will get you to the first occurrence of foo, / will repeat the last search. Hit i to enter insert mode and type in text. Hit Esc to go back. Key a does the same thing, but sets the cursor after the selected character. Hit Insert to switch between insert and replace modes. Typing in :w will write changes to a file, :q exits the editor, :e &lt;filename&gt; opens another file. Sometimes you need to do some copy-pasting: copy (yank) line with Y and paste it with p. You should know that vim allows you to prefix the majority of commands with a number: typing in 13Y will yank 13 lines, 40j will take you 40 lines down, etc. Command x will delete a character, dd will delete a whole line. Of course, you can prefix it with a number if you need to delete more then one line. :%s/foo/bar will find and replace the first occurrence of foo with bar, :%s/foo/bar/g will do so within the whole file. Splitting windows is very helpful tool: :split &lt;filename&gt; will split the window horizontally, :vsplit &lt;filename&gt;will do so vertically. Hit Ctrl + w, and then arrow key will select an active view, Ctrl + w, r will swap the views. Simply type :q to close the window. CustomizingHere’s example of a ~/.vimrc file, and the basic options necessary for editing code with vim. 1234567syntax onset tabstop=4set shiftwidth=4set smartindentset autoindentset expandtab Option syntax on enables syntax highlight, tabstop sets tab width, shiftwidth sets tab width for auto indentation, smartindent, autoindent enables indentation (smart indentation implies adding an extra indentation level after defining function, starting a loop, etc.), optional is expandtab, which tells vim to treat all tabs as spaces. If you are fan of limiting line width with n columns - add option colorcolumn=80, or (if your vim version is below 7.3) add the following lines: 12highlight OverLength ctermbg=red ctermfg=white guibg=#592929match OverLength /%80v.+/ That should highlight all text exceeding the 80 columns limit. Feel free to experiment with the options and start building up your own .vimrc. Using ctags with vimExuberant Ctags allows you to create “tags” for all your classes, functions, and variables to allow easily jumping between them. After installing ctags (package is also available in major repositories named ctags) generate tags: 12$ cd project/$ ctags -R * Open the main project file and move your cursor over to some function call. Hit Ctrl + ] to move to function definition, :tn will move you to the next definition for the function. Hitting Ctrl + t will return you back. Auto completion allows you not to bother with finishing words, variable or function names, and pretty much anything. That being said, Ctrl + n will finish the word for you or allow you to select the desired word from the list. This is just a basic example of what you can do with vim, for further info you can read vim documentation. I may be posting some more tips and tricks on using vim in future.]]></content>
      <categories>
        <category>工具</category>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN 到 Git，迁移的准备工作]]></title>
    <url>%2F2018%2F07%2F22%2FSVN-to-Git-prepping-for-the-migration%2F</url>
    <content type="text"><![CDATA[原文：SVN to Git - prepping for the migration 在Why Git中，我们讨论了Git可以帮助您的团队变得更加敏捷的多种方式。一旦你已经决定转换，下一步就是弄清楚如何将已有的开发工作流迁移到Git。 这篇文章解释了你在将团队从SVN转换为Git时可能会遭遇到的最大变化。在迁移过程中最重要的事情是要记住Git不是SVN。为了理解Git的全部潜力，请尽力拥抱版本控制的新思想。 For administrators Basic Git commands Git Migration Tools For developers For administrators 对管理员采用Git可能需要几天到几个月的时间，具体取决于团队的规模。本节介绍了在培训员工使用 Git 以及从 SVN 迁移仓库到 Git过程中工程经理需要注意的问题。 Basic Git commands 基本Git命令Git 曾因其陡峭的学习曲线儿闻名。然而 Git 维护者一直在稳步发布新的改进，例如合理的默认值和上下文帮助信息，这使得上手Git的过程更加轻松愉悦。 Atlassian 提供了全面的自学Git的系列教程,也包含了网络讨论和在线训练课程。所有这些应该满足了你的团队着手使用Git所需要的全部培训选择。为了让你能够顺利开始，这里有一些常见Git命令的列表： Git task Notes Git commands Tell Git who you are Configure the author name and email address to be used with your commits.Note that Git strips some characters (for example trailing periods) from user.name. git config –global user.name “Sam Smith” git config –global user.email sam@example.com Create a new local repository git init Check out a repository Create a working copy of a local repository: git clone /path/to/repository For a remote server, use: git clone username@host:/path/to/repository Add files Add one or more files to staging (index): git add git add * Commit Commit changes to head (but not yet to the remote repository): git commit -m “Commit message” Commit any files you’ve added with git add, and also commit any files you’ve changed since then: git commit -a Push Send changes to the master branch of your remote repository: git push origin master Status List the files you’ve changed and those you still need to add or commit: git status Connect to a remote repository If you haven’t connected your local repository to a remote server, add the server to be able to push to it: git remote add origin List all currently configured remote repositories: git remote -v Branches Create a new branch and switch to it: git checkout -b Switch from one branch to another: git checkout List all the branches in your repo, and also tell you what branch you’re currently in: git branch Delete the feature branch: git branch -d Push the branch to your remote repository, so others can use it: git push origin Push all branches to your remote repository: git push –all origin Delete a branch on your remote repository: git push origin : Update from the remote repository Fetch and merge changes on the remote server to your working directory: git pull To merge a different branch into your active branch: git merge View all the merge conflicts:View the conflicts against the base file:Preview changes, before merging: git diff git diff –base git diff After you have manually resolved any conflicts, you mark the changed file: git add Tags You can use tagging to mark a significant changeset, such as a release: git tag 1.0.0 CommitId is the leading characters of the changeset ID, up to 10, but must be unique. Get the ID using: git log Push all tags to remote repository: git push –tags origin Undo local changes If you mess up, you can replace the changes in your working tree with the last content in head:Changes already added to the index, as well as new files, will be kept. git checkout – Instead, to drop all your local changes and commits, fetch the latest history from the server and point your local master branch at it, do this: git fetch origin git reset –hard origin/master Search Search the working directory for foo(): git grep “foo()” Git Migration Tools Git 迁移工具有很多工具可以帮助你将已有的工程从SVN迁移到Git上，但是在你决定使用哪种工具之前，你需要弄清楚你希望如何迁移自己的代码。你有以下选项： 迁移整个代码库到Git，同时停用SVN。 不迁移现有工程到Git，但是新的工程使用Git。 迁移一些工程到Git，同时在其他工程上继续使用SVN。 在同一个工程上同步使用SVN 和 Git。 完整迁移到Git会降低开发流程的复杂性，因此这是首选方案。然而对那些拥有数十个开发团队和可能几百个工程项目的大公司来说，这也不一定可行。 你选择的迁移工具很大程度取决于你所选择的上面的策略。一些常见的 SVN-to-Git的迁移工具介绍如下。 Atlassian’s migration scripts Atlassian的迁移工具如果你对突然过渡感兴趣，那么Atlassian的迁移脚本对你来说是个不错的选择。这些脚本提供了将已有的SVN仓库可靠地转换为Git仓库所需要的全部工具。生成的native-Git历史记录可确保你在转换过程后无须处理任何SVN-to-Git的互操作性问题。 我们提供了完整的技术演练 ，使用这些脚本将您的整个代码库转换为Git仓库集合。演练解释了从提取SVN作者信息到重新组织非标准SVN存储库结构的所有内容。 SVN Mirror for Stash (now Bitbucket Server) pluginSVN Mirror for Stash 是一个Bitbucket Server 插件，可以让你轻松地维护兼容SVN和Git的混合代码库。和Atlassian的迁移脚本不同的是，SVN Mirror for Stash 允许你在同一个工程上同步使用 Git 和 SVN，只要你喜欢。 这个折中的解决方案对大公司来说是一个很棒的选择。它允许不同的团队在方便时迁移工作流，从而实现增量采用Git。 What is Git-SVN?git-svn工具是一个作用于本地Git仓库和 远程SVN仓库之间的接口。Git-svn让开发者可以在本地编写和向本地Git提交代码，然后将提交的内容用 SVN commit风格的操作提交到SVN中心仓库。这应该是暂时的，但是探索从SVN切换到Git的过程中很有帮助。 如果你不确定要切换到Git并希望让一些开发者探索Git命令而不全面迁移的情况下，git svn 是一个选择。它也非常适合培训阶段 - 而不是突然过渡，你的团队可以轻松地使用本地Git命令，不必担心协作的工作流。 要注意 git svn 应该只是你的迁移过程中的暂时阶段。因为它仍然依赖于SVN这个后端，它无法利用更加强大的Git功能，例如分支或者高级协作工作流程。 Rollout Strategies 推出策略迁移代码库只是应用Git的一个方面。你也应该考虑如何将Git介绍给代码库背后的人。外部顾问，内部Git冠军和飞行员团队是将开发团队迁移到Git的三个主要策略。 External Git Consultants 外部顾问Git顾问基本上可以象征性地收费为你处理迁移过程。这样做的优点是，你可以不用自己花时间学习就能创建一个完美适配你的团队的Git工作流。它还可以为您提供专家培训资源，如果你的团队正在学习Git。 Atlassian Experts 是从SVN迁移到Git的专家，也是寻找Git顾问的好资源。 另一方面，自己设计和实现一个Git工作流是团队理解新的开发流程的内部工作的好办法。这中方式可以避免当专家离开后，团队陷入黑暗的风险。 Internal Git Champions 内部Git冠军Git冠军是你公司内部对使用Git感到很高兴的开发者。利用冠军程序员对于拥有强大的开发者文化的公司和渴望成为早期Git使用者的热心程序员来说是一个很好的选择。 相比于外面的顾问，这种方式还有一个有点就是能够将Git专业知识保留在内部。然而需要大量的时间来训练Git冠军，而且需要承担选择错误的Git工作流或者错误的实现的风险。 Pilot Teams 飞行员团队第三种选择是用飞行员团队测试。如果你有一个小团队在一个相对独立的项目上工作，这种方式最好。将外部专家于飞行员团队内部的Git冠军组合甚至效果更佳。 这样做的好处是需要整个团队的支持，并且还限制了选择错误工作流的风险，因为它在设计新的开发流程的时候获得了整个团队的输入。换句话说，它确保确保比顾问或冠军在独自设计工作流程时更早的捕获到任何缺失的部分。 另一方面，利用飞行员团队意味着更多的初期训练和调试时间：并不是一个开发者在整理工作流，整个开发团队会在他们对新的工作流程感到舒适时暂时降低工作效率。 Security and Permissions 安全和权限访问控制是你需要从根本上重新思考如何管理代码库的Git的一个方面。 在SVN中，你通常将所有代码库存放在一个单独的中心仓库中，然后限制不同团队或者个人对文件夹的访问。在Git中，这 不再可能了：开发者必须能够签出整个仓库才能使用它。你通常不能签出一个仓库的子集，就像在SVN上时一样。权限只能被授予整个Git仓库。 这就意味着你必须将庞大的单片SVN仓库拆分成几个小的Git仓库。当我们将 Jira 开发团队迁移到Git上时，我们实际上在Atlassian遇到了这个第一手资料。 请记住，Git是被设计用于从几千个独立Linux开发者那里安全地集成代码贡献的，所以，它必定提供了一些方式来供你搭建你的团队需要的任何方式的访问控制。但是这可能需要重新审视您的构建周期。 如果你担心要维护新的Git仓库集合之间的依赖关系，你可能会发现Git之上的依赖关系管理层会很有帮助。依赖管理层将会有助于构建期，因为随着项目增长，你需要缓存来加速构建时间。可以在这篇有用的文章中找到每个技术栈的推荐依赖关系管理层工具列表：“Git和项目依赖关系” . For developers 开发者A Repository for Every Developer 每个开发人员的代码库作为开发者，你需要适应的最大的改变就是Git分布式的本质。不同于单个中心库，每一个开发者都有他们自己的整个代码库的副本。这极大的改变了你和程序员同事们协作的方式。 你可以使用 git clone 将整个Git仓库克隆到本地计算机上，而不是使用svn checkout从SVN库签出工作副本。 通过使用git push，git fetch 或者git pull 在仓库的分支之间移动来实现协作。共享通常在Git分支级别上完成，但也可以像SVN一样在提交级别上完成。但是在Git中，提交代表着项目的整个状态，而不是文件修改。你在SVN 和 Git中都可以使用分支，这里重要的区别是你可以用Git在本地完成提交，而不用共享你的工作。这能让你更自由进行实验，在离线状态下工作更有效，而且加速几乎所有版本控制相关的命令。 然而，理解这一点很重要，就是远程仓库并不是一个直接链接到其他人的仓库的。它只是一个标签，防止你每次与远程仓库交互的时候必须重新键入整个URL。你一直都是在一个独立的环境中工作的，直到你明确地从一个远程仓库pull或者push一个分支。 对SVN而言，另一个较大的调整就是“local” 和 “remote” 的概念。本地仓库在你的本地计算机上，所有其他的仓库都被认为是远程仓库。远程仓库的主要目的是为了让你的代码可以被团队的其他人访问到，因此并不会在其中（远程仓库）进行活动开发。本地仓库位于本地计算机上，你可以在其中进行所有软件开发。 Don’t Be Scared of Branching or Merging 不要还怕分支和合并在SVN中，你通过在你的工作副本中编辑文件来提交，然后运行 svn commit 来发送代码到中心库。然后其他人就可以通过svn update拉取这些修改到他们自己的工作副本中。SVN分支通常避讳用于项目的大型，长期运行方面，因为合并是一个危险的过程，有可能破坏项目结构。 Git的基本开发工作流程是非常不同的。Git开发围绕着分支和合并而不是受限于单一的开发线（例如，trunk/）。 当你想要在Git中开始处理任何事情时，你可以用 git checkout -b &lt;branch-name&gt; 创建并签出一个新的分支。这让你有了一条专有的开发支线，你可以在这条支线上写代码，不用担心影响到团队里的其他任何人。如果你破坏了一些东西无法修复，你只需要使用git branch -d &lt;branch-name&gt; 抛弃分支。如果你构建了一些有用的东西，就提交一个pull请求，要求将其合并到master分支中。 Potential Git Workflows 潜在的Git工作流当你选择Git工作流的时候，考虑你的团队需求很重要。一个简单的工作流可以最大化开发速度和灵活性，而更复杂的工作流程可以确保更高的一致性和对正在进行的工作的控制。 中心化工作流 提供与常见SVN流程最接近的匹配，所以这是一个很好的入门选项。 基于这个想法，使用功能分支工作流 可以让开发人员保持工作的独立性，并保护重要的共享分支。功能分支也构成了通过pull请求来管理更改的基础。 一个Gitflow 工作流 是功能分支的一个更加正式的，结构化的扩展，使其成为具有明确定义的发布周期的大型团队的理想选择。 最后，如果你需要最大限度地隔离和控制更改，或者让更多开发人员贡献于同一个存储库，请考虑forking 工作流 。 但是，如果你真的想要充分利用Git，作为专业团队，你应该考虑用功能分支工作流。这是一个真正分布式工作流，具有高度安全性，令人难以置信的可扩展性和典型的敏捷性。 Conclusion 总结将团队迁移到Git可能是一个艰巨的任务，但是也不一定是。这篇文章介绍了一些常用的选项来迁移你的代码库，将Git融入到你的开发团队，以及处理安全和权限问题。我们也介绍了开发者在迁移过程中应该为止做好准备的最大挑战。 希望你现在以及有了坚实的基础来将分布式开发引入你的公司，无论其规模或其当前的开发实践。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建一个Git仓库]]></title>
    <url>%2F2018%2F07%2F21%2FSetting-up-a-repository%2F</url>
    <content type="text"><![CDATA[git init git clone git config 本教程主要覆盖的几点如下: 初始化一个新的 Git repo 克隆一个已有的 Git Repo 向 Repo 提交一个文件的修改版本 对 Git Repo 进行一些远程协作的配置 常用的 Git 版本控制命令 在本章结束后，你应该就能够创建一个 Git Repo，使用 Git 常用的命令，提交修改的文件，查看工程的修改历史以及连接一个 Git 托管服务（如 Bitbucket） Git仓库是什么? Git 仓库 是你的工程的一个虚拟的存储，它允许你保存代码的不同版本，这样你就可以在需要的时候获取这些版本了。 初始化一个新的仓库：git init你将使用 git init 来创建一个新的 repo，git init 对新 repo 执行初始化设置的一次性命令。执行这个命令会在你的当前工作目录下创建一个名为.git 的子目录。同时也会创建一个新的master分支。 创建新的git仓库对现有工程进行版本控制这个示例假设你已经有了想要在里面创建git repo的工程文件夹。第一步是cd到这个工程文件夹的根目录下，然后执行git init命令。 12cd /path/to/your/existing/codegit init 将git init命令指向这个已有的工程目录也会执行和上面同样的初始化设置，作用于该项目目录。 1git init &lt;project directory&gt; 浏览git init页面查看git init的详细信息。 克隆一个已有的仓库：git clone如果项目已经搭建了一个中心仓库，clone命令就是最常用的获取本地开发克隆的命令。和git init一样，克隆通畅也是一次性指令。一旦获取到一个working copy，所有 version control 指令都是通过本地仓库管理的。 1git clone &lt;repo url&gt; git clone被用于创建一个copy或者远端仓库的clone。你可以给git clone传一个仓库的URL地址。Git支持几种不同的网络传输协议和对应的URL格式。示例中我们将会用到Git SSH协议。Git SSH URL遵循这样一个模板git@HOSTNAME:USERNAME/REPONAME.git 一个Git SSH URL的示例以及它与模板的对应关系如下： HOSTNAME: bitbucket.org USERNAME: rhyolight REPONAME: javascript-data-store 当命令执行后，将会开始拉取远端仓库master分支上的最新版本的文件，这些文件会被存放在一个新建的文件夹内。新建的文件夹会命名为上面示例中的REPONAME，即javascript-data-store 。这个文件夹包含了远端仓库的全部历史记录以及新创建的master分支。 更多git clone 的使用和支持的Git URL格式，请看git clone Page 保存修改到仓库：git add 和 git commit既然你已经克隆或者初始化了一个仓库，你就可以向它提交文件版本的修改了。下面的例子假设你已经在/path/to/project目录下创建了一个项目。步骤如下： 将当前目录指向 /path/to/project 新建一个文件 CommitTest.txt 包含内容”test content for git tutorial” 执行 git add 将 CommitTest.txt 添加到仓库暂存区（staging area） 提交修改，附带一个描述本次提交修改内容的message参数 1234cd /path/to/projectecho "test content for git tutorial" &gt;&gt; CommitTest.txtgit add CommitTest.txtgit commit -m "added CommitTest.txt to the repo" 执行示例后，你的repo就会将CommitTest.txt添加到历史中，并跟踪未来这个文件的更新。 这个示例介绍了两个git命令：add和commit。示例非常有限，更多关于这两个命令的内容在git add 和 git commit 。git add的另一个常用的案例是--all选项。执行 git add --all会将仓库中所有的修改未跟踪的文件添加到repo并更新repo的工作树（working tree）。 协作：git push理解这一点很重要，Git中working copy 的概念与你从SVN仓库中使用check out命令签出代码得到的working copy是非常不同的。与SVN不同，Git的所有working copy都于中心仓库一模一样，他们都是完整（full-fledged）的Git仓库（Git repositories ）。 这就造成了Git协作与SVN协作根本上的不同。SVN依赖与中心仓库与工作副本之间的关系，而Git的协作模型基于仓库与仓库之间的交互。在Git你是从一个仓库向另一个仓库推送或拉取，而不是向SVN的中心仓库迁入工作副本。 当然，没有任何事情阻止你给某个特定的Git Repo赋予特殊的意义。例如，简单地将某个Git Repo设定未中心库，就可以使用Git建立一个中心化的工作流。 裸仓库 vs. 克隆的仓库如果你用上一节 “Initializing a new Repository” 中的git clone来创建的本地仓库，那么你的仓库里就已经配置好了远程协作。git clone将会自动地为你的repo配置一个指向远端克隆来源的URL。这就意味着，一旦你修改了文件并执行了提交，你就可以将这些修改git push到远端仓库 如果你使用git init创建的一个新鲜的repo，那么你就没有这个可以push修改的远端repo。通常初始化一个新的repo的做法是先去Git托管那里创建一个repo。 服务将会提供一个Git URL，你可以将这个URL添加到你的本地仓库，然后git push到托管repo。一旦你用选择的Git托管服务创建了远端repo，那么你就需要更新你的本地仓库配置，建立映射。我们将会在下面 Configuration &amp; Set Up教程中探讨这个操作。 如果你更喜欢托管自己的远程仓库，则需要设置“裸仓库”。git init和git clone命令都接收 --bare参数。裸仓库最通常是用于创建远程的中心仓库。 配置和设置：git config一旦你设置了远端repo，你就需要在你的本地git config中添加一个远程repo的url，并为你的本地分支设置一个上游分支。git remote命令提供了这样的工具。 1git remote add &lt;remote_name&gt; &lt;remote_repo_url&gt; 这个命令会将位于&lt;remote_repo_url&gt;的远程仓库映射到你的本地仓库下的&lt;remote_name&gt;引用中（这里是指 remote_name 是远端仓库的一个标识或引用，相当于别名，这样在执行如git push，pull，fetch等其他指令时就可以轻松地指定远端仓库）。一点你建立了远端repo的映射，你就可以将本地分支推送给远端仓库。 1git push -u &lt;remote_name&gt; &lt;local_branch_name&gt; 这个命令将会将本地repo的&lt;local_branc_name&gt;分支push到未于&lt;remote_name&gt; 的远端repo。 跟深入的了解git remote，见Git remote page。 除了配置远端repo的URL，你还需要设置一些Git全局配置选项，例如username，email。git config命令可以帮助你用命令行配置你的Git安装程序（或者一个单独的仓库）。这个命令可以完成从用户信息到优先选项（preference），到仓库行为的一切定义。下面列出了几个常用的配置选项。 Git在三个单独的文件中保存了配置选项，允许你将配置选项的作用域设定为单个仓库（本地），用户（全局）或者整个系统（系统）： 本地: &lt;repo&gt;/.git/config – 具体仓库的设置. 全局: /.gitconfig – 具体用户的设置. 这是加 –global 标识的设置保存的位置. 系统: $(prefix)/etc/gitconfig – 系统级设置. 在当前仓库中定义用于所有提交操作的作者名称。通常我们会想要为当前用户的设置加上 --global 标识。 1git config --global user.name &lt;name&gt; 为当前用户定义所有提交的作者名称。 加上--local选项或者干脆不指定配置级别，将会为当前的本地仓库设置user.name 。 1git config --local user.email &lt;email&gt; 为当前用户定义用于所有提交的作者邮箱。 1git config --global alias.&lt;alias-name&gt; &lt;git-command&gt; 为Git命令创建一个快捷方式。这是一个很强大的功能，能够为常用的git命令创建自定义的快捷方式。简单的示例如下： 1git config --global alias.ci commit 创建一个 ci命令作为快捷方式来执行git commit。 学习更多的git别名访问 git config page. 1git config --system core.editor &lt;editor&gt; 为当前计算机上的所有用户指定用于git commit等命令的文本编辑器。&lt;edtor&gt; 参数是启动所需要的编辑器的命令（例如，vi）。这个示例用到了–system选项。–system选项将会将配置应用于整个系统，意味着这台机器上的所有用户和repo。更多关于配置级别的详细信息访问git config page。 1git config --global --edit 在文本编辑器中打开全局配置文件来进行手动设置。深入了解如何在文本编辑器中配置Git，访问 Git config page。 讨论所有配置选项都保存在一个纯文本文件中，所以git config命令真的是一个方便的命令行接口。通常你只需要在安装Git的时候设置一次，就可以在一台新的开发机器上开始工作了，为了适用于所有情况，你需要使用--global标识。一个重要的例外是作者邮箱地址。你可能需要为一些个人或者开源的仓库设置个人邮箱地址，为你的工作相关的仓库设置你的专业邮箱地址。 Git将配置保存在三个单独的文件中，允许你将配置选项设定在单个仓库，用户和整个系统的作用域里。 &lt;repo&gt;/.git/config – 具体仓库的配置。 ~/.gitconfig – 用户级配置，这里保存着那些附加了--global 选项的配置。 $(prefix)/etc/gitconfig – 系统级配置。 当这些文件中的选项冲突时，本地设置覆盖用户设置，用户设置会覆盖系统级设置。如果你打开任意一个配置文件 ，将会看到下面这些东西： 12345678910111213[user] name = John Smith email = john@example.com [alias] st = status co = checkout br = branch up = rebase ci = commit [core] editor = vim 你可以手动编辑这些值，这与git config的效果是一样的。 例子在你安装完Git之后的第一见想做的事情就是告诉Git你的名字和email，以及自定义一些默认的设置。一个经典的初始配置看起来差不多是下面这个样子： 告诉Git你是谁git config 1git --global user.name &quot;John Smith&quot; git config --global user.email john@example.com 选择你最喜欢的文本编辑器 1git config --global core.editor vim 添加一些类似SVN的别名 12345git config --global alias.st statusgit config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.up rebasegit config --global alias.ci commit 这样会创建一个上一节中讲到的~/.gitconfig 文件。深入的了解git config 请看git config page。 总结这里我们演示了如何使用 git init 和 git clone 创建一个 git 仓库。这篇教程可以被应用在管理软件源码和其他需要被版本话管理的内容。Git add, git commit, git push, 和 git remote 也被引入并在高级别上应用了. Read our guide about which code repository system is right for your team!]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器是如何工作的]]></title>
    <url>%2F2018%2F07%2F17%2FHow-Does-Browser-Work%2F</url>
    <content type="text"><![CDATA[Web browsers are probably the most widely used software. In this book I will explain how they work behind the scenes. We will see what happens when you type ‘google.com’ in the address bar until you see the Google page on the browser screen. 浏览器可能是使用最广泛的软件了。我将在这本书里解释浏览器后台是如何工作的。我们将会看到从你在浏览器的地址栏里敲下 ‘google.com’ 直到你看到浏览器窗口里显示出Google的网页之间发生了什么。 The browsers we will talk about 我们将要谈到的浏览器There are five major browsers used today - Internet Explorer, Firefox, Safari, Chrome and Opera.I will give examples from the open source browsers - Firefox,Chrome and Safari, which is partly open source.According to the W3C browser statistics, currently(October 2009), the usage share of Firefox, Safari and Chrome together is nearly 60%. So nowdays open source browsers are a substantial part of the browser business。 当今主流的浏览器一共有5种，分别是 Internet Explorer, FireFox, Safari, Chrome 以及 Opera。 我将从一些开源浏览器种给出示例，FireFox，Chrome，Safari这几种是部分开源的。 根据W3C 浏览器统计，目前（2009年10月），FireFox，Safari以及Chrome一共占据了浏览器将近60%的市场份额。 所以现在开源浏览器是浏览器业务的重要组成部分。 The browser’s main functionality 浏览器的主要功能The browser main functionality is to present the web resource you choose, by requesting it from the server and displaying it on the browser window. The resource format is usually HTML but also PDF, image and more. The location of the resource is specified by the user using a URI (Uniform resource Identifier). More on that in the network chapter. 浏览器的主要功能是通过向服务器发出请求并将结果显示在浏览器窗口的方式展示用户选择的网络资源。常见网络资源的格式是HTML，当然也有PDF，image等等。这些资源在网络中的位置是用户通过URI（Uniform resource Identifier）指定的。在网络的章节会详细说明。 The way the browser interprets and displays HTML files is specified in the HTML and CSS specifications. These specifications are maintained by the W3C (World Wide Web Consortium) organization, which is the standards organization for the web. 浏览器解释和显示HTML文件的方式是在HTML和CSS规范中指定的。这些规范是由W3C（World Wide Web Consortium)组织维护的，该组织是Web的标准组织。 The current version of HTML is 4 (http://www.w3.org/TR/html401/). Version 5 is in progress. The current CSS version is 2 (http://www.w3.org/TR/CSS2/) and version 3 is in progress. 当前HTML的版本是4(http://www.w3.org/TR/html401/)，第5版正在进行中。目前CSS版本是2(http://www.w3.org/TR/CSS2/) ，第3版正在进行中。 For years browsers conformed to only a part of the specifications and developed their own extensions. That caused serious compatibility issues for web authors. Today most of the browsers more or less conform to the specifications. 多年来，各家浏览器只遵循了部分规范，并各自开发这自己的扩展功能。这给Web作者造成了严重的兼容性问题。今天大多数浏览器都遵循了规范。 Browsers’ user interface have a lot in common with each other. Among the common user interface elements are: 浏览器用户界面彼此有很多共同之处，常见的用户元素如下： Address bar for inserting the URI 用于插入URI的地址栏 Back and forward buttons 前进后退按钮 Bookmarking options 书签选项 A refresh and stop buttons for refreshing and stopping the loading of current documents 用于刷新和停止加载当前文档的刷新和停止按钮。 Home button that gets you to your home page 主页按钮，可以访问您的主页。 Strangely enough, the browser’s user interface is not specified in any formal specification, it is just good practices shaped over years of experience and by browsers imitating each other. The HTML5 specification doesn’t define UI elements a browser must have, but lists some common elements. Among those are the address bar, status bar and tool bar. There are, of course, features unique to a specific browser like Firefox downloads manager. 奇怪的是，浏览器的用户界面并没有在任何规范中声明，这仅仅是多年实践经验和浏览器之间互相模仿的结果。HTML5规范没有定义浏览器必须有的UI元素，但是列出了一些常见的元素。其中包括地址栏，状态栏以及工具栏。当然还有像FireFox下载管理器这样的特定浏览器所特有的功能。 More on that in the user interface chapter. 更多内容会在用户界面的章节讲解。 The browser’s high level structure 浏览器的高级结构The browser’s main components are (1.1): 浏览器的主要组件有（1.1）： The user interface - this includes the address bar, back/forward button, bookmarking menu etc. Every part of the browser display except the main window where you see the requested page. 用户界面，即包括地址栏，前进/后退按钮，书签菜单等。除了您看到所请求的页面的主窗口之外，浏览器的每个部分都会显示。 The browser engine - the interface for querying and manipulating the rendering engine. 浏览器引擎，即用于查询和操纵渲染引擎的接口 The rendering engine - responsible for displaying the requested content. For example if the requested content is HTML, it is responsible for parsing the HTML and CSS and displaying the parsed content on the screen. 渲染引擎，负责显示请求的内容。例如如果请求的内容是HTML，渲染引擎就负责解析HTML和CSS并将解析的内容显示在屏幕上。 Networking - used for network calls, like HTTP requests. It has platform independent interface and underneath implementations for each platform. 网络组件，用于执行网络调用，如HTTP请求。它具有独立于平台的接口和每个平台的底层实现。 UI backend - used for drawing basic widgets like combo boxes and windows. It exposes a generic interface that is not platform specific. Underneath it uses the operating system user interface methods. UI后台，用于绘制类似于组合框和窗口这样的基本部件。它暴露出一些与平台无关的通用接口。在底层调用操作系统的用户界面方法。 JavaScript interpreter. Used to parse and execute the JavaScript code. JavaScript解释器，用于解析和执行JavaScript代码。 Data storage. This is a persistence layer. The browser needs to save all sorts of data on the hard disk, for examples, cookies. The new HTML specification (HTML5) defines ‘web database’ which is a complete (although light) database in the browser. 数据存储，这是一个持久层。浏览器需要将所有类型的数据保存到磁盘上，像cookie这种。新的HTML规范（HTML5)定义了 ‘web database’ ，这是一个完善（而轻量）的浏览器数据库。 Figure 1: Browser main components. 图1:浏览器主要组件 It is important to note that Chrome, unlike most browsers, holds multiple instances of the rendering engine - one for each tab,. Each tab is a separate process. 值得注意的是，Chrome与大多数浏览器不同，它会生成多个渲染引擎的实例，即一个标签页对应一个渲染引擎实例。每个标签也是一个单独的进程。 I will devote a chapter for each of these components. 我将为每一个组件设置一个章节。 Communication between the components 组件之间的通信Both Firefox and Chrome developed a special communication infrastructures. FireFox和Chrome都各自开发了特殊的通信基础框架。 They will be discussed in a special chapter. 我们将在特定章节中讨论。 The rendering engine 渲染引擎The responsibility of the rendering engine is well… Rendering, that is display of the requested contents on the browser screen. 渲染引擎的职责就是。。。渲染，就是说将用户请求的内容显示到浏览器屏幕上。 By default the rendering engine can display HTML and XML documents and images. It can display other types through a plug-in (a browser extension). An example is displaying PDF using a PDF viewer plug-in. We will talk about plug-ins and extensions in a special chapter. In this chapter we will focus on the main use case - displaying HTML and images that are formatted using CSS. 渲染引擎默认可以显示HTML和XML文档以及图片。它可以通过插件（浏览器插件）显示其他类型的资源。例如使用一个PDF阅读器插件在浏览器中显示PDF文档。我们将会在特定的章节谈到插件和扩展。这一章，我们重点介绍主要用例 -显示使用CSS格式化的HTML和图像。 Rendering engines 渲染引擎Our reference browsers - Firefox, Chrome and Safari are built upon two rendering engines. Firefox uses Gecko - a “home made” Mozilla rendering engine. Both Safari and Chrome use Webkit. 我们参考的浏览器-FireFox，Chrome和Safari都是基于两个渲染引擎。FireFox使用的是Gecko-由Mozilla公司自研的渲染引擎。Safari和Chrome都是用的Webkit。 Webkit is an open source rendering engine which started as an engine for the Linux platform and was modified by Apple to support Mac and Windows. See http://webkit.org/ for more details. Webkit是一个始于Linux平台的开源的渲染引擎，被Apple公司修改为支持Mac和Windows操作系统。 The main flow 主要工作流程The rendering engine will start getting the contents of the requested document from the networking layer. This will usually be done in 8K chunks. 渲染引擎将会从网络层接收用户请求到的文档的内容。通畅是按照8K大小的块进行的。 After that this is the basic flow of the rendering engine: 之后渲染引擎的主要工作流程如下： Figure 2:Rendering engine basic flow. 图2: 渲染引擎主要工作流 The rendering engine will start parsing the HTML document and turn the tags to DOM nodes in a tree called the “content tree”. It will parse the style data, both in external CSS files and in style elements. The styling information together with visual instructions in the HTML will be used to create another tree - the render tree. 渲染引擎将会解析HTML文档，并将HTML中的标签转化成一个被叫做“content tree（内容树）”的树上的DOM节点。它会解析样式数据，不管是来自外部CSS文件还是内部样式元素上的。所有的样式信息连同HTML中的可视化指令将被一起用于创建另一棵树-渲染树。 The render tree contains rectangles with visual attributes like color and dimensions. The rectangles are in the right order to be displayed on the screen. 渲染树包含了具有视觉属性（如颜色和尺寸）的矩形。这些矩形以正确的顺序排列，可以显示在屏幕上。 After the construction of the render tree it goes through a “layout“ process. This means giving each node the exact coordinates where it should appear on the screen. The next stage is painting - the render tree will be traversed and each node will be painted using the UI backend layer. 在创建完渲染树以后渲染引擎要经历一个布局的处理。这就意味着要给每个节点提供它们应该出现在屏幕上的确切座标。下一阶段是绘制 - 渲染树将会被遍历，并使用UI后端 层绘制每一个节点。 It’s important to understand that this is a gradual process. For better user experience, the rendering engine will try to display contents on the screen as soon as possible. It will not wait until all HTML is parsed before starting to build and layout the render tree. Parts of the content will be parsed and displayed, while the process continues with the rest of the contents that keeps coming from the network. 理解这是一个渐进的过程很重要。为了更佳的用户体验，渲染引擎将会尝试尽快在屏幕上显示内容。它不会等到所有HTML被解析就会开始构建和布局渲染树。部分内容会被解析和显示，同时继续处理来自网络的剩余内容。 Main flow examples Figure 3: Webkit main flow 图3:Webkit 主要工作流 Figure 4: Mozilla’s Gecko rendering engine main flow(3.6) 图4:Mozilla的Gecko渲染引擎的主要工作流 From figures 3 and 4 you can see that although Webkit and Gecko use slightly different terminology, the flow is basically the same. 从 图3 和 图4 中你可以看到，尽管 WebKit 和 Gecko 使用的术语略有不同，但是流程大体相同。 Gecko calls the tree of visually formatted elements - Frame tree. Each element is a frame. Webkit uses the term “Render Tree” and it consists of “Render Objects”. Webkit uses the term “layout” for the placing of elements, while Gecko calls it “Reflow”. “Attachment” is Webkit’s term for connecting DOM nodes and visual information to create the render tree. A minor non semantic difference is that Gecko has an extra layer between the HTML and the DOM tree. It is called the “content sink” and is a factory for making DOM elements. We will talk about each part of the flow: Gecko 将这个可视化格式的元素树称之为 - Frame tree（帧树）。每个元素都是一个frame（帧）。Webkit 用 “Render Tree” （渲染树）来称呼它，而且它包含的是 “Render Objects”（渲染对象）。Webkit 用 “layout” （布局）来放置元素，但是 Gecko 称之为 “Reflow”（渲染）。”Attachment” 是 Webkit 用于连接 DOM 节点与可视信息以创建渲染树的术语。一个小的非语义化差异是 Gecko 在 HTML 和 DOM 之间还有一个额外的层。被称作 “content sink”（内容接收器），是制造 DOM 元素的工厂。流程的各个部分我们都会谈到： Parsing - generalSince parsing is a very significant process within the rendering engine, we will go into it a little more deeply. Let’s begin with a little introduction about parsing.Parsing a document means translating it to some structure that makes sense - something the code can understand and use. The result of parsing is usually a tree of nodes that represent the structure of the document. It is called a parse tree or a syntax tree.Example - parsing the expression “2 + 3 - 1” could return this tree: Figure 5: mathematical expression tree node GrammarsParsing is based on the syntax rules the document obeys - the language or format it was written in. Every format you can parse must have deterministic grammar consisting of vocabulary and syntax rules. It is called a context free grammar. Human languages are not such languages and therefore cannot be parsed with conventional parsing techniques. Parser - Lexer combinationParsing can be separated into two sub processes - lexical analysis and syntax analysis. Lexical analysis is the process of breaking the input into tokens. Tokens are the language vocabulary - the collection of valid building blocks. In human language it will consist of all the words that appear in the dictionary for that language. Syntax analysis is the applying of the language syntax rules. Parsers usually divide the work between two components - the lexer(sometimes called tokenizer) that is responsible for breaking the input into valid tokens, and the parser that is responsible for constructing the parse tree by analyzing the document structure according to the language syntax rules. The lexer knows how to strip irrelevant characters like white spaces and line breaks. Figure 6: from source document to parse trees The parsing process is iterative. The parser will usually ask the lexer for a new token and try to match the token with one of the syntax rules. If a rule is matched, a node corresponding to the token will be added to the parse tree and the parser will ask for another token.If no rule matches, the parser will store the token internally, and keep asking for tokens until a rule matching all the internally stored tokens is found. If no rule is found then the parser will raise an exception. This means the document was not valid and contained syntax errors. TranslationMany times the parse tree is not the final product. Parsing is often used in translation - transforming the input document to another format. An example is compilation. The compiler that compiles a source code into machine code first parses it into a parse tree and then translates the tree into a machine code document. Figure 7: compilation flow Parsing exampleIn figure 5 we built a parse tree from a mathematical expression. Let’s try to define a simple mathematical language and see the parse process. Vocabulary: Our language can include integers, plus signs and minus signs. Syntax: The language syntax building blocks are expressions, terms and operations. Our language can include any number of expressions. A expression is defined as a “term” followed by an “operation” followed by another term An operation is a plus token or a minus token A term is an integer token or an expression Let’s analyze the input “2 + 3 - 1”.The first substring that matches a rule is “2”, according to rule #5 it is a term. The second match is “2 + 3” this matches the second rule - a term followed by an operation followed by another term. The next match will only be hit at the end of the input. “2 + 3 - 1” is an expression because we already know that ?2+3? is a term so we have a term followed by an operation followed by another term. “2 + + “will not match any rule and therefore is an invalid input. Formal definitions for vocabulary and syntaxVocabulary is usually expressed by regular expressions. For example our language will be defined as: 123INTEGER :0|[1-9][0-9]*PLUS : +MINUS: - As you see, integers are defined by a regular expression. Syntax is usually defined in a format called BNF. Our language will be defined as: 123expression := term operation termoperation := PLUS | MINUSterm := INTEGER | expression We said that a language can be parsed by regular parsers if its grammar is a context frees grammar. An intuitive definition of a context free grammar is a grammar that can be entirely expressed in BNF. For a formal definition see http://en.wikipedia.org/wiki/Context-free_grammar Types of parsersThere are two basic types of parsers - top down parsers and bottom up parsers. An intuitive explanation is that top down parsers see the high level structure of the syntax and try to match one of them. Bottom up parsers start with the input and gradually transform it into the syntax rules, starting from the low level rules until high level rules are met. Let’s see how the two types of parsers will parse our example: Top down parser will start from the higher level rule - it will identify “2 + 3” as an expression. It will then identify “2 + 3 - 1” as an expression (the process of identifying the expression evolves matching the other rules, but the start point is the highest level rule). The bottom up parser will scan the input until a rule is matched it will then replace the matching input with the rule. This will go on until the end of the input. The partly matched expression is placed on the parsers stack. Stack Input 2 + 3 - 1 term + 3 - 1 term operation 3 - 1 expression - 1 expression operation 1 expression This type of bottom up parser is called a shift reduce parser, because the input is shifted to the right (imagine a pointer pointing first at the input start and moving to the right) and is gradually reduced to syntax rules. Generating parsers automaticallyThere are tools that can generate a parser for you. They are called parser generators. You feed them with the grammar of your language - its vocabulary and syntax rules and they generate a working parser. Creating a parser requires a deep understanding of parsing and its not easy to create an optimized parser by hand, so parser generators can be very useful. Webkit uses two well known parser generators - Flex for creating a lexer and Bison for creating a parser (you might run into them with the names Lex and Yacc). Flex input is a file containing regular expression definitions of the tokens. Bison’s input is the language syntax rules in BNF format. HTML ParserThe job of the HTML parser is to parse the HTML markup into a parse tree. The HTML grammar definitionThe vocabulary and syntax of HTML are defined in specifications created by the w3c organization. The current version is HTML4 and work on HTML5 is in progress. Not a context free grammarAs we have seen in the parsing introduction, grammar syntax can be defined formally using formats like BNF.Unfortunately all the conventional parser topics do not apply to HTML (I didn’t bring them up just for fun - they will be used in parsing CSS and JavaScript). HTML cannot easily be defined by a context free grammar that parsers need.There is a formal format for defining HTML - DTD (Document Type Definition) - but it is not a context free grammar.This appears strange at first site - HTML is rather close to XML .There are lots of available XML parsers. There is an XML variation of HTML - XHTML - so what’s the big difference?The difference is that HTML approach is more “forgiving”, it lets you omit certain tags which are added implicitly, sometimes omit the start or end of tags etc. On the whole it’s a “soft” syntax, as opposed to XML’s stiff and demanding syntax.Apparently this seemingly small difference makes a world of a difference. On one hand this is the main reason why HTML is so popular - it forgives your mistakes and makes life easy for the web author. On the other hand, it makes it difficult to write a format grammar. So to summarize - HTML cannot be parsed easily, not by conventional parsers since its grammar is not a context free grammar, and not by XML parsers. HTML DTDHTML definition is in a DTD format. This format is used to define languages of the SGML family. The format contains definitions for all allowed elements, their attributes and hierarchy. As we saw earlier, the HTML DTD doesn’t form a context free grammar. There are a few variations of the DTD. The strict mode conforms solely to the specifications but other modes contain support for markup used by browsers in the past. The purpose is backwards compatibility with older content. The current strict DTD is here:http://www.w3.org/TR/html4/strict.dtd DOMThe output tree - the parse tree is a tree of DOM element and attribute nodes. DOM is short for Document Object Model. It is the object presentation of the HTML document and the interface of HTML elements to the outside world like JavaScript.The root of the tree is the “Document“ object. The DOM has an almost one to one relation to the markup. Example, this markup: 12345678&lt;html&gt; &lt;body&gt; &lt;p&gt; Hello World &lt;/p&gt; &lt;div&gt; &lt;img src="example.png"/&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; Would be translated to the following DOM tree: Figure 8: DOM tree of the example markup Like HTML, DOM is specified by the w3c organization. See http://www.w3.org/DOM/DOMTR. It is a generic specification for manipulating documents. A specific module describes HTML specific elements. The HTML definitions can be found here:http://www.w3.org/TR/2003/REC-DOM-Level-2-HTML-20030109/idl-definitions.html. When I say the tree contains DOM nodes, I mean the tree is constructed of elements that implement one of the DOM interfaces. Browsers use concrete implementations that have other attributes used by the browser internally. The parsing algorithmAs we saw in the previous sections, HTML cannot be parsed using the regular top down or bottom up parsers. The reasons are: The forgiving nature of the language. The fact that browsers have traditional error tolerance to support well known cases of invalid HTML. The parsing process in reentrant. Usually the source doesn’t change during parsing, but in HTML, script tags containing “document.write” can add extra tokens, so the parsing process actually modifies the input. Unable to use the regular parsing techniques, browsers create custom parsers for parsing HTML. The parsing algorithm is described in details by the HTML5 specification. The algorithm consists of two stages - tokenization and tree construction. Tokenization is the lexical analysis, parsing the input into tokens. Among HTML tokens are start tags, end tags, attribute names and attribute values. The tokenizer recognizes the token, gives it to the tree constructor and consumes the next character for recognizing the next token and so on until the end of the input. Figure 6: HTML parsing flow (taken from HTML5 spec) The tokenization algorithmThe algorithm’s output is an HTML token. The algorithm is expressed as a state machine. Each state consumes one or more characters of the input stream and updates the next state according to those characters. The decision is influenced by the current tokenization state and by the tree construction state. This means the same consumed character will yield different results for the correct next state, depending on the current state. The algorithm is too complex to bring fully, so let’s see a simple example that will help us understand the principal. Basic example - tokenizing the following HTML: 12345&lt;html&gt; &lt;body&gt; Hello world &lt;/body&gt;&lt;/html&gt; The initial state is the “Data state”. When the “&lt;” character is encountered, the state is changed to “Tag open state” . Consuming an “a-z” character causes creation of a “Start tag token”, the state is change to “Tag name state” . We stay in this state until the “&gt;” character is consumed. Each character is appended to the new token name. In our case the created token is an “html” token. When the “&gt;” tag is reached, the current token is emitted and the state changes back to the “Data state” . The ““ tag will be treated by the same steps. So far the “html” and “body” tags were emitted. We are now back at the “Data state” . Consuming the “H” character of “Hello world” will cause creation and emitting of a character token, this goes on until the “&lt;” of ““ is reached. We will emit a character token for each character of “Hello world”. We are now back at the “Tag open state” . Consuming the next input “/“ will cause creation of an “end tag token” and a move to the “Tag name state” . Again we stay in this state until we reach “&gt;”.Then the new tag token will be emitted and we go back to the “Data state” . The ““ input will be treated like the previous case. Figure 9: Tokenizing the example input Tree construction algorithmWhen the parser is created the Document object is created. During the tree construction stage the DOM tree with the Document in its root will be modified and elements will be added to it. Each node emitted by the tokenizer will be processed by the tree constructor. For each token the specification defines which DOM element is relevant to it and will be created for this token. Except of adding the element to the DOM tree it is also added to a stack of open elements. This stack is used to correct nesting mismatches and unclosed tags. The algorithm is also described as a state machine. The states are called “insertion modes”. Let’s see the tree construction process for the example input: 12345&lt;html&gt; &lt;body&gt; Hello world &lt;/body&gt;&lt;/html&gt; The input to the tree construction stage is a sequence of tokens from the tokenization stage The first mode is the “initial mode”. Receiving the html token will cause a move to the “before html” mode and a reprocessing of the token in that mode. This will cause a creation of the HTMLHtmlElement element and it will be appended to the root Document object.The state will be changed to “before head”. We receive the “body” token. An HTMLHeadElement will be created implicitly although we don’t have a “head” token and it will be added to the tree.We now move to the “in head” mode and then to “after head”. The body token is reprocessed, an HTMLBodyElement is created and inserted and the mode is transferred to “in body”.The character tokens of the “Hello world” string are now received. The first one will cause creation and insertion of a “Text” node and the other characters will be appended to that node.The receiving of the body end token will cause a transfer to “after body” mode. We will now receive the html end tag which will move us to “after after body” mode. Receiving the end of file token will end the parsing. Figure 10: tree construction of example html Actions when the parsing is finishedAt this stage the browser will mark the document as interactive and start parsing scripts that are in “deferred” mode - those who should be executed after the document is parsed. The document state will be then set to “complete” and a “load” event will be fired. You can see the full algorithms for tokenization and tree construction in HTML5 specification - http://www.w3.org/TR/html5/syntax.html#html-parser Browsers error toleranceYou never get an “Invalid Syntax” error on an HTML page. Browsers fix an invalid content and go on.Take this HTML for example: 123456789&lt;html&gt; &lt;mytag&gt; &lt;/mytag&gt; &lt;div&gt; &lt;p&gt; &lt;/div&gt; Really lousy HTML &lt;/p&gt;&lt;/html&gt; I must have violated about a million rules (“mytag” is not a standard tag, wrong nesting of the “p” and “div” elements and more) but the browser still shows it correctly and doesn’t complain. So a lot of the parser code is fixing the HTML author mistakes. The error handling is quite consistent in browsers but amazingly enough it’s not part of HTML current specification. Like bookmarking and back/forward buttons it’s just something that developed in browsers over the years. There are known invalid HTML constructs that repeat themselves in many sites and the browsers try to fix them in a conformant way with other browsers. The HTML5 specification does define some of these requirements. Webkit summarizes this nicely in the comment at the beginning of the HTML parser class 12345678910111213141516The parser parses tokenized input into the document, building up the document tree. If the document is well-formed, parsing it is straightforward. Unfortunately, we have to handle many HTML documents that are not well-formed, so the parser has to be tolerant about errors. We have to take care of at least the following error conditions: 1. The element being added is explicitly forbidden inside some outer tag.In this case we should close all tags up to the one, which forbids the element, and add it afterwards. 2. We are not allowed to add the element directly. It could be that the person writing the document forgot some tag in between (or that the tag in between is optional).This could be the case with the following tags: HTML HEAD BODY TBODY TR TD LI (did I forget any?). 3. We want to add a block element inside to an inline element. Close all inline elements up to the next higher block element. 4. If this doesn&apos;t help, close elements until we are allowed to add the element or ignore the tag. Let’s see some Webkit error tolerance examples: 1&lt;/br&gt; instead of &lt;br&gt; Some sites use instead of . In order to be compatible with IE and Firefox Webkit treats this like .The code: 1234if (t-&gt;isCloseTag(brTag) &amp;&amp; m_document-&gt;inCompatMode()) &#123; reportError(MalformedBRError); t-&gt;beginTag = true;&#125; Note - the error handling is internal - it won’t be presented to the user. A stray tableA stray table is a table inside another table contents but not inside a table cell.Like this example: 123456&lt;table&gt; &lt;table&gt; &lt;tr&gt;&lt;td&gt;inner table&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;tr&gt;&lt;td&gt;outer table&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; Webkit will change the hierarchy to two sibling tables: 123456&lt;table&gt; &lt;tr&gt;&lt;td&gt;outer table&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;table&gt; &lt;tr&gt;&lt;td&gt;inner table&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; The code: 12if (m_inStrayTableContent &amp;&amp; localName == tableTag) popBlock(tableTag); Webkit uses a stack for the current element contents - it will pop the inner table out of the outer table stack. The tables will now be siblings. Nested form elementsIn case the user puts a form inside another form, the second form is ignored.The code: 123if (!m_currentFormElement) &#123; m_currentFormElement = new HTMLFormElement(formTag, m_document);&#125; A too deep tag hierarchyThe comment speaks for itself. 12www.liceo.edu.mx is an example of a site that achieves a level of nesting of about 1500 tags, all from a bunch of &lt;b&gt;s.We will only allow at most 20 nested tags of the same type before just ignoring them all together. 123456789bool HTMLParser::allowNestedRedundantTag(const AtomicString&amp; tagName)&#123;unsigned i = 0;for (HTMLStackElem* curr = m_blockStack; i &lt; cMaxRedundantTagDepth &amp;&amp; curr &amp;&amp; curr-&gt;tagName == tagName; curr = curr-&gt;next, i++) &#123; &#125;return i != cMaxRedundantTagDepth;&#125; Misplaced html or body end tagsAgain - the comment speaks for itself. 123Support for really broken html.We never close the body tag, since some stupid web pages close it before the actual end of the doc.Let&apos;s rely on the end() call to close things. 12if (t-&gt;tagName == htmlTag || t-&gt;tagName == bodyTag ) return; So web authors beware - unless you want to appear as an example in a Webkit error tolerance code - write well formed HTML. CSS parsingRemember the parsing concepts in the introduction? Well, unlike HTML, CSS is a context free grammar and can be parsed using the types of parsers described in the introduction. In fact the CSS specification defines CSS lexical and syntax grammar (http://www.w3.org/TR/CSS2/grammar.html). Let’s see some examples:The lexical grammar (vocabulary) is defined by regular expressions for each token: 1234567comment \/\*[^*]*\*+([^/*][^*]*\*+)*\/num [0-9]+|[0-9]*"."[0-9]+nonascii [\200-\377]nmstart [_a-z]|&#123;nonascii&#125;|&#123;escape&#125;nmchar [_a-z0-9-]|&#123;nonascii&#125;|&#123;escape&#125;name &#123;nmchar&#125;+ident &#123;nmstart&#125;&#123;nmchar&#125;* “ident” is short for identifier, like a class name. “name” is an element id (that is referred by “#” ) The syntax grammar is described in BNF. 123456789101112131415161718192021222324ruleset : selector [ ',' S* selector ]* '&#123;' S* declaration [ ';' S* declaration ]* '&#125;' S* ;selector : simple_selector [ combinator selector | S+ [ combinator selector ] ] ;simple_selector : element_name [ HASH | class | attrib | pseudo ]* | [ HASH | class | attrib | pseudo ]+ ;class : '.' IDENT ;element_name : IDENT | '*' ;attrib : '[' S* IDENT S* [ [ '=' | INCLUDES | DASHMATCH ] S* [ IDENT | STRING ] S* ] ']' ;pseudo : ':' [ IDENT | FUNCTION S* [IDENT S*] ')' ] ; Explanation: A ruleset is this structure: 1234div.error , a.error &#123; color:red; font-weight:bold;&#125; div.error and a.error are selectors. The part inside the curly braces contains the rules that are applied by this ruleset. This structure is defined formally in this definition: 1234ruleset : selector [ ',' S* selector ]* '&#123;' S* declaration [ ';' S* declaration ]* '&#125;' S* ; This means a ruleset is a selector or optionally number of selectors separated by a coma and spaces (S stands for white space). A ruleset contains curly braces and inside them a declaration or optionally a number of declarations separated by a semicolon. “declaration” and “selector” will be defined in the following BNF definitions. Webkit CSS parserWebkit uses Flex and Bison parser generators to create parsers automatically from the CSS grammar files. As you recall from the parser introduction, Bison creates a bottom up shift reduce parser. Firefox uses a top down parser written manually. In both cases each CSS file is parsed into a StyleSheet object, each object contains CSS rules. The CSS rule objects contain selector and declaration objects and other object corresponding to CSS grammar. Figure 7: parsing CSS Parsing scriptsThis will be dealt with in the chapter about JavaScript The order of processing scripts and style sheetsScriptsThe model of the web is synchronous. Authors expect scripts to be parsed and executed immediately when the parser reaches a tag. The parsing of the document halts until the script was executed. If the script is external then the resource must be first fetched from the network - this is also done synchronously, the parsing halts until the resource is fetched. This was the model for many years and is also specified in HTML 4 and 5 specifications. Authors could mark the script as “defer” and thus it will not halt the document parsing and will execute after it is parsed. HTML5 adds an option to mark the script as asynchronous so it will be parsed and executed by a different thread. Speculative parsingBoth Webkit and Firefox do this optimization. While executing scripts, another thread parses the rest of the document and finds out what other resources need to be loaded from the network and loads them. These way resources can be loaded on parallel connections and the overall speed is better. Note - the speculative parser doesn’t modify the DOM tree and leaves that to the main parser, it only parses references to external resources like external scripts, style sheets and images. Style sheetsStyle sheets on the other hand have a different model. Conceptually it seems that since style sheets don’t change the DOM tree, there is no reason to wait for them and stop the document parsing. There is an issue, though, of scripts asking for style information during the document parsing stage. If the style is not loaded and parsed yet, the script will get wrong answers and apparently this caused lots of problems. It seems to be an edge case but is quite common. Firefox blocks all scripts when there is a style sheet that is still being loaded and parsed. Webkit blocks scripts only when they try to access for certain style properties that may be effected by unloaded style sheets. Render tree constructionWhile the DOM tree is being constructed, the browser constructs another tree, the render tree. This tree is of visual elements in the order in which they will be displayed. It is the visual representation of the document. The purpose of this tree is to enable painting the contents in their correct order. Firefox calls the elements in the render tree “frames”. Webkit uses the term renderer or render object.A renderer knows how to layout and paint itself and it’s children.Webkits RenderObject class, the base class of the renderers has the following definition: 12345678class RenderObject&#123; virtual void layout(); virtual void paint(PaintInfo); virtual void rect repaintRect(); Node* node; //the DOM node RenderStyle* style; // the computed style RenderLayer* containgLayer; //the containing z-index layer&#125; Each renderer represents a rectangular area usually corresponding to the node’s CSS box, as described by the CSS2 spec. It contains geometric information like width, height and position.The box type is affected by the “display” style attribute that is relevant for the node (see the style computation section). Here is Webkit code for deciding what type of renderer should be created for a DOM node, according to the display attribute. 123456789101112131415161718192021222324252627RenderObject* RenderObject::createObject(Node* node, RenderStyle* style)&#123; Document* doc = node-&gt;document(); RenderArena* arena = doc-&gt;renderArena(); ... RenderObject* o = 0; switch (style-&gt;display()) &#123; case NONE: break; case INLINE: o = new (arena) RenderInline(node); break; case BLOCK: o = new (arena) RenderBlock(node); break; case INLINE_BLOCK: o = new (arena) RenderBlock(node); break; case LIST_ITEM: o = new (arena) RenderListItem(node); break; ... &#125; return o;&#125; The element type is also considered, for example form controls and tables have special frames. In Webkit if an element wants to create a special renderer it will override the “createRenderer” method. The renderers points to style objects that contains the non geometric information. The render tree relation to the DOM treeThe renderers correspond to the DOM elements, but the relation is not one to one. Non visual DOM elements will not be inserted in the render tree. An example is the “head” element. Also elements whose display attribute was assigned to “none” will not appear in the tree (elements with “hidden” visibility attribute will appear in the tree). There are DOM elements which correspond to several visual objects. These are usually elements with complex structure that cannot be described by a single rectangle. For example, the “select” element has 3 renderers - one for the display area, one for the drop down list box and one for the button. Also when text is broken into multiple lines because the width is not sufficient for one line, the new lines will be added as extra renderers.Another example of several renderers is broken HTML. According to CSS spec an inline element must contain either only block element or only inline elements. In case of mixed content, anonymous block renderers will be created to wrap the inline elements. Some render objects correspond to a DOM node but not in the same place in the tree. Floats and absolutely positioned elements are out of flow, placed in a different place in the tree, and mapped to the real frame. A placeholder frame is where they should have been. Figure 11: The render tree and the corresponding DOM tree(3.1). The “Viewport” is the initial containing block. In Webkit it will be the “RenderView” object. The flow of constructing the treeIn Firefox, the presentation is registered as a listener for DOM updates. The presentation delegates frame creation to the “FrameConstructor” and the constructor resolves style(see style computation) and creates a frame. In Webkit the process of resolving the style and creating a renderer is called “attachment”. Every DOM node has an “attach” method. Attachment is synchronous, node insertion to the DOM tree calls the new node “attach” method. Processing the html and body tags results in the construction of the render tree root. The root render object corresponds to what the CSS spec calls the containing block - the top most block that contains all other blocks. Its dimensions are the viewport - the browser window display area dimensions. Firefox calls it ViewPortFrame and Webkit calls it RenderView. This is the render object that the document point to. The rest of the tree is constructed as a DOM nodes insertion.See CSS2 on this topic - http://www.w3.org/TR/CSS21/intro.html#processing-model Style ComputationBuilding the render tree requires calculating the visual properties of each render object. This is done by calculating the style properties of each element. The style includes style sheets of various origins, inline style elements and visual properties in the HTML (like the “bgcolor” property).The later is translated to matching CSS style properties. The origins of style sheets are the browser’s default style sheets, the style sheets provided by the page author and user style sheets - these are style sheets provides by the browser user (browsers let you define your favorite style. In Firefox, for instance, this is done by placing a style sheet in the “Firefox Profile” folder). Style computation brings up a few difficulties: Style data is a very large construct, holding the numerous style properties, this can cause memory problems. Finding the matching rules for each element can cause performance issues if it’s not optimized. Traversing the entire rule list for each element to find matches is a heavy task. Selectors can have complex structure that can cause the matching process to start on a seemingly promising path that is proven to be futile and another path has to be tried.For example - this compound selector: 123div div div div&#123;...&#125; Means the rules apply to a ““ who is the descendant of 3 divs.Suppose you want to check if the rule applies for a given ““ element. You choose a certain path up the tree for checking. You may need to traverse the node tree up just to find out there are only two divs and the rule does not apply. You then need to try other paths in the tree. Applying the rules involves quite complex cascade rules that define the hierarchy of the rules. Let’s see how the browsers face these issues: Sharing style dataWebkit nodes references style objects (RenderStyle) These objects can be shared by nodes in some conditions. The nodes are siblings or cousins and: The elements must be in the same mouse state (e.g., one can’t be in :hover while the other isn’t) Neither element should have an id The tag names should match The class attributes should match The set of mapped attributes must be identical The link states must match The focus states must match Neither element should be affected by attribute selectors, where affected is defined as having any selector match that uses an attribute selector in any position within the selector at all There must be no inline style attribute on the elements There must be no sibling selectors in use at all. WebCore simply throws a global switch when any sibling selector is encountered and disables style sharing for the entire document when they are present. This includes the + selector and selectors like :first-child and :last-child. Firefox rule treeFirefox has two extra trees for easier style computation - the rule tree and style context tree. Webkit also has style objects but they are not stored in a tree like the style context tree, only the DOM node points to its relevant style. Figure 13: Firefox style context tree(2.2) The style contexts contain end values. The values are computed by applying all the matching rules in the correct order and performing manipulations that transform them from logical to concrete values. For example - if the logical value is percentage of the screen it will be calculated and transformed to absolute units. The rule tree idea is really clever. It enables sharing these values between nodes to avoid computing them again. This also saves space. All the matched rules are stored in a tree. The bottom nodes in a path have higher priority. The tree contains all the paths for rule matches that were found. Storing the rules is done lazily. The tree isn’t calculated at the beginning for every node, but whenever a node style needs to be computed the computed paths are added to the tree. The idea is to see the tree paths as words in a lexicon. Lets say we already computed this rule tree: Suppose we need to match rules for another element in the content tree, and find out the matched rules (in the correct order) are B - E - I. We already have this path in the tree because we already computed path A - B - E - I - L. We will now have less work to do. Let’s see how the tree saves as work. Division into structsThe style contexts are divided into structs. Those structs contain style information for a certain category like border or color. All the properties in a struct are either inherited or non inherited. Inherited properties are properties that unless defined by the element, are inherited from its parent. Non inherited properties (called “reset” properties) use default values if not defined. The tree helps us by caching entire structs (containing the computed end values) in the tree. The idea is that if the bottom node didn’t supply a definition for a struct, a cached struct in an upper node can be used. Computing the style contexts using the rule treeWhen computing the style context for a certain element, we first compute a path in the rule tree or use an existing one. We then begin to apply the rules in the path to fill the structs in our new style context. We start at the bottom node of the path - the one with the highest precedence (usually the most specific selector) and traverse the tree up until our struct is full. If there is no specification for the struct in that rule node, then we can greatly optimize - we go up the tree until we find a node that specifies it fully and simply point to it - that’s the best optimization - the entire struct is shared. This saves computation of end values and memory.If we find partial definitions we go up the tree until the struct is filled. If we didn’t find any definitions for our struct, then in case the struct is an “inherited” type - we point to the struct of our parent in the context tree, in this case we also succeeded in sharing structs. If its a reset struct then default values will be used. If the most specific node does add values then we need to do some extra calculations for transforming it to actual values. We then cache the result in the tree node so it can be used by children. In case an element has a sibling or a brother that points to the same tree node then the entire style context can be shared between them. Lets see an example: Suppose we have this HTML 123456789101112&lt;html&gt; &lt;body&gt; &lt;div class="err" id="div1"&gt; &lt;p&gt; this is a &lt;span class="big"&gt; big error &lt;/span&gt; this is also a &lt;span class="big"&gt; very big error&lt;/span&gt; error &lt;/p&gt; &lt;/div&gt; &lt;div class="err" id="div2"&gt;another error&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; And the following rules: 1234561. div &#123;margin:5px;color:black&#125;2. .err &#123;color:red&#125;3. .big &#123;margin-top:3px&#125;4. div span &#123;margin-bottom:4px&#125;5. #div1 &#123;color:blue&#125;6. #div 2 &#123;color:green&#125; To simplify things let’s say we need to fill out only two structs - the color struct and the margin struct. The color struct contains only one member - the color The margin struct contains the four sides.The resulting rule tree will look like this (the nodes are marked with the node name : the # of rule they point at): Figure 12: The rule tree The context tree will look like this (node name : rule node they point to): Figure 13: The context tree Suppose we parse the HTML and get to the second tag. We need to create a style context for this node and fill its style structs.We will match the rules and discover that the matching rules for the are 1 ,2 and 6. This means there is already an existing path in the tree that our element can use and we just need to add another node to it for rule 6 (node F in the rule tree).We will create a style context and put it in the context tree. The new style context will point to node F in the rule tree. We now need to fill the style structs. We will begin by filling out the margin struct. Since the last rule node(F) doesn’t add to the margin struct, we can go up the tree until we find a cached struct computed in a previous node insertion and use it. We will find it on node B, which is the uppermost node that specified margin rules. We do have a definition for the color struct, so we can’t use a cached struct. Since color has one attribute we don’t need to go up the tree to fill other attributes. We will compute the end value (convert string to RGB etc) and cache the computed struct on this node. The work on the second element is even easier. We will match the rules and come to the conclusion that it points to rule G, like the previous span. Since we have siblings that point to the same node, we can share the entire style context and just point to the context of the previous span. For structs that contain rules that are inherited from the parent, caching is done on the context tree (the color property is actually inherited, but Firefox treats it as reset and caches it on the rule tree).For instance if we added rules for fonts in a paragraph: 1p &#123;font-family:Verdana;font size:10px;font-weight:bold&#125; Then the div element, which is a child of the paragraph in the context tree, could have shared the same font struct as his parent. This is if no font rules where specified for the “div”. In Webkit, who does not have a rule tree, the matched declarations are traversed 4 times. First non important high priority properties (properties that should be applied first because others depend on them - like display) are applied, than high priority important, then normal priority non important, then normal priority important rules. This means that properties that appear multiple times will be resolved according to the correct cascade order. The last wins. So to summarize - sharing the style objects(entirely or some of the structs inside them) solves issues 1 and 3. Firefox rule tree also helps in applying the properties in the correct order. Manipulating the rules for an easy matchThere are several sources for style rules: CSS rules, either in external style sheets or in style elements. 1p &#123;color:blue&#125; Inline style attributes like 1&lt;p style="color:blue" /&gt; HTML visual attributes (which are mapped to relevant style rules) 1&lt;p bgcolor="blue" /&gt; The last two are easily matched to the element since he owns the style attributes and HTML attributes can be mapped using the element as the key. As noted previously in issue #2, the CSS rule matching can be trickier. To solve the difficulty, the rules are manipulated for easier access. After parsing the style sheet, the rules are added one of several hash maps, according to the selector. There are maps by id, by class name, by tag name and a general map for anything that doesn’t fit into those categories. If the selector is an id, the rule will be added to the id map, if it’s a class it will be added to the class map etc.This manipulation makes it much easier to match rules. There is no need to look in every declaration - we can extract the relevant rules for an element from the maps. This optimization eliminates 95+% of the rules, so that they need not even be considered during the matching process(4.1). Let’s see for example the following style rules: 123p.error &#123;color:red&#125;#messageDiv &#123;height:50px&#125;div &#123;margin:5px&#125; The first rule will be inserted into the class map. The second into the id map and the third into the tag map. For the following HTML fragment; 12&lt;p class="error"&gt;an error occurred &lt;/p&gt;&lt;div id=" messageDiv"&gt;this is a message&lt;/div&gt; We will first try to find rules for the p element. The class map will contain an “error” key under which the rule for “p.error” is found. The div element will have relevant rules in the id map (the key is the id) and the tag map. So the only work left is finding out which of the rules that were extracted by the keys really match.For example if the rule for the div was 1table div &#123;margin:5px&#125; it will still be extracted from the tag map, because the key is the rightmost selector, but it would not match our div element, who does not have a table ancestor. Both Webkit and Firefox do this manipulation. Applying the rules in the correct cascade orderThe style object has properties corresponding to every visual attribute (all css attributes but more generic). If the property is not defined by any of the matched rules - then some properties can be inherited by the parent element style object. Other properties have default values. The problem begins when there is more than one definition - here comes the cascade order to solve the issue. Style sheet cascade orderA declaration for a style property can appear in several style sheets, and several times inside a style sheet. This means the order of applying the rules is very important. This is called the “cascade” order. According to CSS2 spec, the cascade order is (from low to high): Browser declarations User normal declarations Author normal declarations Author important declarations User important declarations The browser declarations are least important and the user overrides the author only if the declaration was marked as important. Declarations with the same order will be sorted by specifity and then the order they are specified. The HTML visual attributes are translated to matching CSS declarations . They are treated as author rules with low priority. SpecifityThe selector specifity is defined by the CSS2 specification as follows: count 1 if the declaration is from is a ‘style’ attribute rather than a rule with a selector, 0 otherwise (= a) count the number of ID attributes in the selector (= b) count the number of other attributes and pseudo-classes in the selector (= c) count the number of element names and pseudo-elements in the selector (= d) Concatenating the four numbers a-b-c-d (in a number system with a large base) gives the specificity. The number base you need to use is defined by the highest count you have in one of the categories.For example, if a=14 you can use hexadecimal base. In the unlikely case where a=17 you will need a 17 digits number base. The later situation can happen with a selector like this: html body div div p … (17 tags in your selector.. not very likely). Some examples: 1234567891011* &#123;&#125; /* a=0 b=0 c=0 d=0 -&gt; specificity = 0,0,0,0 */li &#123;&#125; /* a=0 b=0 c=0 d=1 -&gt; specificity = 0,0,0,1 */li:first-line &#123;&#125; /* a=0 b=0 c=0 d=2 -&gt; specificity = 0,0,0,2 */ul li &#123;&#125; /* a=0 b=0 c=0 d=2 -&gt; specificity = 0,0,0,2 */ul ol+li &#123;&#125; /* a=0 b=0 c=0 d=3 -&gt; specificity = 0,0,0,3 */h1 + *[rel=up]&#123;&#125; /* a=0 b=0 c=1 d=1 -&gt; specificity = 0,0,1,1 */ul ol li.red &#123;&#125; /* a=0 b=0 c=1 d=3 -&gt; specificity = 0,0,1,3 */li.red.level &#123;&#125; /* a=0 b=0 c=2 d=1 -&gt; specificity = 0,0,2,1 */#x34y &#123;&#125; /* a=0 b=1 c=0 d=0 -&gt; specificity = 0,1,0,0 */style="" /* a=1 b=0 c=0 d=0 -&gt; specificity = 1,0,0,0 */ Sorting the rulesAfter the rules are matched, they are sorted according to the cascade rules. Webkit uses bubble sort for small lists and merge sort for big ones. Webkit implements sorting by overriding the “&gt;” operator for the rules: 123456static bool operator &gt;(CSSRuleData&amp; r1, CSSRuleData&amp; r2)&#123; int spec1 = r1.selector()-&gt;specificity(); int spec2 = r2.selector()-&gt;specificity(); return (spec1 == spec2) : r1.position() &gt; r2.position() : spec1 &gt; spec2; &#125; Gradual processWebkit uses a flag that marks if all top level style sheets (including @imports) have been loaded. If the style is not fully loaded when attaching - place holders are used and it s marked in the document, and they will be recalculated once the style sheets were loaded. LayoutWhen the renderer is created and added to the tree, it does not have a position and size. Calculating these values is called layout or reflow. HTML uses a flow based layout model, meaning that most of the time it is possible to compute the geometry in a single pass. Elements later in the flow&#39;&#39; typically do not affect the geometry of elements that are earlierin the flow’’, so layout can proceed left-to-right, top-to-bottom through the document. There are exceptions - for example, HTML tables may require more than one pass (3.5). The coordinate system is relative to the root frame. Top and left coordinates are used. Layout is a recursive process. It begins at the root renderer, which corresponds to the element of the HTML document. Layout continues recursively through some or all of the frame hierarchy, computing geometric information for each renderer that requires it. The position of the root renderer is 0,0 and its dimensions is the viewport - the visible part of the browser window. All renderers have a “layout” or “reflow” method, each renderer invokes the layout method of its children that need layout. Dirty bit systemIn order not to do a full layout for every small change, browser use a “dirty bit” system. A renderer that is changed or added marks itself and its children as “dirty” - needing layout. There are two flags - “dirty” and “children are dirty”. Children are dirty means that although the renderer itself may be ok, it has at least one child that needs a layout. Global and incremental layoutLayout can be triggered on the entire render tree - this is “global” layout. This can happen as a result of: A global style change that affects all renderers, like a font size change. As a result of a screen being resized Layout can be incremental, only the dirty renderers will be layed out (this can cause some damage which will require extra layouts).Incremental layout is triggered (asynchronously) when renderers are dirty. For example when new renderers are appended to the render tree after extra content came from the network and was added to the DOM tree. Figure 20:Incremental layout - only dirty renderers and their children are layed out(3.6). Asynchronous and Synchronous layoutIncremental layout is done asynchronously. Firefox queues “reflow commands” for incremental layouts and a scheduler triggers batch execution of these commands. Webkit also has a timer that executes an incremental layout - the tree is traversed and “dirty” renderers are layout out. Scripts asking for style information, like “offsightHeight” can trigger incremental layout synchronously. Global layout will usually be triggered synchronously. Sometimes layout is triggered as a callback after an initial layout because some attributes , like the scrolling position changed. OptimizationsWhen a layout is triggered by a “resize” or a change in the renderer position(and not size), the renders sizes are taken from a cache and not recalculated.. In some cases - only a sub tree is modified and layout does not start from the root. This can happen in cases where the change is local and does not affect its surroundings - like text inserted into text fields (otherwise every keystroke would have triggered a layout starting from the root). The layout processThe layout usually has the following pattern: Parent renderer determines its own width. Parent goes over children and: Place the child renderer (sets its x and y). Calls child layout if needed(they are dirty or we are in a global layout or some other reason) - this calculates the child’s height. Parent uses children accumulative heights and the heights of the margins and paddings to set it own height - this will be used by the parent renderer’s parent. Sets its dirty bit to false. Firefox uses a “state” object(nsHTMLReflowState) as a parameter to layout (termed “reflow”). Among others the state includes the parents width.The output of Firefox layout is a “metrics” object(nsHTMLReflowMetrics). It will contain the renderer computed height. Width calculationThe renderer’s width is calculated using the container block’s width , the renderer’s style “width” property, the margins and borders.For example the width of the following div: 1&lt;div style="width:30%"/&gt; Would be calculated by Webkit as following(class RenderBox method calcWidth): The container width is the maximum of the containers availableWidth and 0. The availableWidth in this case is the contentWidth which is calculated as: 1clientWidth() - paddingLeft() - paddingRight() clientWidth and clientHeight represent the interior of an object excluding border and scrollbar. The elements width is the “width” style attribute. It will be calculated as an absolute value by computing the percentage of the container width. The horizontal borders and paddings are now added. So far this was the calculation of the “preferred width”. Now the minimum and maximum widths will be calculated. If the preferred width is higher then the maximum width - the maximum width is used. If it is lower then the minimum width (the smallest unbreakable unit) hen the minimum width is used. The values are cached, in case a layout is needed but the width does not change. Line BreakingWhen a renderer in the middle of layout decides it needs to break. It stops and propagates to its parent it needs to be broken. The parent will create the extra renderers and calls layout on them. PaintingIn the painting stage, the render tree is traversed and the renderers “paint” method is called to display their content on the screen. Painting uses the UI infrastructure component. More on that in the chapter about the UI. Global and IncrementalLike layout, painting can also be global - the entire tree is painted - or incremental. In incremental painting, some of the renderers change in a way that does not affect the entire tree. The changed renderer invalidates it’s rectangle on the screen. This causes the OS to see it as a “dirty region” and generate a “paint” event. The OS does it cleverly and coalesces several regions into one. In Chrome it is more complicated because the renderer is in a different process then the main process. Chrome simulates the OS behavior to some extent. The presentation listens to these events and delegates the message to the render root. The tree is traversed until the relevant renderer is reached. It will repaint itself (and usually its children). The painting orderCSS2 defines the order of the painting process - http://www.w3.org/TR/CSS21/zindex.html . This is actually the order in which the elements are stacked in the stacking contexts . This order affects painting since the stacks are painted from back to front. The stacking order of a block renderer is: background color background image border children outline Firefox display listFirefox goes over the render tree and builds a display list for the painted rectangular. It contains the renderers relevant for the rectangular, in the right painting order (backgrounds of the renderers, then borders etc). That way the tree needs to be traversed only once for a repaint instead of several times - painting all backgrounds, then all images , then all borders etc. Firefox optimizes the process by not adding elements that will be hidden, like elements completely beneath other opaque elements. Webkit rectangle storageBefore repainting, webkit saves the old rectangle as a bitmap. It then paints only the delta between the new and old rectangles. Dynamic changesThe browsers try to do the minimal possible actions in response to a change. So changes to an elements color will cause only repaint of the element. Changes to the element position will cause layout and repaint of the element, its children and possibly siblings. Adding a DOM node will cause layout and repaint of the node. Major changes, like increasing font size of the “html” element, will cause invalidation of caches, relyout and repaint of the entire tree. The rendering engine’s threadsThe rendering engine is single threaded. Almost everything, except network operations, happens in a single thread. In Firefox and safari this is the main thread of the browser. In chrome it’s the tab process main thread. Network operations can be performed by several parallel threads. The number of parallel connections is limited (usually 2 - 6 connections. Firefox 3, for example, uses 6). Event loopThe browser main thread is an event loop. Its an infinite loop that keeps the process alive. It waits for events (like layout and paint events) and processes them. This is Firefox code for the main event loop: 12while (!mExiting) NS_ProcessNextEvent(thread); CSS2 visual modelThe canvasAccording to CCS2 specification, the term canvas describes “the space where the formatting structure is rendered.” - where the browser paints the content.The canvas is infinite for each dimension of the space but browsers choose an initial width based on the dimensions of the viewport. According to http://www.w3.org/TR/CSS2/zindex.html, the canvas is transparent if contained within another, and given a browser defined color if it is not. CSS Box modelThe CSS box model describes the rectangular boxes that are generated for elements in the document tree and laid out according to the visual formatting model.Each box has a content area (e.g., text, an image, etc.) and optional surrounding padding, border, and margin areas. Figure 14:CSS2 box model Each node generates 0..n such boxes.All elements have a “display” property that determines their type of box that will be generated.Examples: 123block - generates a block box.inline - generates one or more inline boxes.none - no box is generated. The default is inline but the browser style sheet set other defaults. For example - the default display for “div” element is block. You can find a default style sheet example here http://www.w3.org/TR/CSS2/sample.html Positioning schemeThere are three schemes: Normal - the object is positioned according to its place in the document - this means its place in the render tree is like its place in the dom tree and layed out according to its box type and dimensions Float - the object is first layed out like normal flow, then moved as far left or right as possible Absolute - the object is put in the render tree differently than its place in the DOM tree The positioning scheme is set by the “position” property and the “float” attribute. static and relative cause a normal flow absolute and fixed cause an absolute positioning In static positioning no position is defined and the default positioning is used. In the other schemes, the author specifies the position - top,bottom,left,right. The way the box is layed out is determined by: Box type Box dimensions Positioning scheme External information - like images size and the size of the screen Box typesBlock box: forms a block - have their own rectangle on the browser window. Figure 15:Block box Inline box: does not have its own block, but is inside a containing block. Figure 15:Inine boxes Blocks are formatted vertically one after the other. Inlines are formatted horizontally. Figure 16:Block and Inline formatting Inline boxes are put inside lines or “line boxes”. The lines are at least as tall as the tallest box but can be taller, when the boxes are aligned “baseline” - meaning the bottom part of an element is aligned at a point of another box other then the bottom. In case the container width is not enough, the inlines will be put in several lines. This is usually what happens in a paragraph. Figure 17:Lines PositioningRelativeRelative positioning - positioned like usual and then moved by the required delta. Figure 18:Relative positioning FloatsA float box is shifted to the left or right of a line. The interesting feature is that the other boxes flow around it The HTML: 123&lt;p&gt;&lt;img style="float:right" src="images/image.gif" width="100" height="100"&gt;Lorem ipsum dolor sit amet, consectetuer...&lt;/p&gt; Will look like: Figure 19:Float Absolute and fixedThe layout is defined exactly regardless of the normal flow. The element does not participate in the normal flow. The dimensions are relative to the container. In fixed - the container is the view port. Figure 20:Fixed positioning Note - the fixed box will not move even when the document is scrolled! Layered representationIt is specified by the z-index CSS property. It represents the 3rd dimension of the box, its position along the “z axis”. The boxes are divided to stacks (called stacking contexts). In each stack the back elements will be painted first and the forward elements on top, closer to the user. In case of overlap the will hide the former element.The stacks are ordered according to the z-index property. Boxes with “z-index” property form a local stack. The viewport has the outer stack.Example: 12345678910111213141516&lt;STYLE type="text/css"&gt; div &#123; position: absolute; left: 2in; top: 2in; &#125; &lt;/STYLE&gt; &lt;P&gt; &lt;DIV style="z-index: 3;background-color:red; width: 1in; height: 1in; "&gt; &lt;/DIV&gt; &lt;DIV style="z-index: 1;background-color:green;width: 2in; height: 2in;"&gt; &lt;/DIV&gt; &lt;/p&gt; The result will be this: Figure 20:Fixed positioning Although the green div comes before the red one, and would have been painted before in the regular flow, the z-index property is higher, so it is more forward in the stack held by the root box. Resources Browser architecture Grosskurth, Alan. A Reference Architecture for Web Browsers. http://grosskurth.ca/papers/browser-refarch.pdf. Parsing Aho, Sethi, Ullman, Compilers: Principles, Techniques, and Tools (aka the “Dragon book”), Addison-Wesley, 1986 Rick Jelliffe. The Bold and the Beautiful: two new drafts for HTML 5. http://broadcast.oreilly.com/2009/05/the-bold-and-the-beautiful-two.html. Firefox L. David Baron, Faster HTML and CSS: Layout Engine Internals for Web Developers. http://dbaron.org/talks/2008-11-12-faster-html-and-css/slide-6.xhtml. L. David Baron, Faster HTML and CSS: Layout Engine Internals for Web Developers(Google tech talk video). http://www.youtube.com/watch?v=a2_6bGNZ7bA. L. David Baron, Mozilla’s Layout Engine. http://www.mozilla.org/newlayout/doc/layout-2006-07-12/slide-6.xhtml. L. David Baron, Mozilla Style System Documentation. http://www.mozilla.org/newlayout/doc/style-system.html. Chris Waterson, Notes on HTML Reflow. http://www.mozilla.org/newlayout/doc/reflow.html. Chris Waterson, Gecko Overview. http://www.mozilla.org/newlayout/doc/gecko-overview.htm. Alexander Larsson, The life of an HTML HTTP request. https://developer.mozilla.org/en/The_life_of_an_HTML_HTTP_request. Webkit David Hyatt, Implementing CSS(part 1). http://weblogs.mozillazine.org/hyatt/archives/cat_safari.html. David Hyatt, An Overview of WebCore. http://weblogs.mozillazine.org/hyatt/WebCore/chapter2.html. David Hyatt, WebCore Rendering. http://webkit.org/blog/114/. David Hyatt, The FOUC Problem. http://webkit.org/blog/66/the-fouc-problem/. W3C Specifications HTML 4.01 Specification. http://www.w3.org/TR/html4/. HTML5 Specification. http://dev.w3.org/html5/spec/Overview.html. Cascading Style Sheets Level 2 Revision 1 (CSS 2.1) Specification. http://www.w3.org/TR/CSS2/. Browsers build instructions Firefox. https://developer.mozilla.org/en/Build_Documentation Webkit. http://webkit.org/building/build.html]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>Browser</category>
      </categories>
      <tags>
        <tag>FE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[探索 JavaScript For-in 循环]]></title>
    <url>%2F2018%2F07%2F14%2FExplorer-JavaScript-For-in-loops%2F</url>
    <content type="text"><![CDATA[For-in 循环是对象属性迭代技术中唯一一项可以跨浏览器的。 关于使用 for-in 循环迭代数组的危险性以及何时使用 hasOwnPropert 过滤器的文章有很多，但是美中不足的是，关于这些普遍使用的语言结构的文章又出奇的不完整。本文尝试着填补一些空白，希望能对读者有所帮助。 基础ES 5 规范详细说明了 for-in 语句的两种不同的语法： 1. for (var variable in objectExpression) {statement}第一种是我们熟悉的格式。等号右边的 objectExpression 可以是任意可计算为 JavaScript 对象的表达式。如果我们在等号右边给定了原始类型，那么它将会被包装成对象。然后逐一迭代包装对象的属性。在每一次迭代中，对象属性的名称将被赋值给声明的迭代变量，如果存在表达式，会对表达式进行计算。 12345var myObj = &#123;a: 1, b: 2, c: 3&#125;, myKeys = [];for (var property in myObj) &#123; myKeys.push(property);&#125;myKeys; //['a','b','c']; 循环变量可以选择在 for-in 循环外部声明。只有当语句跨越多行并且语句为可选的情况下大括号才是必须的。因此下面的代码也是正确的，虽然看上去没什么意义，除非你就是对 myObj 的最后一个属性的名字感兴趣（稍后介绍更多关于迭代顺序的内容）。 123var myObj = &#123;a: 1, b: 2, c: 3&#125;, lastProperty;for (lastProperty in myObj);lastProperty; //"c"; 这里是另外一个例子，这一次 objectExpression 是一个原始类型： 12345678var str = "hello!", spreadOut = "";for (var index in str) &#123; (index &gt; 0) &amp;&amp; (spreadOut += " ") spreadOut += str[index];&#125;spreadOut; //"h e l l o !" 请注意，和所有属性名称一样，在上面的例子中的循环变量 index 实际上都是字符型，所以我们不能像上面那样简单地判断是否为真。稍后我们会一起看看为什么 String 类型与 Array 类型并不总是用于 for-in 循环的最佳选择。 2.for (LeftHandSideExpression in objectExpression) {statement}这种有趣的语法很少出现在文档中（MDC没有提及这种语法）。在 ECMAScript 术语中， leftHandSideExpression 是解析为属性引用的任意表达式（想象一下任何可以出现在赋值等号左侧的表达式）。在每一次迭代中，下一个属性的名字被赋值给 leftHandSideExpression 的计算结果。leftHandSideExpression 表达式在每次迭代时解析为不同引用是完全可行的，有时候这种方式非常有用，甚至更加优雅，例如，获取属性名称数组现在变得轻而易举。 123var myObj = &#123;a: 1, b: 2, c: 3&#125;, myKeys = [], i=0;for (myKeys[i++] in myObj);myKeys; //['a','b','c']; 哪些属性会被迭代？这需要了解一些JavaScript的内部原理。对象是属性的集合，每一个属性都有他们自己的一系列内部特性 。（我们可以将其看作抽象属性 - 他们被用于JavaScript引擎，但是用户不能直接访问这些特性。ECMAScript 使用[[property]]这样的格式来表示内部特性。 [[Enumerable]]是这些特性的其中之一。for-in 语句会迭代[[Enumerable]]值为true的每一个属性。包括对象原型链继承过来的可枚举属性。[[Enumerable]]值为false的属性，以及被覆盖的属性（例如，被子孙对象的同名属性覆盖的原型对象属性）不会被被迭代。 实际上这意味着,for-in循环会默认选择非影子，用户定义的（包括继承属性)但非内置的属性。例如，Ojbect 对象的内置方法（toString）不会被枚举。 这也意味着，如果你习惯于扩展内置对象的原型，那么你的自定义扩展属性将会被枚举出来： 123456var arr = ['a','b','c'], indexes = [];Array.prototype.each = function() &#123;/blah/&#125;;for (var index in arr) &#123; indexes.push(index);&#125;indexes; //["0", "1", "2", "each"] whoops! 一些框架（例如，Prototype.js 以及 Mootools）添加了很多自定义原型扩展，并且使用 for-in 循环来迭代Array和String类型，这些通常都被认为不是什么好主意。使用常规 for循环来迭代Array和String类型是一个好的替代方法。另外,ES5 定义了一些自定义的Array迭代器（forEach，map等等）。不幸的是，这些作为替代方案的迭代策略没有一个对常规对象有效 - 这也是为什么扩展Object.prototype被认为是非常坏的实践。 关于 “DontEnum” bugIE 9以下版本的浏览器会出现一些奇怪的迭代行为，因此内置影子属性（以及non-enumerable属性和ES3语法中的[[DontEnum]]属性）将不会被枚举出来。 1234567891011var obj = &#123;a: 2,//shadow a non-enumerabletoString: "I'm an obj"&#125;,result = [];for (result[result.length] in obj);result;//IE&lt;9 -&gt; ["a"]//Other browsers -&gt; ["a", "toString"] 我能阻止一些属性被迭代吗？答案是可以。有许多标准技术可以将不需要的属性成员从for-in循环中过滤出来。 1. Object.prototype.hasOwnProperty这个方法会调用属性的内置方法[[GetOwnProperty]]来确定给定的属性是不是直接定义在对象上的（而不是定义在原型链上某处的）。 1234567var arr = ['a','b','c'], indexes = [];Array.prototype.each = function() &#123;/*blah*/&#125;;for (var index in arr) &#123; if (arr.hasOwnProperty(index)) &#123; indexes.push(index);&#125;indexes; //["0", "1", "2"] JSLint 希望你总是将for-in语句的循环体用if语句包裹起来，即使是枚举一个常规对象的时候（不要紧，你可以简单地使用一个 &amp;&amp; 替代 if! 语句来充当断言条件）。 如果你是一个偏执狂，你或者其他人可能会覆盖 hasOwnProperty 地本地定义，那么你直接调用原型引用。 123456//snip... for (var index in arr) &#123; if (Object.prototype.hasOwnProperty.call(arr, index)) &#123; indexes.push(index); &#125; &#125; 2. Object.definePropertyES5 介绍了Object对象上的一些方法，允许使用自定义内部特性来定义属性（不支持FireFox&lt;4 和 IE&lt;9的版本）。 1234567var obj = &#123;&#125;;Object.defineProperty( obj, "value", &#123; value: true, writable: false, enumerable: true, configurable: true&#125;); 我们可以通过据此设置[[Enumerable]]特性的值来达到从for-in循环中隐藏一些自定义原型扩展的目的。 1234567891011var arr = ['a','b','c'], indexes = [];Object.defineProperty(Array.prototype, "each", &#123; value: function() &#123;/*blah*/&#125;, writable: false, enumerable: false, configurable: false&#125;);for (var index in arr) &#123; indexes.push(index);&#125;indexes; //["0", "1", "2"] 迭代顺序如何确定？ECMA 标准没有声明枚举顺序，但是非数组是对象的实际标准是按照被属性赋值的的顺序来进行枚举。 12345678910var obj = &#123;a: 1, b: 2, c: 3&#125;, result = [];obj.e; //referenced but not assignedobj.f = 'bar'; //1st assignmentobj.e = 4;obj.dd = 5;obj.f = 'foo'; //2nd assignmentfor (var prop in obj) &#123; result.push(prop);&#125;result.toString(); //"a,b,c,f,e,dd" 然而目前有许多问题你需要注意：在IE浏览器环境中删除属性在IE中删除一个属性，然后重新定义它，不会更新属性在迭代顺序中的位置，这与其他主流浏览器中观察到的行为相悖： 123456789var obj = &#123;a: 1, b: 2, c: 3&#125;, result = [];delete obj.b;obj.b = 4;for (var prop in obj) &#123; result.push(prop);&#125;result.toString(); //IE -&gt;"a,b,c"//Other browsers -&gt; "a,c,b" Chrome中数字命名的属性Chrome 浏览器会优先处理数字命名的key，以数字顺序而不是插入顺序遍历。 1234567var obj = &#123;3:'a', 2:'b', 'foo':'c', 1:'d'&#125;, result = [];for (var prop in obj) &#123; result.push(prop);&#125;result.toString();//Chrome -&amp;gt; "1,2,3,foo"//Other browsers -&amp;gt; "3,2,foo,1" 这个被记录下来的bug，有大量充满争议的评论在讨论这个bug是否应该被修复。我认为这个bug应该被修复。根据定义，常规对象的属性确定是无序的，并且ECMA也没有定义出一个标准 - 但 John Resig 和 Charles Kendrick 指出，ECMA标准的缺失不能成为借口 - 标准通常都是遵循实现的，而不是反过来 - 在这个例子中，chrome的处理是不合适的。 关于 in 操作符这个漂亮的 for-in 表达式使用内置的[[HasProperty]]方法来检查一个给定的对象中是否存在某个命名的属性： propertyNameExpression中的 objectExpression 它像下面的伪代码中这样工作： 123var name = //resolve [propertyNameExpression];var obj = //resolve [objectExpression];return obj.[[HasProperty]](name); 这里有一个使用方法的例子： 123456789101112var obj = &#123;a:1, b:2, c:undefined, d:4&#125;, aa = &#123;&#125;;'b' in obj; //true'c' in obj; //true ('undefined' but still exists)'e' in obj; //false (does not exist)delete obj.c;'c' in obj; //false (no longer exists)obj.e;'e' in obj; //false (referenced but not assigned)//resolving expressionsaa.o = obj;aa.a = 'a';aa.a in aa.o; //true 请注意，’c’是如何在 o.c 值为 undefined 的情况下从obj对象中返回true的。内部方法[[HasProperty]]将会对任意赋值的对象返回true，不管值为多少。这一点在区分那些被刻意赋值为undefined的属性与只是简单的不存在的属性的时候很有用。和 for-in 循环相似的是，in 操作符会搜索对象的原型链。与 for-in 循环不同的是，in 操作符不能区分可枚举属性与不可枚举属性： 1234var arr = [true,false,false];1 in arr; //true'slice' in arr; //true'toString' in arr; //true 这就是全部了，请随意在评论中提出建议，纰漏以及投诉。 –本文为译文 原文链接]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ike-scan扫描ipsec vpn服务端ike加密算法]]></title>
    <url>%2F2018%2F07%2F11%2Fike-scan%E6%89%AB%E6%8F%8F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%9A%84ike%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文：IPsec IKEv1 algorithms IPsec IKEv1 AlgorithmsWeak Legacy AlgorithmsAs mentioned in the README.md file, there is a general consensus that the following legacy algorithms are now considered weak or broken in regards to security and should be phased out and replaced with stronger algorithms: Encryption Algorithms : 3DES Blowfish Integrity Algorithms : MD5 SHA1 Diffie Hellman Groups : MODP768 MODP1024 MODP1536 Legacy algorithms that are considered weak or broken are regularly removed from the default set of allowed algorithms with newer releases of strongSwan and Libreswan. As of strongSwan 5.4.0 and Libreswan 3.20, the above algorithms (apart from SHA1 and MODP1536 for Libreswan which still includes them for backwards compatibility) have been or in some cases already been removed from the default set of allowed algorithms. If you are not sure, or want to confirm which IPsec IKEv1 phase 1 algorithms your VPN server server proposes, see the section on how to query the VPN server. If the VPN server is only proposing weak or broken algorithms, it is recommended that it be reconfigured to propose stronger algorithms, e.g. AES, SHA2 and MODP2048. Compatibility with VPN servers using weak legacy IPsec IKEv1 algorithmsNetworkManager-l2tp as of version 1.2.6 uses the Libreswan or strongSwan default set of allowed algorithms for phase 1 and phase 2 proposal negotiations. This means VPN servers that are using only legacy ciphers that strongSwan or Libreswan now consider broken will result in a failed connection, unless user specified algorithms to supplement or override the default set of algorithms are used for phase 1 and 2. Please see Example workaround for 3DES, SHA1 and MODP1024 broken algorithms section in the source code’s README.md file for an example workaround for the 3DES, SHA1 and MODP1024 broken algorithms that many L2TP/IPsec VPN servers are still proposing. Querying VPN server for its IKEv1 algorithm proposalsInstall the ike-scan package which most Linux distributions provide and then run the following script (with further details on how below the script) : 12345678910111213141516171819#!/bin/sh# Encryption algorithms: 3des=5, aes128=7/128, aes192=7/192, aes256=7/256ENCLIST=&quot;5 7/128 7/192 7/256&quot;# Hash algorithms: md5=1, sha1=2, sha256=5, sha384=6, sha512=7HASHLIST=&quot;1 2 5 6 7&quot;# Diffie-Hellman groups: 1, 2, 5, 14, 15, 19, 20, 21GROUPLIST=&quot;1 2 5 14 15 19 20 21&quot;# Authentication method: Preshared Key=1AUTH=1for ENC in $ENCLIST; do for HASH in $HASHLIST; do for GROUP in $GROUPLIST; do echo ike-scan --trans=$ENC,$HASH,$AUTH,$GROUP -M &quot;$@&quot; ike-scan --trans=$ENC,$HASH,$AUTH,$GROUP -M &quot;$@&quot; done donedone Let’s assume the above script has been copied and pasted to a file called ike-scan.sh, to run the script, issue something like the following on the command-line. Note: ike-scan needs UDP port 500 to be free, this can be achieved by stopping any running IPsec service (e.g. sudo ipsec stop). Replace 123.54.76.9 in the below with your VPN server and we’ll grep for SA (i.e. IPSec Security Association) which is the main thing we are interested in. 123sudo ipsec stopchmod a+rx ./ike-scan.shsudo ./ike-scan.sh 123.54.76.9 | grep SA It may take a few minutes for the script to run to completion and the output shall look something like: 12SA=(Enc=3DES Hash=SHA1 Auth=PSK Group=2:modp1024 LifeType=Seconds LifeDuration(4)=0x00007080)SA=(Enc=AES Hash=SHA1 Auth=PSK Group=14:modp2048 KeyLength=128 LifeType=Seconds LifeDuration(4)=0x00007080 From the above example script output, it would mean the following phase 1 &amp; 2 algorithms options could be set in the IPsec dialog box advanced options: Phase1 Algorithms: aes128-sha1-modp2048,3des-sha1-modp1024 Phase2 Algorithms: aes128-sha1,3des-md5 Overriding and not just supplementing the default cipherFor strongSwan, but not Libreswan, in some cases you may need to put an exclamation mark (!) at the end of the phase 1 or 2 settings to override and not just supplement the default ciphers. For example, some Cisco Unity VPN servers may require: Phase1 Algorithms: aes128-sha1-modp1024,3des-sha1-modp1024! Phase2 Algorithms: aes128-sha1,3des-md5 KDE Plasma &lt; 5.11 and legacy IPsec IKEv1 ciphersKDE Plasma-nm (&lt; version 5.11) front end for NetworkManager-l2tp doesn’t have the text boxes for user defined IPsec phase 1 and 2 algorithms, KDE bug# 380859. With Plasma 5.11 support has been added with commit# 1adb364. Current KDE Plasma &lt; 5.11 workarounds for IPsec phase 1 and 2 algorithms support include: backport the Plasma-nm patch for NetworkManager-l2tp 1.2.6 UI support. Use newer KDE backported packages for your linux distribution if available. “Layer 2 Tunneling Protocol (L2TP)” not showing upAfter installing NetworkManager-l2tp from either the source code or a prebuilt binary package, if “Layer 2 Tunnelling Protocol (L2TP)” does not show up when trying to add a VPN connection, try one of the following: sudo systemctl restart NetworkManager sudo service network-manager restart logout/login reboot Unable to save passwordLogout/login or reboot if the saved password isn’t being rembered and you are seeing something like the following in the journalctl output, : 12gnome-shell[2143]: JS LOG: Invalid VPN service type (cannot find authentication binary)... NetworkManager[1234]: &lt;error&gt; ... von-connection...: Failed to request VPN secrets #3: No agents were available for this request. This bug has been fixed with newer gnome-shell versions see GNOME bug# 773893 and Fedora gnome-shell bug# 1389107 Unable to create or edit a L2TP VPN connectionUnless you are using KDE (Plasma-nm) or the command-line (/usr/bin/nmcli), you will be using a GNOME based NetworkManager connection editor to create or edit VPN connections. If you are using pre-build binary packages, please ensure you have installed the NetworkManager-l2tp-gnome or network-manager-l2tp-gnome package which provides the necessary files for use with a GNOME based NetworkManager connection editor, otherwise you may see a variation of the following error : 12Could not load editor VPN plugin for &apos;org.freedesktop.NetworkManager.l2tp&apos;(missing plugin file &quot;/usr/lib64/NetworkManager/libnm-vpn-plugin-l2tp-editor.so&quot;). Issue with not stopping system xl2tpd serviceNetworkManager-l2tp starts its own instance of an xl2tpd process and if the system xl2tpd service is running, its own xl2tpd instance won’t be able to use UDP port 1701, so will use an ephemeral port (i.e. random high port). Although the use of an ephemeral port is described in “Securing L2TP using IPsec” RFC3193written by Microsoft and Cisco, there are some L2TP/IPsec servers and/or firewalls that will have issues with the use of an ephemeral port. Stopping the system xl2tpd service should free UDP port 1701 and on systemd based Linux distributions, the xl2tpd service can be stopped with the following: 1sudo systemctl stop xl2tpd If stopping the xl2tpd service fixes your VPN connection issue, you can disable the xl2tpd service from starting at boot time with : 1sudo systemctl disable xl2tpd Orphaned pppd processWith xl2tpd ≤ 1.3.6 (and in particular Linux distributions’ xl2tpd packages that don’t have xl2tpd commit# a193e02 backported which fixes a NULL-pointer deference bug), a pppd process will be left behind when tearing down a VPN connection because the parent xl2tpd process crashes before it has a chance at reaping the child pppd process. Ubuntu 16.04 and 16.10 have updated xl2tpd 1.3.6 packages that contains the fix (Ubuntu bug# 1677990). EAP: peer reports authentication failureIf you see EAP: peer reports authentication failure in the journalctl output (or elsewhere), then in the VPN connection’s PPP Settings dialog box, untick EAP in the authentication methods list. In some situations, the Use Point-to-Point encryption (MPPE) checkbox may also need to be ticked. DNS resolution issues.local hostname resolutionThere are unfortunately many Microsoft Windows networks that still use .local for internal hostnames that are resolved using unicast DNS even though Microsoft no longer recommends using .local. The use of unicast DNS for resolving .local has fallen into disfavor as mobile devices, printers and other devices supporting Zeroconf (aka Bonjour) have become increasingly common and they use multicast DNS (mDNS) for resolving hostnames ending in .local. In /etc/nsswitch.conf most Linux distributions put mdns4_minimal ahead of dns in the hosts:line which often looks something like: 1hosts: files mdns4_minimal [NOTFOUND=return] dns With the above nsswitch.conf hosts configuration, .local hostname resolution will return NOTFOUND if the hostname can not be found in mDNS. If you must VPN to a network using .local with unicast DNS and not too concerned about potential Zeroconf performance issues, one workaround is to to move dns before mdns4_minimal in the hosts: line. NetworkManager ≤ 1.6.2 and Systemd-resolved ignoring VPN server’s DNSNetworkManager 1.6 introduced support for the systemd-resolved local DNS forwarder backend. Some Linux distributions have switched from DNSMasq to Systemd-resolved for DNS. Unfortunately with NetworkManager ≤ 1.6.2 because the ppp interfaces isn’t “managed” by NetworkManager the VPN server’s DNS configuration is being ignored as described in GNOME bug# 779087. A workaround is to rollback to using DNSMasq: Edit /etc/NetworkManager/NetworkManager.conf and add the following line under the [main] section: 1dns=dnsmasq Backup the Systemd resolv.conf file (NetworkManager should create a new one): 1sudo mv /etc/resolv.conf /etc/resolv.conf.systemd Disable and stop the systemd-resolved service: 12sudo systemctl disable systemd-resolvedsudo systemctl stop systemd-resolved Restart network-manager 1sudo systemctl restart NetworkManager Ubuntu AppArmor issue with strongSwanFor Ubuntu versions &lt; 16.04, strongSwan’s charon and stroke daemons are prevented from performing correctly as child processes under NetworkManager-l2tp due to an AppArmor name space issue involving NetworkManager and the AppArmor profiles for charon and stroke. The simplest workaround is to disable the charon and stroke AppArmor profiles : 1234sudo ln -s /etc/apparmor.d/usr.lib.ipsec.charon /etc/apparmor.d/disable/sudo apparmor_parser -R /etc/apparmor.d/usr.lib.ipsec.charonsudo ln -s /etc/apparmor.d/usr.lib.ipsec.stroke /etc/apparmor.d/disable/sudo apparmor_parser -R /etc/apparmor.d/usr.lib.ipsec.stroke With Ubuntu 16.04 (Xenial Xerus), the issue is fixed by upgrading to strongswan 5.3.5-1ubuntu3.1 (or later). With Ubuntu 16.10 (Yakkety Yak), the issue is fixed by upgrading to strongswan 5.3.5-1ubuntu4.1 (or later). With Ubuntu 17.04 and later, there is no strongSwan AppArmor issue. openSUSE and SUSE Linux Enterprise ServerFor NetworkManager-l2tp to work, please ensure the Wicked service is disabled and NetworkManager service enable: 1234sudo systemctl stop wickedsudo systemctl disable wickedsudo systemctl enable NetworkManagersudo systemctl start NetworkManager]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>vpn</tag>
        <tag>ipsec</tag>
        <tag>ike-scan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Header Field Definitions]]></title>
    <url>%2F2018%2F07%2F02%2FHTTP%20Header%20Field%20Definitions%2F</url>
    <content type="text"><![CDATA[part of Hypertext Transfer Protocol – HTTP/1.1RFC 2616 Fielding, et al. 14 Header Field DefinitionsThis section defines the syntax and semantics of all standard HTTP/1.1 header fields. For entity-header fields, both sender and recipient refer to either the client or the server, depending on who sends and who receives the entity. 这部分定义了所有标准 HTTP/1.1 头部字段的语法和语义。对 实体头部字段，发送者和接收者指客户端或者服务器，取决于谁发送以及谁接收实体 14.1 AcceptThe Accept request-header field can be used to specify certain media types which are acceptable for the response. Accept headers can be used to indicate that the request is specifically limited to a small set of desired types, as in the case of a request for an in-line image. Accept 请求头可以被用于指定可接收的请求响应中的媒体类型。Accept 头部可以用于指示请求只限于特定一小组所需的类型，例如在在请求一个内嵌图片的时候可以指定图片的格式等。 12345678Accept = "Accept" ":" #( media-range [ accept-params ] )media-range = ( "*/*" | ( type "/" "*" ) | ( type "/" subtype ) ) *( ";" parameter )accept-params = ";" "q" "=" qvalue *( accept-extension )accept-extension = ";" token [ "=" ( token | quoted-string ) ] The asterisk ““ character is used to group media types into ranges, with “/“ indicating all media types and “type/“ indicating all subtypes of that type. The media-range MAY include media type parameters that are applicable to that range. Each media-range MAY be followed by one or more accept-params, beginning with the “q” parameter for indicating a relative quality factor. The first “q” parameter (if any) separates the media-range parameter(s) from the accept-params. Quality factors allow the user or user agent to indicate the relative degree of preference for that media-range, using the qvalue scale from 0 to 1 (section 3.9). The default value is q=1. 12345678Note: Use of the &quot;q&quot; parameter name to separate media typeparameters from Accept extension parameters is due to historicalpractice. Although this prevents any media type parameter named&quot;q&quot; from being used with a media range, such an event is believedto be unlikely given the lack of any &quot;q&quot; parameters in the IANAmedia type registry and the rare usage of any media typeparameters in Accept. Future media types are discouraged fromregistering any parameter named &quot;q&quot;. The example 1Accept: audio/*; q=0.2, audio/basic SHOULD be interpreted as “I prefer audio/basic, but send me any audio type if it is the best available after an 80% mark-down in quality.” If no Accept header field is present, then it is assumed that the client accepts all media types. If an Accept header field is present, and if the server cannot send a response which is acceptable according to the combined Accept field value, then the server SHOULD send a 406 (not acceptable) response. A more elaborate example is 12Accept: text/plain; q=0.5, text/html, text/x-dvi; q=0.8, text/x-c Verbally, this would be interpreted as “text/html and text/x-c are the preferred media types, but if they do not exist, then send the text/x-dvi entity, and if that does not exist, send the text/plain entity.” Media ranges can be overridden by more specific media ranges or specific media types. If more than one media range applies to a given type, the most specific reference has precedence. For example, 1Accept: text/*, text/html, text/html;level=1, */* have the following precedence: 12341) text/html;level=12) text/html3) text/*4) */* The media type quality factor associated with a given type is determined by finding the media range with the highest precedence which matches that type. For example, 12Accept: text/*;q=0.3, text/html;q=0.7, text/html;level=1, text/html;level=2;q=0.4, */*;q=0.5 would cause the following values to be associated: 12345678910 text/html;level=1 = 1 text/html = 0.7 text/plain = 0.3 image/jpeg = 0.5 text/html;level=2 = 0.4 text/html;level=3 = 0.7Note: A user agent might be provided with a default set of qualityvalues for certain media ranges. However, unless the user agent isa closed system which cannot interact with other rendering agents,this default set ought to be configurable by the user. 14.2 Accept-CharsetThe Accept-Charset request-header field can be used to indicate what character sets are acceptable for the response. This field allows clients capable of understanding more comprehensive or special- purpose character sets to signal that capability to a server which is capable of representing documents in those character sets. 12Accept-Charset = &quot;Accept-Charset&quot; &quot;:&quot; 1#( ( charset | &quot;*&quot; )[ &quot;;&quot; &quot;q&quot; &quot;=&quot; qvalue ] ) Character set values are described in section 3.4. Each charset MAY be given an associated quality value which represents the user’s preference for that charset. The default value is q=1. An example is 1Accept-Charset: iso-8859-5, unicode-1-1;q=0.8 The special value ““, if present in the Accept-Charset field, matches every character set (including ISO-8859-1) which is not mentioned elsewhere in the Accept-Charset field. If no ““ is present in an Accept-Charset field, then all character sets not explicitly mentioned get a quality value of 0, except for ISO-8859-1, which gets a quality value of 1 if not explicitly mentioned. If no Accept-Charset header is present, the default is that any character set is acceptable. If an Accept-Charset header is present, and if the server cannot send a response which is acceptable according to the Accept-Charset header, then the server SHOULD send an error response with the 406 (not acceptable) status code, though the sending of an unacceptable response is also allowed. 14.3 Accept-EncodingThe Accept-Encoding request-header field is similar to Accept, but restricts the content-codings (section 3.5) that are acceptable in the response. 123Accept-Encoding = &quot;Accept-Encoding&quot; &quot;:&quot; 1#( codings [ &quot;;&quot; &quot;q&quot; &quot;=&quot; qvalue ] )codings = ( content-coding | &quot;*&quot; ) Examples of its use are: 12345Accept-Encoding: compress, gzipAccept-Encoding:Accept-Encoding: *Accept-Encoding: compress;q=0.5, gzip;q=1.0Accept-Encoding: gzip;q=1.0, identity; q=0.5, *;q=0 A server tests whether a content-coding is acceptable, according to an Accept-Encoding field, using these rules: 1234567891011121314151. If the content-coding is one of the content-codings listed in the Accept-Encoding field, then it is acceptable, unless it is accompanied by a qvalue of 0. (As defined in section 3.9, a qvalue of 0 means &quot;not acceptable.&quot;)2. The special &quot;*&quot; symbol in an Accept-Encoding field matches any available content-coding not explicitly listed in the header field.3. If multiple content-codings are acceptable, then the acceptable content-coding with the highest non-zero qvalue is preferred.4. The &quot;identity&quot; content-coding is always acceptable, unless specifically refused because the Accept-Encoding field includes &quot;identity;q=0&quot;, or because the field includes &quot;*;q=0&quot; and does not explicitly include the &quot;identity&quot; content-coding. If the Accept-Encoding field-value is empty, then only the &quot;identity&quot; encoding is acceptable. If an Accept-Encoding field is present in a request, and if the server cannot send a response which is acceptable according to the Accept-Encoding header, then the server SHOULD send an error response with the 406 (Not Acceptable) status code. If no Accept-Encoding field is present in a request, the server MAY assume that the client will accept any content coding. In this case, if “identity” is one of the available content-codings, then the server SHOULD use the “identity” content-coding, unless it has additional information that a different content-coding is meaningful to the client. 12345678910Note: If the request does not include an Accept-Encoding field,and if the &quot;identity&quot; content-coding is unavailable, thencontent-codings commonly understood by HTTP/1.0 clients (i.e.,&quot;gzip&quot; and &quot;compress&quot;) are preferred; some older clientsimproperly display messages sent with other content-codings. Theserver might also make this decision based on information aboutthe particular user-agent or client.Note: Most HTTP/1.0 applications do not recognize or obey qvaluesassociated with content-codings. This means that qvalues will notwork and are not permitted with x-gzip or x-compress. 14.4 Accept-LanguageThe Accept-Language request-header field is similar to Accept, but restricts the set of natural languages that are preferred as a response to the request. Language tags are defined in section 3.10. 123Accept-Language = &quot;Accept-Language&quot; &quot;:&quot; 1#( language-range [ &quot;;&quot; &quot;q&quot; &quot;=&quot; qvalue ] )language-range = ( ( 1*8ALPHA *( &quot;-&quot; 1*8ALPHA ) ) | &quot;*&quot; ) Each language-range MAY be given an associated quality value which represents an estimate of the user’s preference for the languages specified by that range. The quality value defaults to “q=1”. For example, 1Accept-Language: da, en-gb;q=0.8, en;q=0.7 would mean: “I prefer Danish, but will accept British English and other types of English.” A language-range matches a language-tag if it exactly equals the tag, or if it exactly equals a prefix of the tag such that the first tag character following the prefix is “-“. The special range “*”, if present in the Accept-Language field, matches every tag not matched by any other range present in the Accept-Language field. 123456Note: This use of a prefix matching rule does not imply thatlanguage tags are assigned to languages in such a way that it isalways true that if a user understands a language with a certaintag, then this user will also understand all languages with tagsfor which this tag is a prefix. The prefix rule simply allows theuse of prefix tags if this is the case. The language quality factor assigned to a language-tag by the Accept-Language field is the quality value of the longest language- range in the field that matches the language-tag. If no language- range in the field matches the tag, the language quality factor assigned is 0. If no Accept-Language header is present in the request, the server SHOULD assume that all languages are equally acceptable. If an Accept-Language header is present, then all languages which are assigned a quality factor greater than 0 are acceptable. It might be contrary to the privacy expectations of the user to send an Accept-Language header with the complete linguistic preferences of the user in every request. For a discussion of this issue, see section 15.1.4. As intelligibility is highly dependent on the individual user, it is recommended that client applications make the choice of linguistic preference available to the user. If the choice is not made available, then the Accept-Language header field MUST NOT be given in the request. 12345678Note: When making the choice of linguistic preference available tothe user, we remind implementors of the fact that users are notfamiliar with the details of language matching as described above,and should provide appropriate guidance. As an example, usersmight assume that on selecting &quot;en-gb&quot;, they will be served anykind of English document if British English is not available. Auser agent might suggest in such a case to add &quot;en&quot; to get thebest matching behavior. 14.5 Accept-Ranges12345678910111213The Accept-Ranges response-header field allows the server toindicate its acceptance of range requests for a resource: Accept-Ranges = &quot;Accept-Ranges&quot; &quot;:&quot; acceptable-ranges acceptable-ranges = 1#range-unit | &quot;none&quot;Origin servers that accept byte-range requests MAY send Accept-Ranges: bytesbut are not required to do so. Clients MAY generate byte-rangerequests without having received this header for the resourceinvolved. Range units are defined in section 3.12.Servers that do not accept any kind of range request for aresource MAY send Accept-Ranges: noneto advise the client not to attempt a range request. 14.6 Age12345678910111213141516The Age response-header field conveys the sender&apos;s estimate of theamount of time since the response (or its revalidation) wasgenerated at the origin server. A cached response is &quot;fresh&quot; ifits age does not exceed its freshness lifetime. Age values arecalculated as specified in section 13.2.3. Age = &quot;Age&quot; &quot;:&quot; age-value age-value = delta-secondsAge values are non-negative decimal integers, representing time inseconds.If a cache receives a value larger than the largest positiveinteger it can represent, or if any of its age calculationsoverflows, it MUST transmit an Age header with a value of2147483648 (2^31). An HTTP/1.1 server that includes a cache MUSTinclude an Age header field in every response generated from itsown cache. Caches SHOULD use an arithmetic type of at least 31bits of range. 14.7 Allow1234567891011121314151617181920The Allow entity-header field lists the set of methods supportedby the resource identified by the Request-URI. The purpose of thisfield is strictly to inform the recipient of valid methodsassociated with the resource. An Allow header field MUST bepresent in a 405 (Method Not Allowed) response. Allow = &quot;Allow&quot; &quot;:&quot; #MethodExample of use: Allow: GET, HEAD, PUTThis field cannot prevent a client from trying other methods.However, the indications given by the Allow header field valueSHOULD be followed. The actual set of allowed methods is definedby the origin server at the time of each request.The Allow header field MAY be provided with a PUT request torecommend the methods to be supported by the new or modifiedresource. The server is not required to support these methods andSHOULD include an Allow header in the response giving the actualsupported methods.A proxy MUST NOT modify the Allow header field even if it does notunderstand all the methods specified, since the user agent mighthave other means of communicating with the origin server. 14.8 Authorization1234567891011121314151617181920212223242526272829303132333435A user agent that wishes to authenticate itself with a server--usually, but not necessarily, after receiving a 401 response--doesso by including an Authorization request-header field with therequest. The Authorization field value consists of credentialscontaining the authentication information of the user agent forthe realm of the resource being requested. Authorization = &quot;Authorization&quot; &quot;:&quot; credentialsHTTP access authentication is described in &quot;HTTP Authentication:Basic and Digest Access Authentication&quot; [43]. If a request isauthenticated and a realm specified, the same credentials SHOULDbe valid for all other requests within this realm (assuming thatthe authentication scheme itself does not require otherwise, suchas credentials that vary according to a challenge value or usingsynchronized clocks).When a shared cache (see section 13.7) receives a requestcontaining an Authorization field, it MUST NOT return thecorresponding response as a reply to any other request, unless oneof the following specific exceptions holds:1. If the response includes the &quot;s-maxage&quot; cache-control directive, the cache MAY use that response in replying to a subsequent request. But (if the specified maximum age has passed) a proxy cache MUST first revalidate it with the origin server, using the request-headers from the new request to allow the origin server to authenticate the new request. (This is the defined behavior for s-maxage.) If the response includes &quot;s- maxage=0&quot;, the proxy MUST always revalidate it before re-using it.2. If the response includes the &quot;must-revalidate&quot; cache-control directive, the cache MAY use that response in replying to a subsequent request. But if the response is stale, all caches MUST first revalidate it with the origin server, using the request-headers from the new request to allow the origin server to authenticate the new request.3. If the response includes the &quot;public&quot; cache-control directive, it MAY be returned in reply to any subsequent request. 14.9 Cache-ControlThe Cache-Control general-header field is used to specify directives that MUST be obeyed by all caching mechanisms along the request/response chain. The directives specify behavior intended to prevent caches from adversely interfering with the request or response. These directives typically override the default caching algorithms. Cache directives are unidirectional in that the presence of a directive in a request does not imply that the same directive is to be given in the response. 12Note that HTTP/1.0 caches might not implement Cache-Control andmight only implement Pragma: no-cache (see section 14.32). Cache directives MUST be passed through by a proxy or gateway application, regardless of their significance to that application, since the directives might be applicable to all recipients along the request/response chain. It is not possible to specify a cache- directive for a specific cache. 123456789101112131415161718192021222324Cache-Control = &quot;Cache-Control&quot; &quot;:&quot; 1#cache-directivecache-directive = cache-request-directive | cache-response-directivecache-request-directive = &quot;no-cache&quot; ; Section 14.9.1 | &quot;no-store&quot; ; Section 14.9.2 | &quot;max-age&quot; &quot;=&quot; delta-seconds ; Section 14.9.3, 14.9.4 | &quot;max-stale&quot; [ &quot;=&quot; delta-seconds ] ; Section 14.9.3 | &quot;min-fresh&quot; &quot;=&quot; delta-seconds ; Section 14.9.3 | &quot;no-transform&quot; ; Section 14.9.5 | &quot;only-if-cached&quot; ; Section 14.9.4 | cache-extension ; Section 14.9.6 cache-response-directive = &quot;public&quot; ; Section 14.9.1 | &quot;private&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ] ; Section 14.9.1 | &quot;no-cache&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ]; Section 14.9.1 | &quot;no-store&quot; ; Section 14.9.2 | &quot;no-transform&quot; ; Section 14.9.5 | &quot;must-revalidate&quot; ; Section 14.9.4 | &quot;proxy-revalidate&quot; ; Section 14.9.4 | &quot;max-age&quot; &quot;=&quot; delta-seconds ; Section 14.9.3 | &quot;s-maxage&quot; &quot;=&quot; delta-seconds ; Section 14.9.3 | cache-extension ; Section 14.9.6cache-extension = token [ &quot;=&quot; ( token | quoted-string ) ] When a directive appears without any 1#field-name parameter, the directive applies to the entire request or response. When such a directive appears with a 1#field-name parameter, it applies only to the named field or fields, and not to the rest of the request or response. This mechanism supports extensibility; implementations of future versions of the HTTP protocol might apply these directives to header fields not defined in HTTP/1.1. The cache-control directives can be broken down into these general categories: 12345678910- Restrictions on what are cacheable; these may only be imposed by the origin server.- Restrictions on what may be stored by a cache; these may be imposed by either the origin server or the user agent.- Modifications of the basic expiration mechanism; these may be imposed by either the origin server or the user agent.- Controls over cache revalidation and reload; these may only be imposed by a user agent.- Control over transformation of entities.- Extensions to the caching system. 14.9.1 What is CacheableBy default, a response is cacheable if the requirements of the request method, request header fields, and the response status indicate that it is cacheable. Section 13.4 summarizes these defaults for cacheability. The following Cache-Control response directives allow an origin server to override the default cacheability of a response: public Indicates that the response MAY be cached by any cache, even if it would normally be non-cacheable or cacheable only within a non- shared cache. (See also Authorization, section 14.8, for additional details.) private Indicates that all or part of the response message is intended for a single user and MUST NOT be cached by a shared cache. This allows an origin server to state that the specified parts of the response are intended for only one user and are not a valid response for requests by other users. A private (non-shared) cache MAY cache the response. Note: This usage of the word private only controls where the response may be cached, and cannot ensure the privacy of the message content. no-cache If the no-cache directive does not specify a field-name, then a cache MUST NOT use the response to satisfy a subsequent request without successful revalidation with the origin server. This allows an origin server to prevent caching even by caches that have been configured to return stale responses to client requests. If the no-cache directive does specify one or more field-names, then a cache MAY use the response to satisfy a subsequent request, subject to any other restrictions on caching. However, the specified field-name(s) MUST NOT be sent in the response to a subsequent request without successful revalidation with the origin server. This allows an origin server to prevent the re-use of certain header fields in a response, while still allowing caching of the rest of the response. Note: Most HTTP/1.0 caches will not recognize or obey this directive. 14.9.2 What May be Stored by Caches no-store The purpose of the no-store directive is to prevent the inadvertent release or retention of sensitive information (for example, on backup tapes). The no-store directive applies to the entire message, and MAY be sent either in a response or in a request. If sent in a request, a cache MUST NOT store any part of either this request or any response to it. If sent in a response, a cache MUST NOT store any part of either this response or the request that elicited it. This directive applies to both non- shared and shared caches. “MUST NOT store” in this context means that the cache MUST NOT intentionally store the information in non-volatile storage, and MUST make a best-effort attempt to remove the information from volatile storage as promptly as possible after forwarding it. Even when this directive is associated with a response, users might explicitly store such a response outside of the caching system (e.g., with a “Save As” dialog). History buffers MAY store such responses as part of their normal operation. The purpose of this directive is to meet the stated requirements of certain users and service authors who are concerned about accidental releases of information via unanticipated accesses to cache data structures. While the use of this directive might improve privacy in some cases, we caution that it is NOT in any way a reliable or sufficient mechanism for ensuring privacy. In particular, malicious or compromised caches might not recognize or obey this directive, and communications networks might be vulnerable to eavesdropping. 14.9.3 Modifications of the Basic Expiration MechanismThe expiration time of an entity MAY be specified by the origin server using the Expires header (see section 14.21). Alternatively, it MAY be specified using the max-age directive in a response. When the max-age cache-control directive is present in a cached response, the response is stale if its current age is greater than the age value given (in seconds) at the time of a new request for that resource. The max-age directive on a response implies that the response is cacheable (i.e., “public”) unless some other, more restrictive cache directive is also present. If a response includes both an Expires header and a max-age directive, the max-age directive overrides the Expires header, even if the Expires header is more restrictive. This rule allows an origin server to provide, for a given response, a longer expiration time to an HTTP/1.1 (or later) cache than to an HTTP/1.0 cache. This might be useful if certain HTTP/1.0 caches improperly calculate ages or expiration times, perhaps due to desynchronized clocks. Many HTTP/1.0 cache implementations will treat an Expires value that is less than or equal to the response Date value as being equivalent to the Cache-Control response directive “no-cache”. If an HTTP/1.1 cache receives such a response, and the response does not include a Cache-Control header field, it SHOULD consider the response to be non-cacheable in order to retain compatibility with HTTP/1.0 servers. Note: An origin server might wish to use a relatively new HTTP cache control feature, such as the “private” directive, on a network including older caches that do not understand that feature. The origin server will need to combine the new feature with an Expires field whose value is less than or equal to the Date value. This will prevent older caches from improperly caching the response. s-maxage If a response includes an s-maxage directive, then for a shared cache (but not for a private cache), the maximum age specified by this directive overrides the maximum age specified by either the max-age directive or the Expires header. The s-maxage directive also implies the semantics of the proxy-revalidate directive (see section 14.9.4), i.e., that the shared cache must not use the entry after it becomes stale to respond to a subsequent request without first revalidating it with the origin server. The s- maxage directive is always ignored by a private cache. Note that most older caches, not compliant with this specification, do not implement any cache-control directives. An origin server wishing to use a cache-control directive that restricts, but does not prevent, caching by an HTTP/1.1-compliant cache MAY exploit the requirement that the max-age directive overrides the Expires header, and the fact that pre-HTTP/1.1-compliant caches do not observe the max-age directive. Other directives allow a user agent to modify the basic expiration mechanism. These directives MAY be specified on a request: max-age Indicates that the client is willing to accept a response whose age is no greater than the specified time in seconds. Unless max- stale directive is also included, the client is not willing to accept a stale response. min-fresh Indicates that the client is willing to accept a response whose freshness lifetime is no less than its current age plus the specified time in seconds. That is, the client wants a response that will still be fresh for at least the specified number of seconds. max-stale Indicates that the client is willing to accept a response that has exceeded its expiration time. If max-stale is assigned a value, then the client is willing to accept a response that has exceeded its expiration time by no more than the specified number of seconds. If no value is assigned to max-stale, then the client is willing to accept a stale response of any age. If a cache returns a stale response, either because of a max-stale directive on a request, or because the cache is configured to override the expiration time of a response, the cache MUST attach a Warning header to the stale response, using Warning 110 (Response is stale). A cache MAY be configured to return stale responses without validation, but only if this does not conflict with any “MUST”-level requirements concerning cache validation (e.g., a “must-revalidate” cache-control directive). If both the new request and the cached entry include “max-age” directives, then the lesser of the two values is used for determining the freshness of the cached entry for that request. 14.9.4 Cache Revalidation and Reload ControlsSometimes a user agent might want or need to insist that a cache revalidate its cache entry with the origin server (and not just with the next cache along the path to the origin server), or to reload its cache entry from the origin server. End-to-end revalidation might be necessary if either the cache or the origin server has overestimated the expiration time of the cached response. End-to-end reload may be necessary if the cache entry has become corrupted for some reason. End-to-end revalidation may be requested either when the client does not have its own local cached copy, in which case we call it “unspecified end-to-end revalidation”, or when the client does have a local cached copy, in which case we call it “specific end-to-end revalidation.” The client can specify these three kinds of action using Cache- Control request directives: End-to-end reload The request includes a “no-cache” cache-control directive or, for compatibility with HTTP/1.0 clients, “Pragma: no-cache”. Field names MUST NOT be included with the no-cache directive in a request. The server MUST NOT use a cached copy when responding to such a request. Specific end-to-end revalidation The request includes a “max-age=0” cache-control directive, which forces each cache along the path to the origin server to revalidate its own entry, if any, with the next cache or server. The initial request includes a cache-validating conditional with the client’s current validator. Unspecified end-to-end revalidation The request includes “max-age=0” cache-control directive, which forces each cache along the path to the origin server to revalidate its own entry, if any, with the next cache or server. The initial request does not include a cache-validating conditional; the first cache along the path (if any) that holds a cache entry for this resource includes a cache-validating conditional with its current validator. max-age When an intermediate cache is forced, by means of a max-age=0 directive, to revalidate its own cache entry, and the client has supplied its own validator in the request, the supplied validator might differ from the validator currently stored with the cache entry. In this case, the cache MAY use either validator in making its own request without affecting semantic transparency. However, the choice of validator might affect performance. The best approach is for the intermediate cache to use its own validator when making its request. If the server replies with 304 (Not Modified), then the cache can return its now validated copy to the client with a 200 (OK) response. If the server replies with a new entity and cache validator, however, the intermediate cache can compare the returned validator with the one provided in the client’s request, using the strong comparison function. If the client’s validator is equal to the origin server’s, then the intermediate cache simply returns 304 (Not Modified). Otherwise, it returns the new entity with a 200 (OK) response. If a request includes the no-cache directive, it SHOULD NOT include min-fresh, max-stale, or max-age. only-if-cached In some cases, such as times of extremely poor network connectivity, a client may want a cache to return only those responses that it currently has stored, and not to reload or revalidate with the origin server. To do this, the client may include the only-if-cached directive in a request. If it receives this directive, a cache SHOULD either respond using a cached entry that is consistent with the other constraints of the request, or respond with a 504 (Gateway Timeout) status. However, if a group of caches is being operated as a unified system with good internal connectivity, such a request MAY be forwarded within that group of caches. must-revalidate Because a cache MAY be configured to ignore a server’s specified expiration time, and because a client request MAY include a max- stale directive (which has a similar effect), the protocol also includes a mechanism for the origin server to require revalidation of a cache entry on any subsequent use. When the must-revalidate directive is present in a response received by a cache, that cache MUST NOT use the entry after it becomes stale to respond to a subsequent request without first revalidating it with the origin server. (I.e., the cache MUST do an end-to-end revalidation every time, if, based solely on the origin server’s Expires or max-age value, the cached response is stale.) The must-revalidate directive is necessary to support reliable operation for certain protocol features. In all circumstances an HTTP/1.1 cache MUST obey the must-revalidate directive; in particular, if the cache cannot reach the origin server for any reason, it MUST generate a 504 (Gateway Timeout) response. Servers SHOULD send the must-revalidate directive if and only if failure to revalidate a request on the entity could result in incorrect operation, such as a silently unexecuted financial transaction. Recipients MUST NOT take any automated action that violates this directive, and MUST NOT automatically provide an unvalidated copy of the entity if revalidation fails. Although this is not recommended, user agents operating under severe connectivity constraints MAY violate this directive but, if so, MUST explicitly warn the user that an unvalidated response has been provided. The warning MUST be provided on each unvalidated access, and SHOULD require explicit user confirmation. proxy-revalidate The proxy-revalidate directive has the same meaning as the must- revalidate directive, except that it does not apply to non-shared user agent caches. It can be used on a response to an authenticated request to permit the user’s cache to store and later return the response without needing to revalidate it (since it has already been authenticated once by that user), while still requiring proxies that service many users to revalidate each time (in order to make sure that each user has been authenticated). Note that such authenticated responses also need the public cache control directive in order to allow them to be cached at all. 14.9.5 No-Transform Directive no-transform Implementors of intermediate caches (proxies) have found it useful to convert the media type of certain entity bodies. A non- transparent proxy might, for example, convert between image formats in order to save cache space or to reduce the amount of traffic on a slow link. Serious operational problems occur, however, when these transformations are applied to entity bodies intended for certain kinds of applications. For example, applications for medical imaging, scientific data analysis and those using end-to-end authentication, all depend on receiving an entity body that is bit for bit identical to the original entity-body. Therefore, if a message includes the no-transform directive, an intermediate cache or proxy MUST NOT change those headers that are listed in section 13.5.2 as being subject to the no-transform directive. This implies that the cache or proxy MUST NOT change any aspect of the entity-body that is specified by these headers, including the value of the entity-body itself. 14.9.6 Cache Control ExtensionsThe Cache-Control header field can be extended through the use of one or more cache-extension tokens, each with an optional assigned value. Informational extensions (those which do not require a change in cache behavior) MAY be added without changing the semantics of other directives. Behavioral extensions are designed to work by acting as modifiers to the existing base of cache directives. Both the new directive and the standard directive are supplied, such that applications which do not understand the new directive will default to the behavior specified by the standard directive, and those that understand the new directive will recognize it as modifying the requirements associated with the standard directive. In this way, extensions to the cache-control directives can be made without requiring changes to the base protocol. This extension mechanism depends on an HTTP cache obeying all of the cache-control directives defined for its native HTTP-version, obeying certain extensions, and ignoring all directives that it does not understand. For example, consider a hypothetical new response directive called community which acts as a modifier to the private directive. We define this new directive to mean that, in addition to any non-shared cache, any cache which is shared only by members of the community named within its value may cache the response. An origin server wishing to allow the UCI community to use an otherwise private response in their shared cache(s) could do so by including 1Cache-Control: private, community=&quot;UCI&quot; A cache seeing this header field will act correctly even if the cache does not understand the community cache-extension, since it will also see and understand the private directive and thus default to the safe behavior. Unrecognized cache-directives MUST be ignored; it is assumed that any cache-directive likely to be unrecognized by an HTTP/1.1 cache will be combined with standard directives (or the response’s default cacheability) such that the cache behavior will remain minimally correct even if the cache does not understand the extension(s). 14.10 ConnectionThe Connection general-header field allows the sender to specify options that are desired for that particular connection and MUST NOT be communicated by proxies over further connections. The Connection header has the following grammar: 12Connection = &quot;Connection&quot; &quot;:&quot; 1#(connection-token)connection-token = token HTTP/1.1 proxies MUST parse the Connection header field before a message is forwarded and, for each connection-token in this field, remove any header field(s) from the message with the same name as the connection-token. Connection options are signaled by the presence of a connection-token in the Connection header field, not by any corresponding additional header field(s), since the additional header field may not be sent if there are no parameters associated with that connection option. Message headers listed in the Connection header MUST NOT include end-to-end headers, such as Cache-Control. HTTP/1.1 defines the “close” connection option for the sender to signal that the connection will be closed after completion of the response. For example, 1Connection: close in either the request or the response header fields indicates that the connection SHOULD NOT be considered `persistent’ (section 8.1) after the current request/response is complete. HTTP/1.1 applications that do not support persistent connections MUST include the “close” connection option in every message. A system receiving an HTTP/1.0 (or lower-version) message that includes a Connection header MUST, for each connection-token in this field, remove and ignore any header field(s) from the message with the same name as the connection-token. This protects against mistaken forwarding of such header fields by pre-HTTP/1.1 proxies. See section 19.6.2. 14.11 Content-EncodingThe Content-Encoding entity-header field is used as a modifier to the media-type. When present, its value indicates what additional content codings have been applied to the entity-body, and thus what decoding mechanisms must be applied in order to obtain the media-type referenced by the Content-Type header field. Content-Encoding is primarily used to allow a document to be compressed without losing the identity of its underlying media type. 1Content-Encoding = &quot;Content-Encoding&quot; &quot;:&quot; 1#content-coding Content codings are defined in section 3.5. An example of its use is 1Content-Encoding: gzip The content-coding is a characteristic of the entity identified by the Request-URI. Typically, the entity-body is stored with this encoding and is only decoded before rendering or analogous usage. However, a non-transparent proxy MAY modify the content-coding if the new coding is known to be acceptable to the recipient, unless the “no-transform” cache-control directive is present in the message. If the content-coding of an entity is not “identity”, then the response MUST include a Content-Encoding entity-header (section 14.11) that lists the non-identity content-coding(s) used. If the content-coding of an entity in a request message is not acceptable to the origin server, the server SHOULD respond with a status code of 415 (Unsupported Media Type). If multiple encodings have been applied to an entity, the content codings MUST be listed in the order in which they were applied. Additional information about the encoding parameters MAY be provided by other entity-header fields not defined by this specification. 14.12 Content-LanguageThe Content-Language entity-header field describes the natural language(s) of the intended audience for the enclosed entity. Note that this might not be equivalent to all the languages used within the entity-body. 1Content-Language = &quot;Content-Language&quot; &quot;:&quot; 1#language-tag Language tags are defined in section 3.10. The primary purpose of Content-Language is to allow a user to identify and differentiate entities according to the user’s own preferred language. Thus, if the body content is intended only for a Danish-literate audience, the appropriate field is 1Content-Language: da If no Content-Language is specified, the default is that the content is intended for all language audiences. This might mean that the sender does not consider it to be specific to any natural language, or that the sender does not know for which language it is intended. Multiple languages MAY be listed for content that is intended for multiple audiences. For example, a rendition of the “Treaty of Waitangi,” presented simultaneously in the original Maori and English versions, would call for 1Content-Language: mi, en However, just because multiple languages are present within an entity does not mean that it is intended for multiple linguistic audiences. An example would be a beginner’s language primer, such as “A First Lesson in Latin,” which is clearly intended to be used by an English-literate audience. In this case, the Content-Language would properly only include “en”. Content-Language MAY be applied to any media type – it is not limited to textual documents. 14.13 Content-LengthThe Content-Length entity-header field indicates the size of the entity-body, in decimal number of OCTETs, sent to the recipient or, in the case of the HEAD method, the size of the entity-body that would have been sent had the request been a GET. 1Content-Length = &quot;Content-Length&quot; &quot;:&quot; 1*DIGIT An example is 1Content-Length: 3495 Applications SHOULD use this field to indicate the transfer-length of the message-body, unless this is prohibited by the rules in section 4.4. Any Content-Length greater than or equal to zero is a valid value. Section 4.4 describes how to determine the length of a message-body if a Content-Length is not given. Note that the meaning of this field is significantly different from the corresponding definition in MIME, where it is an optional field used within the “message/external-body” content-type. In HTTP, it SHOULD be sent whenever the message’s length can be determined prior to being transferred, unless this is prohibited by the rules in section 4.4. 14.14 Content-LocationThe Content-Location entity-header field MAY be used to supply the resource location for the entity enclosed in the message when that entity is accessible from a location separate from the requested resource’s URI. A server SHOULD provide a Content-Location for the variant corresponding to the response entity; especially in the case where a resource has multiple entities associated with it, and those entities actually have separate locations by which they might be individually accessed, the server SHOULD provide a Content-Location for the particular variant which is returned. 12Content-Location = &quot;Content-Location&quot; &quot;:&quot; ( absoluteURI | relativeURI ) The value of Content-Location also defines the base URI for the entity. The Content-Location value is not a replacement for the original requested URI; it is only a statement of the location of the resource corresponding to this particular entity at the time of the request. Future requests MAY specify the Content-Location URI as the request- URI if the desire is to identify the source of that particular entity. A cache cannot assume that an entity with a Content-Location different from the URI used to retrieve it can be used to respond to later requests on that Content-Location URI. However, the Content- Location can be used to differentiate between multiple entities retrieved from a single requested resource, as described in section 13.6. If the Content-Location is a relative URI, the relative URI is interpreted relative to the Request-URI. The meaning of the Content-Location header in PUT or POST requests is undefined; servers are free to ignore it in those cases. 14.15 Content-MD5The Content-MD5 entity-header field, as defined in RFC 1864 [23], is an MD5 digest of the entity-body for the purpose of providing an end-to-end message integrity check (MIC) of the entity-body. (Note: a MIC is good for detecting accidental modification of the entity-body in transit, but is not proof against malicious attacks.) 12Content-MD5 = &quot;Content-MD5&quot; &quot;:&quot; md5-digestmd5-digest = &lt;base64 of 128 bit MD5 digest as per RFC 1864&gt; The Content-MD5 header field MAY be generated by an origin server or client to function as an integrity check of the entity-body. Only origin servers or clients MAY generate the Content-MD5 header field; proxies and gateways MUST NOT generate it, as this would defeat its value as an end-to-end integrity check. Any recipient of the entity- body, including gateways and proxies, MAY check that the digest value in this header field matches that of the entity-body as received. The MD5 digest is computed based on the content of the entity-body, including any content-coding that has been applied, but not including any transfer-encoding applied to the message-body. If the message is received with a transfer-encoding, that encoding MUST be removed prior to checking the Content-MD5 value against the received entity. This has the result that the digest is computed on the octets of the entity-body exactly as, and in the order that, they would be sent if no transfer-encoding were being applied. HTTP extends RFC 1864 to permit the digest to be computed for MIME composite media-types (e.g., multipart/* and message/rfc822), but this does not change how the digest is computed as defined in the preceding paragraph. There are several consequences of this. The entity-body for composite types MAY contain many body-parts, each with its own MIME and HTTP headers (including Content-MD5, Content-Transfer-Encoding, and Content-Encoding headers). If a body-part has a Content-Transfer- Encoding or Content-Encoding header, it is assumed that the content of the body-part has had the encoding applied, and the body-part is included in the Content-MD5 digest as is – i.e., after the application. The Transfer-Encoding header field is not allowed within body-parts. Conversion of all line breaks to CRLF MUST NOT be done before computing or checking the digest: the line break convention used in the text actually transmitted MUST be left unaltered when computing the digest. 1234567891011Note: while the definition of Content-MD5 is exactly the same forHTTP as in RFC 1864 for MIME entity-bodies, there are several waysin which the application of Content-MD5 to HTTP entity-bodiesdiffers from its application to MIME entity-bodies. One is thatHTTP, unlike MIME, does not use Content-Transfer-Encoding, anddoes use Transfer-Encoding and Content-Encoding. Another is thatHTTP more frequently uses binary content types than MIME, so it isworth noting that, in such cases, the byte order used to computethe digest is the transmission byte order defined for the type.Lastly, HTTP allows transmission of text types with any of severalline break conventions and not just the canonical form using CRLF. 14.16 Content-RangeThe Content-Range entity-header is sent with a partial entity-body to specify where in the full entity-body the partial body should be applied. Range units are defined in section 3.12. 12345678Content-Range = &quot;Content-Range&quot; &quot;:&quot; content-range-speccontent-range-spec = byte-content-range-specbyte-content-range-spec = bytes-unit SP byte-range-resp-spec &quot;/&quot; ( instance-length | &quot;*&quot; )byte-range-resp-spec = (first-byte-pos &quot;-&quot; last-byte-pos) | &quot;*&quot;instance-length = 1*DIGIT The header SHOULD indicate the total length of the full entity-body, unless this length is unknown or difficult to determine. The asterisk “*” character means that the instance-length is unknown at the time when the response was generated. Unlike byte-ranges-specifier values (see section 14.35.1), a byte- range-resp-spec MUST only specify one range, and MUST contain absolute byte positions for both the first and last byte of the range. A byte-content-range-spec with a byte-range-resp-spec whose last- byte-pos value is less than its first-byte-pos value, or whose instance-length value is less than or equal to its last-byte-pos value, is invalid. The recipient of an invalid byte-content-range- spec MUST ignore it and any content transferred along with it. A server sending a response with status code 416 (Requested range not satisfiable) SHOULD include a Content-Range field with a byte-range- resp-spec of “*”. The instance-length specifies the current length of the selected resource. A response with status code 206 (Partial Content) MUST NOT include a Content-Range field with a byte-range- resp-spec of “*”. Examples of byte-content-range-spec values, assuming that the entity contains a total of 1234 bytes: 12345678. The first 500 bytes: bytes 0-499/1234. The second 500 bytes: bytes 500-999/1234. All except for the first 500 bytes: bytes 500-1233/1234. The last 500 bytes: bytes 734-1233/1234 When an HTTP message includes the content of a single range (for example, a response to a request for a single range, or to a request for a set of ranges that overlap without any holes), this content is transmitted with a Content-Range header, and a Content-Length header showing the number of bytes actually transferred. For example, 123456HTTP/1.1 206 Partial contentDate: Wed, 15 Nov 1995 06:25:24 GMTLast-Modified: Wed, 15 Nov 1995 04:58:08 GMTContent-Range: bytes 21010-47021/47022Content-Length: 26012Content-Type: image/gif When an HTTP message includes the content of multiple ranges (for example, a response to a request for multiple non-overlapping ranges), these are transmitted as a multipart message. The multipart media type used for this purpose is “multipart/byteranges” as defined in appendix 19.2. See appendix 19.6.3 for a compatibility issue. A response to a request for a single range MUST NOT be sent using the multipart/byteranges media type. A response to a request for multiple ranges, whose result is a single range, MAY be sent as a multipart/byteranges media type with one part. A client that cannot decode a multipart/byteranges message MUST NOT ask for multiple byte-ranges in a single request. When a client requests multiple byte-ranges in one request, the server SHOULD return them in the order that they appeared in the request. If the server ignores a byte-range-spec because it is syntactically invalid, the server SHOULD treat the request as if the invalid Range header field did not exist. (Normally, this means return a 200 response containing the full entity). If the server receives a request (other than one including an If- Range request-header field) with an unsatisfiable Range request- header field (that is, all of whose byte-range-spec values have a first-byte-pos value greater than the current length of the selected resource), it SHOULD return a response code of 416 (Requested range not satisfiable) (section 10.4.17). 1234Note: clients cannot depend on servers to send a 416 (Requestedrange not satisfiable) response instead of a 200 (OK) response foran unsatisfiable Range request-header, since not all serversimplement this request-header. 14.17 Content-TypeThe Content-Type entity-header field indicates the media type of the entity-body sent to the recipient or, in the case of the HEAD method, the media type that would have been sent had the request been a GET. 1Content-Type = &quot;Content-Type&quot; &quot;:&quot; media-type Media types are defined in section 3.7. An example of the field is 1Content-Type: text/html; charset=ISO-8859-4 Further discussion of methods for identifying the media type of an entity is provided in section 7.2.1. 14.18 DateThe Date general-header field represents the date and time at which the message was originated, having the same semantics as orig-date in RFC 822. The field value is an HTTP-date, as described in section 3.3.1; it MUST be sent in RFC 1123 [8]-date format. 1Date = &quot;Date&quot; &quot;:&quot; HTTP-date An example is 1Date: Tue, 15 Nov 1994 08:12:31 GMT Origin servers MUST include a Date header field in all responses, except in these cases: 123456789101. If the response status code is 100 (Continue) or 101 (Switching Protocols), the response MAY include a Date header field, at the server&apos;s option.2. If the response status code conveys a server error, e.g. 500 (Internal Server Error) or 503 (Service Unavailable), and it is inconvenient or impossible to generate a valid Date.3. If the server does not have a clock that can provide a reasonable approximation of the current time, its responses MUST NOT include a Date header field. In this case, the rules in section 14.18.1 MUST be followed. A received message that does not have a Date header field MUST be assigned one by the recipient if the message will be cached by that recipient or gatewayed via a protocol which requires a Date. An HTTP implementation without a clock MUST NOT cache responses without revalidating them on every use. An HTTP cache, especially a shared cache, SHOULD use a mechanism, such as NTP [28], to synchronize its clock with a reliable external standard. Clients SHOULD only send a Date header field in messages that include an entity-body, as in the case of the PUT and POST requests, and even then it is optional. A client without a clock MUST NOT send a Date header field in a request. The HTTP-date sent in a Date header SHOULD NOT represent a date and time subsequent to the generation of the message. It SHOULD represent the best available approximation of the date and time of message generation, unless the implementation has no means of generating a reasonably accurate date and time. In theory, the date ought to represent the moment just before the entity is generated. In practice, the date can be generated at any time during the message origination without affecting its semantic value. 14.18.1 Clockless Origin Server OperationSome origin server implementations might not have a clock available. An origin server without a clock MUST NOT assign Expires or Last- Modified values to a response, unless these values were associated with the resource by a system or user with a reliable clock. It MAY assign an Expires value that is known, at or before server configuration time, to be in the past (this allows “pre-expiration” of responses without storing separate Expires values for each resource). 14.19 ETagThe ETag response-header field provides the current value of the entity tag for the requested variant. The headers used with entity tags are described in sections 14.24, 14.26 and 14.44. The entity tag MAY be used for comparison with other entities from the same resource (see section 13.3.3). 1ETag = &quot;ETag&quot; &quot;:&quot; entity-tag Examples: 123ETag: &quot;xyzzy&quot;ETag: W/&quot;xyzzy&quot;ETag: &quot;&quot; 14.20 ExpectThe Expect request-header field is used to indicate that particular server behaviors are required by the client. 12345Expect = &quot;Expect&quot; &quot;:&quot; 1#expectationexpectation = &quot;100-continue&quot; | expectation-extensionexpectation-extension = token [ &quot;=&quot; ( token | quoted-string ) *expect-params ]expect-params = &quot;;&quot; token [ &quot;=&quot; ( token | quoted-string ) ] A server that does not understand or is unable to comply with any of the expectation values in the Expect field of a request MUST respond with appropriate error status. The server MUST respond with a 417 (Expectation Failed) status if any of the expectations cannot be met or, if there are other problems with the request, some other 4xx status. This header field is defined with extensible syntax to allow for future extensions. If a server receives a request containing an Expect field that includes an expectation-extension that it does not support, it MUST respond with a 417 (Expectation Failed) status. Comparison of expectation values is case-insensitive for unquoted tokens (including the 100-continue token), and is case-sensitive for quoted-string expectation-extensions. The Expect mechanism is hop-by-hop: that is, an HTTP/1.1 proxy MUST return a 417 (Expectation Failed) status if it receives a request with an expectation that it cannot meet. However, the Expect request-header itself is end-to-end; it MUST be forwarded if the request is forwarded. Many older HTTP/1.0 and HTTP/1.1 applications do not understand the Expect header. See section 8.2.3 for the use of the 100 (continue) status. 14.21 ExpiresThe Expires entity-header field gives the date/time after which the response is considered stale. A stale cache entry may not normally be returned by a cache (either a proxy cache or a user agent cache) unless it is first validated with the origin server (or with an intermediate cache that has a fresh copy of the entity). See section 13.2 for further discussion of the expiration model. The presence of an Expires field does not imply that the original resource will change or cease to exist at, before, or after that time. The format is an absolute date and time as defined by HTTP-date in section 3.3.1; it MUST be in RFC 1123 date format: 1Expires = &quot;Expires&quot; &quot;:&quot; HTTP-date An example of its use is 1234Expires: Thu, 01 Dec 1994 16:00:00 GMTNote: if a response includes a Cache-Control field with the max-age directive (see section 14.9.3), that directive overrides theExpires field. HTTP/1.1 clients and caches MUST treat other invalid date formats, especially including the value “0”, as in the past (i.e., “already expired”). To mark a response as “already expired,” an origin server sends an Expires date that is equal to the Date header value. (See the rules for expiration calculations in section 13.2.4.) To mark a response as “never expires,” an origin server sends an Expires date approximately one year from the time the response is sent. HTTP/1.1 servers SHOULD NOT send Expires dates more than one year in the future. The presence of an Expires header field with a date value of some time in the future on a response that otherwise would by default be non-cacheable indicates that the response is cacheable, unless indicated otherwise by a Cache-Control header field (section 14.9). 14.22 FromThe From request-header field, if given, SHOULD contain an Internet e-mail address for the human user who controls the requesting user agent. The address SHOULD be machine-usable, as defined by “mailbox” in RFC 822 [9] as updated by RFC 1123 [8]: 1From = &quot;From&quot; &quot;:&quot; mailbox An example is: 1From: webmaster@w3.org This header field MAY be used for logging purposes and as a means for identifying the source of invalid or unwanted requests. It SHOULD NOT be used as an insecure form of access protection. The interpretation of this field is that the request is being performed on behalf of the person given, who accepts responsibility for the method performed. In particular, robot agents SHOULD include this header so that the person responsible for running the robot can be contacted if problems occur on the receiving end. The Internet e-mail address in this field MAY be separate from the Internet host which issued the request. For example, when a request is passed through a proxy the original issuer’s address SHOULD be used. The client SHOULD NOT send the From header field without the user’s approval, as it might conflict with the user’s privacy interests or their site’s security policy. It is strongly recommended that the user be able to disable, enable, and modify the value of this field at any time prior to a request. 14.23 HostThe Host request-header field specifies the Internet host and port number of the resource being requested, as obtained from the original URI given by the user or referring resource (generally an HTTP URL, as described in section 3.2.2). The Host field value MUST represent the naming authority of the origin server or gateway given by the original URL. This allows the origin server or gateway to differentiate between internally-ambiguous URLs, such as the root “/“ URL of a server for multiple host names on a single IP address. 1Host = &quot;Host&quot; &quot;:&quot; host [ &quot;:&quot; port ] ; Section 3.2.2 A “host” without any trailing port information implies the default port for the service requested (e.g., “80” for an HTTP URL). For example, a request on the origin server for http://www.w3.org/pub/WWW/ would properly include: 12GET /pub/WWW/ HTTP/1.1Host: www.w3.org A client MUST include a Host header field in all HTTP/1.1 request messages . If the requested URI does not include an Internet host name for the service being requested, then the Host header field MUST be given with an empty value. An HTTP/1.1 proxy MUST ensure that any request message it forwards does contain an appropriate Host header field that identifies the service being requested by the proxy. All Internet-based HTTP/1.1 servers MUST respond with a 400 (Bad Request) status code to any HTTP/1.1 request message which lacks a Host header field. See sections 5.2 and 19.6.1.1 for other requirements relating to Host. 14.24 If-MatchThe If-Match request-header field is used with a method to make it conditional. A client that has one or more entities previously obtained from the resource can verify that one of those entities is current by including a list of their associated entity tags in the If-Match header field. Entity tags are defined in section 3.11. The purpose of this feature is to allow efficient updates of cached information with a minimum amount of transaction overhead. It is also used, on updating requests, to prevent inadvertent modification of the wrong version of a resource. As a special case, the value “*” matches any current entity of the resource. 1If-Match = &quot;If-Match&quot; &quot;:&quot; ( &quot;*&quot; | 1#entity-tag ) If any of the entity tags match the entity tag of the entity that would have been returned in the response to a similar GET request (without the If-Match header) on that resource, or if “*” is given and any current entity exists for that resource, then the server MAY perform the requested method as if the If-Match header field did not exist. A server MUST use the strong comparison function (see section 13.3.3) to compare the entity tags in If-Match. If none of the entity tags match, or if “*” is given and no current entity exists, the server MUST NOT perform the requested method, and MUST return a 412 (Precondition Failed) response. This behavior is most useful when the client wants to prevent an updating method, such as PUT, from modifying a resource that has changed since the client last retrieved it. If the request would, without the If-Match header field, result in anything other than a 2xx or 412 status, then the If-Match header MUST be ignored. The meaning of “If-Match: *” is that the method SHOULD be performed if the representation selected by the origin server (or by a cache, possibly using the Vary mechanism, see section 14.44) exists, and MUST NOT be performed if the representation does not exist. A request intended to update a resource (e.g., a PUT) MAY include an If-Match header field to signal that the request method MUST NOT be applied if the entity corresponding to the If-Match value (a single entity tag) is no longer a representation of that resource. This allows the user to indicate that they do not wish the request to be successful if the resource has been changed without their knowledge. Examples: 123If-Match: &quot;xyzzy&quot;If-Match: &quot;xyzzy&quot;, &quot;r2d2xxxx&quot;, &quot;c3piozzzz&quot;If-Match: * The result of a request having both an If-Match header field and either an If-None-Match or an If-Modified-Since header fields is undefined by this specification. 14.25 If-Modified-SinceThe If-Modified-Since request-header field is used with a method to make it conditional: if the requested variant has not been modified since the time specified in this field, an entity will not be returned from the server; instead, a 304 (not modified) response will be returned without any message-body. 1If-Modified-Since = &quot;If-Modified-Since&quot; &quot;:&quot; HTTP-date An example of the field is: 1If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT A GET method with an If-Modified-Since header and no Range header requests that the identified entity be transferred only if it has been modified since the date given by the If-Modified-Since header. The algorithm for determining this includes the following cases: 12345678910a) If the request would normally result in anything other than a 200 (OK) status, or if the passed If-Modified-Since date is invalid, the response is exactly the same as for a normal GET. A date which is later than the server&apos;s current time is invalid.b) If the variant has been modified since the If-Modified-Since date, the response is exactly the same as for a normal GET.c) If the variant has not been modified since a valid If- Modified-Since date, the server SHOULD return a 304 (Not Modified) response. The purpose of this feature is to allow efficient updates of cached information with a minimum amount of transaction overhead. 12345678910111213141516171819202122232425Note: The Range request-header field modifies the meaning of If-Modified-Since; see section 14.35 for full details.Note: If-Modified-Since times are interpreted by the server, whoseclock might not be synchronized with the client.Note: When handling an If-Modified-Since header field, someservers will use an exact date comparison function, rather than aless-than function, for deciding whether to send a 304 (NotModified) response. To get best results when sending an If-Modified-Since header field for cache validation, clients areadvised to use the exact date string received in a previous Last-Modified header field whenever possible.Note: If a client uses an arbitrary date in the If-Modified-Sinceheader instead of a date taken from the Last-Modified header forthe same request, the client should be aware of the fact that thisdate is interpreted in the server&apos;s understanding of time. Theclient should consider unsynchronized clocks and rounding problemsdue to the different encodings of time between the client andserver. This includes the possibility of race conditions if thedocument has changed between the time it was first requested andthe If-Modified-Since date of a subsequent request, and thepossibility of clock-skew-related problems if the If-Modified-Since date is derived from the client&apos;s clock without correctionto the server&apos;s clock. Corrections for different time basesbetween client and server are at best approximate due to networklatency. The result of a request having both an If-Modified-Since header field and either an If-Match or an If-Unmodified-Since header fields is undefined by this specification. 14.26 If-None-MatchThe If-None-Match request-header field is used with a method to make it conditional. A client that has one or more entities previously obtained from the resource can verify that none of those entities is current by including a list of their associated entity tags in the If-None-Match header field. The purpose of this feature is to allow efficient updates of cached information with a minimum amount of transaction overhead. It is also used to prevent a method (e.g. PUT) from inadvertently modifying an existing resource when the client believes that the resource does not exist. As a special case, the value “*” matches any current entity of the resource. 1If-None-Match = &quot;If-None-Match&quot; &quot;:&quot; ( &quot;*&quot; | 1#entity-tag ) If any of the entity tags match the entity tag of the entity that would have been returned in the response to a similar GET request (without the If-None-Match header) on that resource, or if “*” is given and any current entity exists for that resource, then the server MUST NOT perform the requested method, unless required to do so because the resource’s modification date fails to match that supplied in an If-Modified-Since header field in the request. Instead, if the request method was GET or HEAD, the server SHOULD respond with a 304 (Not Modified) response, including the cache- related header fields (particularly ETag) of one of the entities that matched. For all other request methods, the server MUST respond with a status of 412 (Precondition Failed). See section 13.3.3 for rules on how to determine if two entities tags match. The weak comparison function can only be used with GET or HEAD requests. If none of the entity tags match, then the server MAY perform the requested method as if the If-None-Match header field did not exist, but MUST also ignore any If-Modified-Since header field(s) in the request. That is, if no entity tags match, then the server MUST NOT return a 304 (Not Modified) response. If the request would, without the If-None-Match header field, result in anything other than a 2xx or 304 status, then the If-None-Match header MUST be ignored. (See section 13.3.4 for a discussion of server behavior when both If-Modified-Since and If-None-Match appear in the same request.) The meaning of “If-None-Match: *” is that the method MUST NOT be performed if the representation selected by the origin server (or by a cache, possibly using the Vary mechanism, see section 14.44) exists, and SHOULD be performed if the representation does not exist. This feature is intended to be useful in preventing races between PUT operations. Examples: 12345If-None-Match: &quot;xyzzy&quot;If-None-Match: W/&quot;xyzzy&quot;If-None-Match: &quot;xyzzy&quot;, &quot;r2d2xxxx&quot;, &quot;c3piozzzz&quot;If-None-Match: W/&quot;xyzzy&quot;, W/&quot;r2d2xxxx&quot;, W/&quot;c3piozzzz&quot;If-None-Match: * The result of a request having both an If-None-Match header field and either an If-Match or an If-Unmodified-Since header fields is undefined by this specification. 14.27 If-RangeIf a client has a partial copy of an entity in its cache, and wishes to have an up-to-date copy of the entire entity in its cache, it could use the Range request-header with a conditional GET (using either or both of If-Unmodified-Since and If-Match.) However, if the condition fails because the entity has been modified, the client would then have to make a second request to obtain the entire current entity-body. The If-Range header allows a client to “short-circuit” the second request. Informally, its meaning is `if the entity is unchanged, send me the part(s) that I am missing; otherwise, send me the entire new entity’. 1If-Range = &quot;If-Range&quot; &quot;:&quot; ( entity-tag | HTTP-date ) If the client has no entity tag for an entity, but does have a Last- Modified date, it MAY use that date in an If-Range header. (The server can distinguish between a valid HTTP-date and any form of entity-tag by examining no more than two characters.) The If-Range header SHOULD only be used together with a Range header, and MUST be ignored if the request does not include a Range header, or if the server does not support the sub-range operation. If the entity tag given in the If-Range header matches the current entity tag for the entity, then the server SHOULD provide the specified sub-range of the entity using a 206 (Partial content) response. If the entity tag does not match, then the server SHOULD return the entire entity using a 200 (OK) response. 14.28 If-Unmodified-SinceThe If-Unmodified-Since request-header field is used with a method to make it conditional. If the requested resource has not been modified since the time specified in this field, the server SHOULD perform the requested operation as if the If-Unmodified-Since header were not present. If the requested variant has been modified since the specified time, the server MUST NOT perform the requested operation, and MUST return a 412 (Precondition Failed). 1If-Unmodified-Since = &quot;If-Unmodified-Since&quot; &quot;:&quot; HTTP-date An example of the field is: 1If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT If the request normally (i.e., without the If-Unmodified-Since header) would result in anything other than a 2xx or 412 status, the If-Unmodified-Since header SHOULD be ignored. If the specified date is invalid, the header is ignored. The result of a request having both an If-Unmodified-Since header field and either an If-None-Match or an If-Modified-Since header fields is undefined by this specification. 14.29 Last-ModifiedThe Last-Modified entity-header field indicates the date and time at which the origin server believes the variant was last modified. 1Last-Modified = &quot;Last-Modified&quot; &quot;:&quot; HTTP-date An example of its use is 1Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT The exact meaning of this header field depends on the implementation of the origin server and the nature of the original resource. For files, it may be just the file system last-modified time. For entities with dynamically included parts, it may be the most recent of the set of last-modify times for its component parts. For database gateways, it may be the last-update time stamp of the record. For virtual objects, it may be the last time the internal state changed. An origin server MUST NOT send a Last-Modified date which is later than the server’s time of message origination. In such cases, where the resource’s last modification would indicate some time in the future, the server MUST replace that date with the message origination date. An origin server SHOULD obtain the Last-Modified value of the entity as close as possible to the time that it generates the Date value of its response. This allows a recipient to make an accurate assessment of the entity’s modification time, especially if the entity changes near the time that the response is generated. HTTP/1.1 servers SHOULD send Last-Modified whenever feasible. 14.30 LocationThe Location response-header field is used to redirect the recipient to a location other than the Request-URI for completion of the request or identification of a new resource. For 201 (Created) responses, the Location is that of the new resource which was created by the request. For 3xx responses, the location SHOULD indicate the server’s preferred URI for automatic redirection to the resource. The field value consists of a single absolute URI. 1Location = &quot;Location&quot; &quot;:&quot; absoluteURI An example is: 1234567 Location: http://www.w3.org/pub/WWW/People.htmlNote: The Content-Location header field (section 14.14) differsfrom Location in that the Content-Location identifies the originallocation of the entity enclosed in the request. It is thereforepossible for a response to contain header fields for both Locationand Content-Location. Also see section 13.10 for cacherequirements of some methods. 14.31 Max-ForwardsThe Max-Forwards request-header field provides a mechanism with the TRACE (section 9.8) and OPTIONS (section 9.2) methods to limit the number of proxies or gateways that can forward the request to the next inbound server. This can be useful when the client is attempting to trace a request chain which appears to be failing or looping in mid-chain. 1Max-Forwards = &quot;Max-Forwards&quot; &quot;:&quot; 1*DIGIT The Max-Forwards value is a decimal integer indicating the remaining number of times this request message may be forwarded. Each proxy or gateway recipient of a TRACE or OPTIONS request containing a Max-Forwards header field MUST check and update its value prior to forwarding the request. If the received value is zero (0), the recipient MUST NOT forward the request; instead, it MUST respond as the final recipient. If the received Max-Forwards value is greater than zero, then the forwarded message MUST contain an updated Max-Forwards field with a value decremented by one (1). The Max-Forwards header field MAY be ignored for all other methods defined by this specification and for any extension methods for which it is not explicitly referred to as part of that method definition. 14.32 PragmaThe Pragma general-header field is used to include implementation- specific directives that might apply to any recipient along the request/response chain. All pragma directives specify optional behavior from the viewpoint of the protocol; however, some systems MAY require that behavior be consistent with the directives. 123Pragma = &quot;Pragma&quot; &quot;:&quot; 1#pragma-directivepragma-directive = &quot;no-cache&quot; | extension-pragmaextension-pragma = token [ &quot;=&quot; ( token | quoted-string ) ] When the no-cache directive is present in a request message, an application SHOULD forward the request toward the origin server even if it has a cached copy of what is being requested. This pragma directive has the same semantics as the no-cache cache-directive (see section 14.9) and is defined here for backward compatibility with HTTP/1.0. Clients SHOULD include both header fields when a no-cache request is sent to a server not known to be HTTP/1.1 compliant. Pragma directives MUST be passed through by a proxy or gateway application, regardless of their significance to that application, since the directives might be applicable to all recipients along the request/response chain. It is not possible to specify a pragma for a specific recipient; however, any pragma directive not relevant to a recipient SHOULD be ignored by that recipient. HTTP/1.1 caches SHOULD treat “Pragma: no-cache” as if the client had sent “Cache-Control: no-cache”. No new Pragma directives will be defined in HTTP. 123Note: because the meaning of &quot;Pragma: no-cache as a responseheader field is not actually specified, it does not provide areliable replacement for &quot;Cache-Control: no-cache&quot; in a response 14.33 Proxy-AuthenticateThe Proxy-Authenticate response-header field MUST be included as part of a 407 (Proxy Authentication Required) response. The field value consists of a challenge that indicates the authentication scheme and parameters applicable to the proxy for this Request-URI. 1Proxy-Authenticate = &quot;Proxy-Authenticate&quot; &quot;:&quot; 1#challenge The HTTP access authentication process is described in “HTTP Authentication: Basic and Digest Access Authentication” [43]. Unlike WWW-Authenticate, the Proxy-Authenticate header field applies only to the current connection and SHOULD NOT be passed on to downstream clients. However, an intermediate proxy might need to obtain its own credentials by requesting them from the downstream client, which in some circumstances will appear as if the proxy is forwarding the Proxy-Authenticate header field. 14.34 Proxy-AuthorizationThe Proxy-Authorization request-header field allows the client to identify itself (or its user) to a proxy which requires authentication. The Proxy-Authorization field value consists of credentials containing the authentication information of the user agent for the proxy and/or realm of the resource being requested. 1Proxy-Authorization = &quot;Proxy-Authorization&quot; &quot;:&quot; credentials The HTTP access authentication process is described in “HTTP Authentication: Basic and Digest Access Authentication” [43] . Unlike Authorization, the Proxy-Authorization header field applies only to the next outbound proxy that demanded authentication using the Proxy- Authenticate field. When multiple proxies are used in a chain, the Proxy-Authorization header field is consumed by the first outbound proxy that was expecting to receive credentials. A proxy MAY relay the credentials from the client request to the next proxy if that is the mechanism by which the proxies cooperatively authenticate a given request. 14.35 Range14.35.1 Byte RangesSince all HTTP entities are represented in HTTP messages as sequences of bytes, the concept of a byte range is meaningful for any HTTP entity. (However, not all clients and servers need to support byte- range operations.) Byte range specifications in HTTP apply to the sequence of bytes in the entity-body (not necessarily the same as the message-body). A byte range operation MAY specify a single range of bytes, or a set of ranges within a single entity. 123456ranges-specifier = byte-ranges-specifierbyte-ranges-specifier = bytes-unit &quot;=&quot; byte-range-setbyte-range-set = 1#( byte-range-spec | suffix-byte-range-spec )byte-range-spec = first-byte-pos &quot;-&quot; [last-byte-pos]first-byte-pos = 1*DIGITlast-byte-pos = 1*DIGIT The first-byte-pos value in a byte-range-spec gives the byte-offset of the first byte in a range. The last-byte-pos value gives the byte-offset of the last byte in the range; that is, the byte positions specified are inclusive. Byte offsets start at zero. If the last-byte-pos value is present, it MUST be greater than or equal to the first-byte-pos in that byte-range-spec, or the byte- range-spec is syntactically invalid. The recipient of a byte-range- set that includes one or more syntactically invalid byte-range-spec values MUST ignore the header field that includes that byte-range- set. If the last-byte-pos value is absent, or if the value is greater than or equal to the current length of the entity-body, last-byte-pos is taken to be equal to one less than the current length of the entity- body in bytes. By its choice of last-byte-pos, a client can limit the number of bytes retrieved without knowing the size of the entity. 12suffix-byte-range-spec = &quot;-&quot; suffix-lengthsuffix-length = 1*DIGIT A suffix-byte-range-spec is used to specify the suffix of the entity-body, of a length given by the suffix-length value. (That is, this form specifies the last N bytes of an entity-body.) If the entity is shorter than the specified suffix-length, the entire entity-body is used. If a syntactically valid byte-range-set includes at least one byte- range-spec whose first-byte-pos is less than the current length of the entity-body, or at least one suffix-byte-range-spec with a non- zero suffix-length, then the byte-range-set is satisfiable. Otherwise, the byte-range-set is unsatisfiable. If the byte-range-set is unsatisfiable, the server SHOULD return a response with a status of 416 (Requested range not satisfiable). Otherwise, the server SHOULD return a response with a status of 206 (Partial Content) containing the satisfiable ranges of the entity-body. Examples of byte-ranges-specifier values (assuming an entity-body of length 10000): 123456789101112- The first 500 bytes (byte offsets 0-499, inclusive): bytes=0- 499- The second 500 bytes (byte offsets 500-999, inclusive): bytes=500-999- The final 500 bytes (byte offsets 9500-9999, inclusive): bytes=-500- Or bytes=9500-- The first and last bytes only (bytes 0 and 9999): bytes=0-0,-1- Several legal but not canonical specifications of the second 500 bytes (byte offsets 500-999, inclusive): bytes=500-600,601-999 bytes=500-700,601-999 14.35.2 Range Retrieval RequestsHTTP retrieval requests using conditional or unconditional GET methods MAY request one or more sub-ranges of the entity, instead of the entire entity, using the Range request header, which applies to the entity returned as the result of the request: 1Range = &quot;Range&quot; &quot;:&quot; ranges-specifier A server MAY ignore the Range header. However, HTTP/1.1 origin servers and intermediate caches ought to support byte ranges when possible, since Range supports efficient recovery from partially failed transfers, and supports efficient partial retrieval of large entities. If the server supports the Range header and the specified range or ranges are appropriate for the entity: 12345678910- The presence of a Range header in an unconditional GET modifies what is returned if the GET is otherwise successful. In other words, the response carries a status code of 206 (Partial Content) instead of 200 (OK).- The presence of a Range header in a conditional GET (a request using one or both of If-Modified-Since and If-None-Match, or one or both of If-Unmodified-Since and If-Match) modifies what is returned if the GET is otherwise successful and the condition is true. It does not affect the 304 (Not Modified) response returned if the conditional is false. In some cases, it might be more appropriate to use the If-Range header (see section 14.27) in addition to the Range header. If a proxy that supports ranges receives a Range request, forwards the request to an inbound server, and receives an entire entity in reply, it SHOULD only return the requested range to its client. It SHOULD store the entire received response in its cache if that is consistent with its cache allocation policies. 14.36 RefererThe Referer[sic] request-header field allows the client to specify, for the server’s benefit, the address (URI) of the resource from which the Request-URI was obtained (the “referrer”, although the header field is misspelled.) The Referer request-header allows a server to generate lists of back-links to resources for interest, logging, optimized caching, etc. It also allows obsolete or mistyped links to be traced for maintenance. The Referer field MUST NOT be sent if the Request-URI was obtained from a source that does not have its own URI, such as input from the user keyboard. 1Referer = &quot;Referer&quot; &quot;:&quot; ( absoluteURI | relativeURI ) Example: 1Referer: http://www.w3.org/hypertext/DataSources/Overview.html If the field value is a relative URI, it SHOULD be interpreted relative to the Request-URI. The URI MUST NOT include a fragment. See section 15.1.3 for security considerations. 14.37 Retry-AfterThe Retry-After response-header field can be used with a 503 (Service Unavailable) response to indicate how long the service is expected to be unavailable to the requesting client. This field MAY also be used with any 3xx (Redirection) response to indicate the minimum time the user-agent is asked wait before issuing the redirected request. The value of this field can be either an HTTP-date or an integer number of seconds (in decimal) after the time of the response. 1Retry-After = &quot;Retry-After&quot; &quot;:&quot; ( HTTP-date | delta-seconds ) Two examples of its use are 12Retry-After: Fri, 31 Dec 1999 23:59:59 GMTRetry-After: 120 In the latter example, the delay is 2 minutes. 14.38 ServerThe Server response-header field contains information about the software used by the origin server to handle the request. The field can contain multiple product tokens (section 3.8) and comments identifying the server and any significant subproducts. The product tokens are listed in order of their significance for identifying the application. 1Server = &quot;Server&quot; &quot;:&quot; 1*( product | comment ) Example: 1Server: CERN/3.0 libwww/2.17 If the response is being forwarded through a proxy, the proxy application MUST NOT modify the Server response-header. Instead, it SHOULD include a Via field (as described in section 14.45). 12345Note: Revealing the specific software version of the server mightallow the server machine to become more vulnerable to attacksagainst software that is known to contain security holes. Serverimplementors are encouraged to make this field a configurableoption. 14.39 TEThe TE request-header field indicates what extension transfer-codings it is willing to accept in the response and whether or not it is willing to accept trailer fields in a chunked transfer-coding. Its value may consist of the keyword “trailers” and/or a comma-separated list of extension transfer-coding names with optional accept parameters (as described in section 3.6). 12TE = &quot;TE&quot; &quot;:&quot; #( t-codings )t-codings = &quot;trailers&quot; | ( transfer-extension [ accept-params ] ) The presence of the keyword “trailers” indicates that the client is willing to accept trailer fields in a chunked transfer-coding, as defined in section 3.6.1. This keyword is reserved for use with transfer-coding values even though it does not itself represent a transfer-coding. Examples of its use are: 123TE: deflateTE:TE: trailers, deflate;q=0.5 The TE header field only applies to the immediate connection. Therefore, the keyword MUST be supplied within a Connection header field (section 14.10) whenever TE is present in an HTTP/1.1 message. A server tests whether a transfer-coding is acceptable, according to a TE field, using these rules: 123456789101112131415161718191. The &quot;chunked&quot; transfer-coding is always acceptable. If the keyword &quot;trailers&quot; is listed, the client indicates that it is willing to accept trailer fields in the chunked response on behalf of itself and any downstream clients. The implication is that, if given, the client is stating that either all downstream clients are willing to accept trailer fields in the forwarded response, or that it will attempt to buffer the response on behalf of downstream recipients. Note: HTTP/1.1 does not define any means to limit the size of a chunked response such that a client can be assured of buffering the entire response.2. If the transfer-coding being tested is one of the transfer- codings listed in the TE field, then it is acceptable unless it is accompanied by a qvalue of 0. (As defined in section 3.9, a qvalue of 0 means &quot;not acceptable.&quot;)3. If multiple transfer-codings are acceptable, then the acceptable transfer-coding with the highest non-zero qvalue is preferred. The &quot;chunked&quot; transfer-coding always has a qvalue of 1. If the TE field-value is empty or if no TE field is present, the only transfer-coding is “chunked”. A message with no transfer-coding is always acceptable. 14.40 TrailerThe Trailer general field value indicates that the given set of header fields is present in the trailer of a message encoded with chunked transfer-coding. 1Trailer = &quot;Trailer&quot; &quot;:&quot; 1#field-name An HTTP/1.1 message SHOULD include a Trailer header field in a message using chunked transfer-coding with a non-empty trailer. Doing so allows the recipient to know which header fields to expect in the trailer. If no Trailer header field is present, the trailer SHOULD NOT include any header fields. See section 3.6.1 for restrictions on the use of trailer fields in a “chunked” transfer-coding. Message header fields listed in the Trailer header field MUST NOT include the following header fields: 123. Transfer-Encoding. Content-Length. Trailer 14.41 Transfer-EncodingThe Transfer-Encoding general-header field indicates what (if any) type of transformation has been applied to the message body in order to safely transfer it between the sender and the recipient. This differs from the content-coding in that the transfer-coding is a property of the message, not of the entity. 1Transfer-Encoding = &quot;Transfer-Encoding&quot; &quot;:&quot; 1#transfer-coding Transfer-codings are defined in section 3.6. An example is: 1Transfer-Encoding: chunked If multiple encodings have been applied to an entity, the transfer- codings MUST be listed in the order in which they were applied. Additional information about the encoding parameters MAY be provided by other entity-header fields not defined by this specification. Many older HTTP/1.0 applications do not understand the Transfer- Encoding header. 14.42 UpgradeThe Upgrade general-header allows the client to specify what additional communication protocols it supports and would like to use if the server finds it appropriate to switch protocols. The server MUST use the Upgrade header field within a 101 (Switching Protocols) response to indicate which protocol(s) are being switched. 1Upgrade = &quot;Upgrade&quot; &quot;:&quot; 1#product For example, 1Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 The Upgrade header field is intended to provide a simple mechanism for transition from HTTP/1.1 to some other, incompatible protocol. It does so by allowing the client to advertise its desire to use another protocol, such as a later version of HTTP with a higher major version number, even though the current request has been made using HTTP/1.1. This eases the difficult transition between incompatible protocols by allowing the client to initiate a request in the more commonly supported protocol while indicating to the server that it would like to use a “better” protocol if available (where “better” is determined by the server, possibly according to the nature of the method and/or resource being requested). The Upgrade header field only applies to switching application-layer protocols upon the existing transport-layer connection. Upgrade cannot be used to insist on a protocol change; its acceptance and use by the server is optional. The capabilities and nature of the application-layer communication after the protocol change is entirely dependent upon the new protocol chosen, although the first action after changing the protocol MUST be a response to the initial HTTP request containing the Upgrade header field. The Upgrade header field only applies to the immediate connection. Therefore, the upgrade keyword MUST be supplied within a Connection header field (section 14.10) whenever Upgrade is present in an HTTP/1.1 message. The Upgrade header field cannot be used to indicate a switch to a protocol on a different connection. For that purpose, it is more appropriate to use a 301, 302, 303, or 305 redirection response. This specification only defines the protocol name “HTTP” for use by the family of Hypertext Transfer Protocols, as defined by the HTTP version rules of section 3.1 and future updates to this specification. Any token can be used as a protocol name; however, it will only be useful if both the client and server associate the name with the same protocol. 14.43 User-AgentThe User-Agent request-header field contains information about the user agent originating the request. This is for statistical purposes, the tracing of protocol violations, and automated recognition of user agents for the sake of tailoring responses to avoid particular user agent limitations. User agents SHOULD include this field with requests. The field can contain multiple product tokens (section 3.8) and comments identifying the agent and any subproducts which form a significant part of the user agent. By convention, the product tokens are listed in order of their significance for identifying the application. 1User-Agent = &quot;User-Agent&quot; &quot;:&quot; 1*( product | comment ) Example: 1User-Agent: CERN-LineMode/2.15 libwww/2.17b3 14.44 VaryThe Vary field value indicates the set of request-header fields that fully determines, while the response is fresh, whether a cache is permitted to use the response to reply to a subsequent request without revalidation. For uncacheable or stale responses, the Vary field value advises the user agent about the criteria that were used to select the representation. A Vary field value of “*” implies that a cache cannot determine from the request headers of a subsequent request whether this response is the appropriate representation. See section 13.6 for use of the Vary header field by caches. 1Vary = &quot;Vary&quot; &quot;:&quot; ( &quot;*&quot; | 1#field-name ) An HTTP/1.1 server SHOULD include a Vary header field with any cacheable response that is subject to server-driven negotiation. Doing so allows a cache to properly interpret future requests on that resource and informs the user agent about the presence of negotiation on that resource. A server MAY include a Vary header field with a non-cacheable response that is subject to server-driven negotiation, since this might provide the user agent with useful information about the dimensions over which the response varies at the time of the response. A Vary field value consisting of a list of field-names signals that the representation selected for the response is based on a selection algorithm which considers ONLY the listed request-header field values in selecting the most appropriate representation. A cache MAY assume that the same selection will be made for future requests with the same values for the listed field names, for the duration of time for which the response is fresh. The field-names given are not limited to the set of standard request-header fields defined by this specification. Field names are case-insensitive. A Vary field value of ““ signals that unspecified parameters not limited to the request-headers (e.g., the network address of the client), play a role in the selection of the response representation. The ““ value MUST NOT be generated by a proxy server; it may only be generated by an origin server. 14.45 ViaThe Via general-header field MUST be used by gateways and proxies to indicate the intermediate protocols and recipients between the user agent and the server on requests, and between the origin server and the client on responses. It is analogous to the “Received” field of RFC 822 [9] and is intended to be used for tracking message forwards, avoiding request loops, and identifying the protocol capabilities of all senders along the request/response chain. 123456Via = &quot;Via&quot; &quot;:&quot; 1#( received-protocol received-by [ comment ] )received-protocol = [ protocol-name &quot;/&quot; ] protocol-versionprotocol-name = tokenprotocol-version = tokenreceived-by = ( host [ &quot;:&quot; port ] ) | pseudonympseudonym = token The received-protocol indicates the protocol version of the message received by the server or client along each segment of the request/response chain. The received-protocol version is appended to the Via field value when the message is forwarded so that information about the protocol capabilities of upstream applications remains visible to all recipients. The protocol-name is optional if and only if it would be “HTTP”. The received-by field is normally the host and optional port number of a recipient server or client that subsequently forwarded the message. However, if the real host is considered to be sensitive information, it MAY be replaced by a pseudonym. If the port is not given, it MAY be assumed to be the default port of the received-protocol. Multiple Via field values represents each proxy or gateway that has forwarded the message. Each recipient MUST append its information such that the end result is ordered according to the sequence of forwarding applications. Comments MAY be used in the Via header field to identify the software of the recipient proxy or gateway, analogous to the User-Agent and Server header fields. However, all comments in the Via field are optional and MAY be removed by any recipient prior to forwarding the message. For example, a request message could be sent from an HTTP/1.0 user agent to an internal proxy code-named “fred”, which uses HTTP/1.1 to forward the request to a public proxy at nowhere.com, which completes the request by forwarding it to the origin server at www.ics.uci.edu. The request received by www.ics.uci.edu would then have the following Via header field: 1Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Proxies and gateways used as a portal through a network firewall SHOULD NOT, by default, forward the names and ports of hosts within the firewall region. This information SHOULD only be propagated if explicitly enabled. If not enabled, the received-by host of any host behind the firewall SHOULD be replaced by an appropriate pseudonym for that host. For organizations that have strong privacy requirements for hiding internal structures, a proxy MAY combine an ordered subsequence of Via header field entries with identical received-protocol values into a single such entry. For example, 123Via: 1.0 ricky, 1.1 ethel, 1.1 fred, 1.0 lucy could be collapsed toVia: 1.0 ricky, 1.1 mertz, 1.0 lucy Applications SHOULD NOT combine multiple entries unless they are all under the same organizational control and the hosts have already been replaced by pseudonyms. Applications MUST NOT combine entries which have different received-protocol values. 14.46 WarningThe Warning general-header field is used to carry additional information about the status or transformation of a message which might not be reflected in the message. This information is typically used to warn about a possible lack of semantic transparency from caching operations or transformations applied to the entity body of the message. Warning headers are sent with responses using: 123456789Warning = &quot;Warning&quot; &quot;:&quot; 1#warning-valuewarning-value = warn-code SP warn-agent SP warn-text [SP warn-date]warn-code = 3DIGITwarn-agent = ( host [ &quot;:&quot; port ] ) | pseudonym ; the name or pseudonym of the server adding ; the Warning header, for use in debuggingwarn-text = quoted-stringwarn-date = &lt;&quot;&gt; HTTP-date &lt;&quot;&gt; A response MAY carry more than one Warning header. The warn-text SHOULD be in a natural language and character set that is most likely to be intelligible to the human user receiving the response. This decision MAY be based on any available knowledge, such as the location of the cache or user, the Accept-Language field in a request, the Content-Language field in a response, etc. The default language is English and the default character set is ISO-8859-1. If a character set other than ISO-8859-1 is used, it MUST be encoded in the warn-text using the method described in RFC 2047 [14]. Warning headers can in general be applied to any message, however some specific warn-codes are specific to caches and can only be applied to response messages. New Warning headers SHOULD be added after any existing Warning headers. A cache MUST NOT delete any Warning header that it received with a message. However, if a cache successfully validates a cache entry, it SHOULD remove any Warning headers previously attached to that entry except as specified for specific Warning codes. It MUST then add any Warning headers received in the validating response. In other words, Warning headers are those that would be attached to the most recent relevant response. When multiple Warning headers are attached to a response, the user agent ought to inform the user of as many of them as possible, in the order that they appear in the response. If it is not possible to inform the user of all of the warnings, the user agent SHOULD follow these heuristics: 12345- Warnings that appear early in the response take priority over those appearing later in the response.- Warnings in the user&apos;s preferred character set take priority over warnings in other character sets but with identical warn- codes and warn-agents. Systems that generate multiple Warning headers SHOULD order them with this user agent behavior in mind. Requirements for the behavior of caches with respect to Warnings are stated in section 13.1.2. This is a list of the currently-defined warn-codes, each with a recommended warn-text in English, and a description of its meaning. 110 Response is stale MUST be included whenever the returned response is stale. 111 Revalidation failed MUST be included if a cache returns a stale response because an attempt to revalidate the response failed, due to an inability to reach the server. 112 Disconnected operation SHOULD be included if the cache is intentionally disconnected from the rest of the network for a period of time. 113 Heuristic expiration MUST be included if the cache heuristically chose a freshness lifetime greater than 24 hours and the response’s age is greater than 24 hours. 199 Miscellaneous warning The warning text MAY include arbitrary information to be presented to a human user, or logged. A system receiving this warning MUST NOT take any automated action, besides presenting the warning to the user. 214 Transformation applied MUST be added by an intermediate cache or proxy if it applies any transformation changing the content-coding (as specified in the Content-Encoding header) or media-type (as specified in the Content-Type header) of the response, or the entity-body of the response, unless this Warning code already appears in the response. 299 Miscellaneous persistent warning The warning text MAY include arbitrary information to be presented to a human user, or logged. A system receiving this warning MUST NOT take any automated action. If an implementation sends a message with one or more Warning headers whose version is HTTP/1.0 or lower, then the sender MUST include in each warning-value a warn-date that matches the date in the response. If an implementation receives a message with a warning-value that includes a warn-date, and that warn-date is different from the Date value in the response, then that warning-value MUST be deleted from the message before storing, forwarding, or using it. (This prevents bad consequences of naive caching of Warning header fields.) If all of the warning-values are deleted for this reason, the Warning header MUST be deleted as well. 14.47 WWW-AuthenticateThe WWW-Authenticate response-header field MUST be included in 401 (Unauthorized) response messages. The field value consists of at least one challenge that indicates the authentication scheme(s) and parameters applicable to the Request-URI. 1WWW-Authenticate = &quot;WWW-Authenticate&quot; &quot;:&quot; 1#challenge The HTTP access authentication process is described in “HTTP Authentication: Basic and Digest Access Authentication” [43]. User agents are advised to take special care in parsing the WWW- Authenticate field value as it might contain more than one challenge, or if more than one WWW-Authenticate header field is provided, the contents of a challenge itself can contain a comma-separated list of authentication parameters.]]></content>
      <categories>
        <category>翻译</category>
        <category>FE</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP Header</tag>
        <tag>Protocol</tag>
      </tags>
  </entry>
</search>
